{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions\n",
    "##### These functions are gonna be apllied at the whole play level, either by processing the first corpus input, or to describe the further details of the different characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expresions which match with different editions ways of pointing out actions outside the speech, \n",
    "# which are gonna be applied in the paragraphs_cleaner function\n",
    "squared_braquets = \"\\[.*?]\"\n",
    "normal_braquets = \"\\(.*?\\)\"\n",
    "squared_to_point = \"\\\\[.*?\\.\"\n",
    "normal_to_point = \"\\\\(.*?\\.\"\n",
    "nothing = \"xxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraphs_cleaner(file, regex1, regex2):\n",
    "    '''It takes a text file and returns a list of word tokenized paragraphs, \n",
    "    each one starting with the name of the character and being followed by \n",
    "    the free speech, free from the internal descriptions'''\n",
    "    f = open(file, \"r\")\n",
    "    contents = f.read()         \n",
    "    f.close()     \n",
    "    paragraph_cutter = re.sub('\\n{2,}', '\\n\\n', contents) #Paragraph identifier\n",
    "    paragraphs = paragraph_cutter.split('\\n\\n') #It cuts the paragraphs by the identified points\n",
    "    clean_result = []\n",
    "    for par in paragraphs:\n",
    "        output = re.sub(\"\\\\n\", \" \", par) # Removes the single new-line characters within the paragraphs\n",
    "        pseudo_clean = re.sub(regex1 , \"\", output) # Removes the additional text \n",
    "        clean = re.sub(regex2 , \"\", pseudo_clean)\n",
    "        clean_result.append(clean)\n",
    "    result = []\n",
    "    for par in clean_result:\n",
    "        output = nltk.word_tokenize(par) #Word tokenizer for each paragraph\n",
    "        result.append(output)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters_details (play_characters):\n",
    "    '''It takes a diccionary in the form of character:speech lines, \n",
    "    and counts the sentences and words for every character'''\n",
    "    for key in play_characters:\n",
    "        word_count = 0\n",
    "        for sen in play_characters[key]:\n",
    "            output = len(re.findall(r\"\\w+\", sen))\n",
    "            word_count += output\n",
    "        print ('%s contains %d sentences and %d words'%(key, len(play_characters[key]), word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Functions\n",
    "\n",
    "##### These functions are gonna be applied at the character level, with a more partial aproach aimed at dealing with the different writting conventions and the irregularities found in different editions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_cleaner (character_raw, n):\n",
    "    '''It takes a list of characters tokenized by words paragraphs,\n",
    "    and returns a list of sentences, where n is the point\n",
    "    where ends the character's name'''\n",
    "    no_name = []\n",
    "    for par in character_raw: #It cuts by the previusly identified point\n",
    "        output = par[n:]\n",
    "        no_name.append(output)\n",
    "    output = []\n",
    "    for sen in no_name: #It joins all the words into one string\n",
    "        for word in sen:\n",
    "            output.append(word)\n",
    "    one_string = \" \".join(output)\n",
    "    result = nltk.sent_tokenize(one_string) #It tokenizes the string into sentences\n",
    "    for sen in  result: #Removes the single points sentences for a best estimation of the sentneces lenght\n",
    "        if sen == '.':\n",
    "            result.remove(sen)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_joiner(strings):\n",
    "    '''It take a list of word_tokenized paragraphs,\n",
    "    and returns a sentence tokenized string'''\n",
    "    output = []\n",
    "    for string in strings:\n",
    "        for word in string:\n",
    "            output.append(word)\n",
    "    one_string = \" \".join(output)\n",
    "    result = nltk.sent_tokenize(one_string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_cleaner_by_name (character_raw, name1, name2, name3):\n",
    "    '''It removes the different names and ways of introducting the character,\n",
    "    when neither the name nor the ending position of the expression are regular'''\n",
    "    for sen in character_raw:\n",
    "        if name1 in sen:\n",
    "            sen.remove(name1)\n",
    "    for sen in character_raw:\n",
    "        if name2 in sen:\n",
    "            sen.remove(name2)\n",
    "    for sen in character_raw:\n",
    "        if name3 in sen:\n",
    "            sen.remove(name3)\n",
    "    output = string_joiner(character_raw)\n",
    "    for sen in  output: #Removes the single points sentences for a best estimation of the lenghth\n",
    "        if sen == '.':\n",
    "            output.remove(sen)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_filter (character):\n",
    "    '''Removes the remaining sentneces which \n",
    "    have less than one character lenght'''\n",
    "    output = []\n",
    "    for sen in character:\n",
    "        if len(sen) > 1:\n",
    "            output.append(sen)\n",
    "    result = string_joiner(output)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Plays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Ideal Husband - Oscar Wilde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aih = paragraphs_cleaner(\"an_ideal_husband_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It gets rid of the introducting paragraphs\n",
    "token_paragraphs_aih = token_paragraphs_aih[48:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An empty dictionary was created for every character with a minimum presence in the play for the further filtering.\n",
    "caversham_raw = []\n",
    "goring_raw = []\n",
    "chiltern_raw = []\n",
    "ladychiltern_raw = []\n",
    "mabel_raw = []\n",
    "cheveley_raw = []\n",
    "for par in token_paragraphs_aih:\n",
    "    if 'CAVERSHAM' in par:\n",
    "        caversham_raw.append(par)\n",
    "    if 'GORING' in par:\n",
    "        goring_raw.append(par)\n",
    "    if 'ROBERT' in par:\n",
    "        chiltern_raw.append(par)\n",
    "    if 'LADY' and 'CHILTERN' in par and not 'MABEL' in par and not 'SIR' in par:\n",
    "        ladychiltern_raw.append(par)\n",
    "    if 'MABEL' in par:\n",
    "        mabel_raw.append(par)\n",
    "    if 'CHEVELEY' in par:\n",
    "        cheveley_raw.append(par)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individualized cleaning by character, in this case with the positional cleaning function.\n",
    "caversham = character_cleaner(caversham_raw, 3)\n",
    "goring = character_cleaner(goring_raw, 3)\n",
    "chiltern = character_cleaner(chiltern_raw, 4)\n",
    "ladychiltern = character_cleaner(ladychiltern_raw, 3)\n",
    "mabel = character_cleaner(mabel_raw, 3)\n",
    "cheveley = character_cleaner(cheveley_raw, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a dict of the plays's characters and their speech lines, thst we will store later\n",
    "an_ideal_husband_characters = {'Caversham':caversham, 'Goring':goring, 'Chiltern':chiltern, 'Lady Chiltern':ladychiltern, 'Mabel':mabel, 'Cheveley':cheveley}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caversham contains 201 sentences and 1507 words\n",
      "Goring contains 775 sentences and 6233 words\n",
      "Chiltern contains 534 sentences and 4937 words\n",
      "Lady Chiltern contains 369 sentences and 2917 words\n",
      "Mabel contains 235 sentences and 1937 words\n",
      "Cheveley contains 522 sentences and 4380 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(an_ideal_husband_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'an_ideal_husband_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "# We are gonna store every dict for a more convenient handling of the data in the subsequent analysis phases\n",
    "%store an_ideal_husband_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Woman of No Importance - Oscar Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_awoni = paragraphs_cleaner(\"a_woman_of_no_importance_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_awoni = token_paragraphs_awoni[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "illingworth_raw = []\n",
    "allonby_raw = []\n",
    "gerald_raw = []\n",
    "mrsarbuthnot_raw = []\n",
    "hunstanton_raw = []\n",
    "hester_raw = []\n",
    "\n",
    "for par in token_paragraphs_awoni:\n",
    "    if 'ILLINGWORTH' in par:\n",
    "        illingworth_raw.append(par)\n",
    "    if 'ALLONBY' in par:\n",
    "        allonby_raw.append(par)\n",
    "    if 'GERALD' in par:\n",
    "        gerald_raw.append(par)\n",
    "    if 'MRS' and 'ARBUTHNOT' in par:\n",
    "        mrsarbuthnot_raw.append(par)\n",
    "    if 'HUNSTANTON' in par:\n",
    "        hunstanton_raw.append(par)\n",
    "    if 'HESTER' in par:\n",
    "        hester_raw.append(par)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "illingworth = character_cleaner(illingworth_raw, 3)\n",
    "allonby = character_cleaner(allonby_raw, 3)\n",
    "gerald = character_cleaner(gerald_raw, 2)\n",
    "mrsarbuthnot = character_cleaner(mrsarbuthnot_raw, 2)\n",
    "hunstanton = character_cleaner(hunstanton_raw, 2)\n",
    "hester = character_cleaner(hester_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_woman_of_no_importance_characters = {'Illingorth':illingworth, 'Allonby':allonby, 'Gerald':gerald, 'Mrs Artbuthnot':mrsarbuthnot, 'Hunstanton':hunstanton, 'Hester':hester}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illingorth contains 426 sentences and 4183 words\n",
      "Allonby contains 213 sentences and 2091 words\n",
      "Gerald contains 255 sentences and 2427 words\n",
      "Mrs Artbuthnot contains 356 sentences and 3079 words\n",
      "Hunstanton contains 367 sentences and 3658 words\n",
      "Hester contains 141 sentences and 1342 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(a_woman_of_no_importance_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing characters with less than 1500 words\n",
    "del a_woman_of_no_importance_characters['Hester']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'a_woman_of_no_importance_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store a_woman_of_no_importance_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Lady Windermer's Fan - Oscar Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_lwf = paragraphs_cleaner(\"lady_windermeres_fan_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_lwf = token_paragraphs_lwf[47:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lordwindermere_raw = []\n",
    "erlynne_raw = []\n",
    "augustus_raw = []\n",
    "windermere_raw = []\n",
    "darlington_raw = []\n",
    "berwick_raw = []\n",
    "for par in token_paragraphs_lwf:\n",
    "    if 'LORD' and 'WINDERMERE' in par and not 'LADY' in par:\n",
    "        lordwindermere_raw.append(par)\n",
    "    if 'ERLYNNE' in par:\n",
    "        erlynne_raw.append(par)\n",
    "    if 'AUGUSTUS' in par:\n",
    "        augustus_raw.append(par)\n",
    "    if 'LADY' and 'WINDERMERE' in par:\n",
    "        windermere_raw.append(par)\n",
    "    if 'DARLINGTON' in par:\n",
    "        darlington_raw.append(par)\n",
    "    if 'BERWICK' in par:\n",
    "        berwick_raw.append(par)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lordwindermere = character_cleaner(lordwindermere_raw, 3)\n",
    "erlynne = character_cleaner(erlynne_raw, 3)\n",
    "augustus = character_cleaner(augustus_raw, 3)\n",
    "windermere = character_cleaner(windermere_raw, 3)\n",
    "darlington = character_cleaner(darlington_raw,3)\n",
    "berwick = character_cleaner(berwick_raw, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lady_windermeres_fan_characters = {'Lord Windermere':lordwindermere, 'Erlynne':erlynne, 'Augustus':augustus, 'Lady Windermere':windermere, 'Darlington':darlington, 'Berwick':berwick}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Windermere contains 233 sentences and 2138 words\n",
      "Erlynne contains 395 sentences and 3521 words\n",
      "Augustus contains 91 sentences and 628 words\n",
      "Lady Windermere contains 727 sentences and 6027 words\n",
      "Darlington contains 190 sentences and 1704 words\n",
      "Berwick contains 189 sentences and 2037 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(lady_windermeres_fan_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lady_windermeres_fan_characters['Augustus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lady_windermeres_fan_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store lady_windermeres_fan_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Importance of Being Earnest - Oscar Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_tiobe = paragraphs_cleaner(\"the_importance_of_being_earnest_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_tiobe = token_paragraphs_tiobe[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jack_raw = []\n",
    "algernon_raw = []\n",
    "gwendolen_raw = []\n",
    "bracknell_raw = []\n",
    "cecily_raw = []\n",
    "prism_raw = []\n",
    "chasuble_raw = []\n",
    "for par in token_paragraphs_tiobe:\n",
    "    if 'Jack' in par[0:1]:\n",
    "        jack_raw.append(par)\n",
    "    if 'Algernon' in par[0:1]:\n",
    "        algernon_raw.append(par)\n",
    "    if 'Gwendolen' in par[0:1]:\n",
    "        gwendolen_raw.append(par)\n",
    "    if 'Bracknell' in par[0:2]:\n",
    "        bracknell_raw.append(par)\n",
    "    if 'Cecily' in par[0:1]:\n",
    "        cecily_raw.append(par)\n",
    "    if 'Prism' in par[0:2]:\n",
    "        prism_raw.append(par)\n",
    "    if 'Chasuble' in par[0:1]:\n",
    "        chasuble_raw.append(par)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "jack = character_cleaner(jack_raw, 2)\n",
    "algernon = character_cleaner(algernon_raw, 2)\n",
    "gwendolen = character_cleaner(gwendolen_raw, 2)\n",
    "bracknell = character_cleaner(bracknell_raw, 3)\n",
    "cecily = character_cleaner(cecily_raw, 3)\n",
    "prism = character_cleaner(prism_raw, 3)\n",
    "chasuble = character_cleaner(chasuble_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_importance_of_being_earnest_characters = {'Jack':jack, 'Algernon':algernon, 'Gwendolen':gwendolen, 'Bracknell':bracknell, 'Cecily':cecily, 'Prism':prism, 'Chasuble':chasuble}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack contains 473 sentences and 4161 words\n",
      "Algernon contains 439 sentences and 4116 words\n",
      "Gwendolen contains 244 sentences and 2242 words\n",
      "Bracknell contains 280 sentences and 2936 words\n",
      "Cecily contains 291 sentences and 2638 words\n",
      "Prism contains 102 sentences and 960 words\n",
      "Chasuble contains 82 sentences and 778 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(the_importance_of_being_earnest_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "del the_importance_of_being_earnest_characters['Prism']\n",
    "del the_importance_of_being_earnest_characters['Chasuble']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'the_importance_of_being_earnest_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store the_importance_of_being_earnest_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pygmalion - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_p = paragraphs_cleaner(\"pygmalion_shaw.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_p = token_paragraphs_p[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickering_raw = []\n",
    "higgins_raw = []\n",
    "liza_raw = []\n",
    "gentleman_raw = []\n",
    "taker_raw = []\n",
    "girl_raw = []\n",
    "mrshiggins_raw = []\n",
    "doolittle_raw = []\n",
    "for par in token_paragraphs_p:\n",
    "    if 'PICKERING' in par:\n",
    "        pickering_raw.append(par)\n",
    "    if 'HIGGINS' in par and not 'MRS.'in par:\n",
    "        higgins_raw.append(par)\n",
    "    if 'LIZA' in par:\n",
    "        liza_raw.append(par)\n",
    "    if 'GENTLEMAN' in par:\n",
    "        gentleman_raw.append(par)\n",
    "    if 'TAKER' in par:\n",
    "        taker_raw.append(par)\n",
    "    if 'GIRL' in par:\n",
    "        girl_raw.append(par)\n",
    "    if 'MRS.' in par and 'HIGGINS' in par[0:2]:\n",
    "        mrshiggins_raw.append(par)\n",
    "    if 'DOOLITTLE' in par:\n",
    "        doolittle_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickering = character_cleaner_by_name(pickering_raw, 'PICKERING', 'xxxxxx', 'xxxxxx')\n",
    "higgins = character_cleaner_by_name(higgins_raw, 'HIGGINS', 'xxxxx', 'xxxxx')\n",
    "liza = character_cleaner_by_name(liza_raw, 'LIZA', 'xxxxx', 'xxxxx')\n",
    "gentelman = character_cleaner_by_name(gentleman_raw, 'THE', 'GENTLEMAN', 'xxxxx')\n",
    "taker = character_cleaner_by_name(taker_raw, 'THE', 'NOTE', 'TAKER')\n",
    "girl = character_cleaner_by_name(girl_raw, 'THE', 'FLOWER', 'GIRL')\n",
    "mrshiggins = character_cleaner_by_name(mrshiggins_raw, 'MRS', 'MRS.', 'HIGGINS')\n",
    "doolittle = character_cleaner_by_name(doolittle_raw, 'DOOLITTLE', 'xxxxxx', 'xxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same characters, just been joined afterwards due to computational convenience\n",
    "pickering = pickering + gentelman\n",
    "higgins = higgins + taker\n",
    "liza = liza + girl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygmalion_characters = {'Pickering':pickering, 'Higgins':higgins, 'Liza':liza, 'Mrs Higgins':mrshiggins, 'Doolittle':doolittle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickering contains 251 sentences and 1774 words\n",
      "Higgins contains 869 sentences and 7394 words\n",
      "Liza contains 495 sentences and 4820 words\n",
      "Mrs Higgins contains 178 sentences and 1466 words\n",
      "Doolittle contains 285 sentences and 2950 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(pygmalion_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pygmalion_characters['Mrs Higgins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pygmalion_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store pygmalion_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Androcles and the Lion - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aatl = paragraphs_cleaner(\"androcles_and_the_lion_shaw.txt\", normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aatl = token_paragraphs_aatl[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavinia_raw = []\n",
    "captain_raw = []\n",
    "androcles_raw = []\n",
    "megaera_raw = []\n",
    "centurion_raw = []\n",
    "spintho_raw = []\n",
    "ferrovius_raw = []\n",
    "for par in token_paragraphs_aatl:\n",
    "    if 'LAVINIA' in par:\n",
    "        lavinia_raw.append(par)\n",
    "    if 'CAPTAIN' in par:\n",
    "        captain_raw.append(par)\n",
    "    if 'ANDROCLES' in par:\n",
    "        androcles_raw.append(par)\n",
    "    if 'MEGAERA' in par:\n",
    "        megaera_raw.append(par)\n",
    "    if 'CENTURION' in par:\n",
    "        centurion_raw.append(par)\n",
    "    if 'SPINTHO' in par:\n",
    "        spintho_raw.append(par)\n",
    "    if 'FERROVIUS' in par:\n",
    "        ferrovius_raw.append(par)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavinia = character_cleaner_by_name(lavinia_raw, 'LAVINIA', 'xxxx', 'xxxx')\n",
    "captain = character_cleaner_by_name(captain_raw, 'CAPTAIN', 'xxxx', 'xxxx')\n",
    "androcles = character_cleaner_by_name(androcles_raw, 'ANDROCLES', 'xxxx', 'xxxx')\n",
    "megaera = character_cleaner_by_name(megaera_raw, 'MEGAERA', 'xxxx', 'xxxx')\n",
    "centurion = character_cleaner_by_name(centurion_raw, 'CENTURION', 'xxxx', 'xxxx')\n",
    "spintho = character_cleaner_by_name(spintho_raw, 'SPINTHO', 'xxxx', 'xxxx')\n",
    "ferrovius = character_cleaner_by_name(ferrovius_raw, 'FERROVIUS', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "androcles_and_the_lion_characters = {'Lavinia':lavinia, 'Captain':captain, 'Androcles':androcles, 'Megaera':megaera, 'Centurion':centurion, 'Spintho':spintho, 'Ferrovius':ferrovius}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lavinia contains 173 sentences and 1637 words\n",
      "Captain contains 155 sentences and 1548 words\n",
      "Androcles contains 219 sentences and 1864 words\n",
      "Megaera contains 68 sentences and 671 words\n",
      "Centurion contains 93 sentences and 590 words\n",
      "Spintho contains 57 sentences and 390 words\n",
      "Ferrovius contains 184 sentences and 1454 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(androcles_and_the_lion_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "del androcles_and_the_lion_characters['Megaera']\n",
    "del androcles_and_the_lion_characters['Centurion']\n",
    "del androcles_and_the_lion_characters['Spintho']\n",
    "del androcles_and_the_lion_characters['Ferrovius']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'androcles_and_the_lion_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store androcles_and_the_lion_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caesar and Cleopatra - George Bernard Shaw    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cac = paragraphs_cleaner(\"caesar_and_cleopatra_shaw.txt\", normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cac = token_paragraphs_cac[18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_raw = []\n",
    "cleopatra_raw = []\n",
    "pothinus_raw = []\n",
    "rufio_raw = []\n",
    "ftatateeta_raw =[]\n",
    "apollodorus_raw = []\n",
    "for par in token_paragraphs_cac:\n",
    "    if 'CAESAR' in par:\n",
    "        caesar_raw.append(par)\n",
    "    if 'CLEOPATRA' in par:\n",
    "        cleopatra_raw.append(par)\n",
    "    if 'POTHINUS' in par:\n",
    "        pothinus_raw.append(par)\n",
    "    if 'RUFIO' in par:\n",
    "        rufio_raw.append(par)\n",
    "    if 'FTATATEETA' in par:\n",
    "        ftatateeta_raw.append(par)\n",
    "    if 'APOLLODORUS' in par:\n",
    "        apollodorus_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar = character_cleaner_by_name(caesar_raw, 'CAESAR', 'xxxx', 'xxxx')\n",
    "cleopatra = character_cleaner_by_name(cleopatra_raw, 'CLEOPATRA', 'xxxx', 'xxxx')\n",
    "pothinus = character_cleaner_by_name(pothinus_raw, 'POTHINUS', 'xxxx', 'xxxx')\n",
    "rufio = character_cleaner_by_name(rufio_raw, 'RUFIO', 'xxxx', 'xxxx')\n",
    "ftatateeta = character_cleaner_by_name(ftatateeta_raw, 'FTATATEETA', 'xxxx', 'xxxx')\n",
    "apollodorus = character_cleaner_by_name(apollodorus_raw, 'APOLLODORUS', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_and_cleopatra_characters = {'Caesar':caesar, 'Cleopatra':cleopatra, 'Pothinus':pothinus, 'Rufio':rufio, 'Ftatateeta':ftatateeta, 'Apollodorus':apollodorus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar contains 756 sentences and 6016 words\n",
      "Cleopatra contains 554 sentences and 4494 words\n",
      "Pothinus contains 118 sentences and 1163 words\n",
      "Rufio contains 268 sentences and 2067 words\n",
      "Ftatateeta contains 110 sentences and 1012 words\n",
      "Apollodorus contains 188 sentences and 1653 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(caesar_and_cleopatra_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "del caesar_and_cleopatra_characters['Pothinus']\n",
    "del caesar_and_cleopatra_characters['Ftatateeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'caesar_and_cleopatra_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store caesar_and_cleopatra_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candida - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_can = paragraphs_cleaner(\"candida_shaw.txt\", normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_can = token_paragraphs_can[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "candida_raw = []\n",
    "marchbanks_raw =[]\n",
    "morell_raw = []\n",
    "burgess_raw = []\n",
    "proserpine_raw = []\n",
    "for par in token_paragraphs_can:\n",
    "    if 'CANDIDA' in par:\n",
    "        candida_raw.append(par)\n",
    "    if 'MARCHBANKS' in par:\n",
    "        marchbanks_raw.append(par)\n",
    "    if 'MORELL' in par:\n",
    "        morell_raw.append(par)\n",
    "    if 'BURGESS' in par:\n",
    "        burgess_raw.append(par)\n",
    "    if 'PROSERPINE' in par:\n",
    "        proserpine_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "candida = character_cleaner_by_name(candida_raw, 'CANDIDA', 'xxxx', 'xxxx')\n",
    "marchbanks = character_cleaner_by_name(marchbanks_raw, 'MARCHBANKS', 'xxxx', 'xxxx')\n",
    "morell = character_cleaner_by_name(morell_raw, 'MORELL', 'xxxx', 'xxxx')\n",
    "burgess = character_cleaner_by_name(burgess_raw, 'BURGESS', 'xxxx', 'xxxx')\n",
    "proserpine = character_cleaner_by_name(proserpine_raw, 'PROSERPINE', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "candida_characters = {'Candida':candida, 'Marchbanks':marchbanks, 'Morell':morell, 'Burgess':burgess, 'Proserpine':proserpine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candida contains 354 sentences and 3208 words\n",
      "Marchbanks contains 388 sentences and 3832 words\n",
      "Morell contains 443 sentences and 4022 words\n",
      "Burgess contains 238 sentences and 2237 words\n",
      "Proserpine contains 147 sentences and 1195 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(candida_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "del candida_characters['Proserpine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'candida_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store candida_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Man And Superman - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_mas = paragraphs_cleaner(\"man_and_superman_shaw.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_mas = token_paragraphs_mas[54:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsden_raw = []\n",
    "octavius_raw = []\n",
    "tanner_raw = []\n",
    "ann_raw = []\n",
    "whitefield_raw = []\n",
    "missramsden_raw = []\n",
    "violet_raw = []\n",
    "hector_raw = []\n",
    "straker_raw = []\n",
    "mendoza_raw = []\n",
    "juan_raw = []\n",
    "devil_raw = []\n",
    "ana_raw = []\n",
    "for par in token_paragraphs_mas:\n",
    "    if  'RAMSDEN' in par:\n",
    "         ramsden_raw.append(par)\n",
    "    if  'OCTAVIUS' in par:\n",
    "         octavius_raw.append(par)\n",
    "    if  'TANNER' in par:\n",
    "         tanner_raw.append(par)\n",
    "    if  'ANN' in par:\n",
    "         ann_raw.append(par)\n",
    "    if  'WHITEFIELD' in par and 'MRS' or 'MRS.' in par:\n",
    "         whitefield_raw.append(par)\n",
    "    if  'RAMSDEN' in par and 'MISS' in par:\n",
    "         missramsden_raw.append(par)\n",
    "    if  'VIOLET' in par:\n",
    "         violet_raw.append(par)\n",
    "    if  'HECTOR' in par:\n",
    "         hector_raw.append(par)\n",
    "    if  'STRAKER' in par:\n",
    "         straker_raw.append(par)\n",
    "    if  'MENDOZA' in par:\n",
    "         mendoza_raw.append(par)\n",
    "    if  'JUAN' in par:\n",
    "         juan_raw.append(par)\n",
    "    if  'DEVIL' in par:\n",
    "         devil_raw.append(par)\n",
    "    if  'ANA' in par:\n",
    "         ana_raw.append(par)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsden = character_cleaner_by_name(ramsden_raw, 'RAMSDEN', 'xxxx', 'xxxx')\n",
    "octavius = character_cleaner_by_name(octavius_raw, 'OCTAVIUS', 'xxxx', 'xxxx')\n",
    "tanner = character_cleaner_by_name(tanner_raw, 'TANNER', 'xxxx', 'xxxx')\n",
    "ann = character_cleaner_by_name(ann_raw, 'ANN', 'xxxx', 'xxxx')\n",
    "missramsden = character_cleaner_by_name(whitefield_raw, 'WHITEFIELD', 'MRS', 'MRS.')\n",
    "violet = character_cleaner_by_name(violet_raw, 'VIOLET', 'xxxx', 'xxxx')\n",
    "hector = character_cleaner_by_name(hector_raw, 'HECTOR', 'xxxx', 'xxxx')\n",
    "straker = character_cleaner_by_name(straker_raw, 'STRAKER', 'xxxx', 'xxxx')\n",
    "mendoza = character_cleaner_by_name(mendoza_raw, 'MENDOZA', 'xxxx', 'xxxx')\n",
    "juan = character_cleaner_by_name(juan_raw, 'JUAN', 'DON', 'xxxx')\n",
    "devil = character_cleaner_by_name(devil_raw, 'DEVIL', 'THE', 'xxxx')\n",
    "ana = character_cleaner_by_name(ana_raw, 'ANA', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_and_superman_characters = {'Ramsden':ramsden, 'Octavius':octavius, 'Tanner':tanner, 'Ann':ann, 'Miss Ramsden':missramsden, 'Violet':violet, 'Hector':hector, 'Straker':straker, 'Mendoza':mendoza, 'Don Juan':juan, 'The Devil':devil, 'Dona Ana':ana}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramsden contains 293 sentences and 2706 words\n",
      "Octavius contains 267 sentences and 2402 words\n",
      "Tanner contains 970 sentences and 10945 words\n",
      "Ann contains 419 sentences and 3675 words\n",
      "Miss Ramsden contains 97 sentences and 1056 words\n",
      "Violet contains 162 sentences and 1526 words\n",
      "Hector contains 128 sentences and 1258 words\n",
      "Straker contains 159 sentences and 1359 words\n",
      "Mendoza contains 192 sentences and 1943 words\n",
      "Don Juan contains 516 sentences and 8995 words\n",
      "The Devil contains 237 sentences and 3511 words\n",
      "Dona Ana contains 131 sentences and 1062 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(man_and_superman_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "del man_and_superman_characters['Miss Ramsden']\n",
    "del man_and_superman_characters['Hector']\n",
    "del man_and_superman_characters['Straker']\n",
    "del man_and_superman_characters['Dona Ana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'man_and_superman_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store man_and_superman_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyntia's Revels - Ben Jonson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cr = paragraphs_cleaner(\"cynthias_revels_jonson.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cr = token_paragraphs_cr[153:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercury_raw = []\n",
    "echo_raw = []\n",
    "cupid_raw = []\n",
    "amorphus_raw = []\n",
    "asotus_raw = []\n",
    "crites_raw = []\n",
    "anaides_raw = []\n",
    "hedon_raw = []\n",
    "arete_raw = []\n",
    "phantase_raw = []\n",
    "philautia_raw = []\n",
    "cyntia_raw = []\n",
    "for par in token_paragraphs_cr:\n",
    "    if  'MER' in par:\n",
    "         mercury_raw.append(par)\n",
    "    if  'ECHO' in par:\n",
    "         echo_raw.append(par)\n",
    "    if  'CUP' in par:\n",
    "         cupid_raw.append(par)\n",
    "    if  'AMO' in par:\n",
    "         amorphus_raw.append(par)\n",
    "    if  'ASO' in par:\n",
    "         asotus_raw.append(par)\n",
    "    if  'CRI' in par:\n",
    "         crites_raw.append(par)\n",
    "    if  'ANA' in par:\n",
    "         anaides_raw.append(par)\n",
    "    if  'HED' in par:\n",
    "         hedon_raw.append(par)\n",
    "    if  'ARE' in par:\n",
    "         arete_raw.append(par)\n",
    "    if  'PHA' in par:\n",
    "         phantase_raw.append(par)\n",
    "    if  'PHI' in par:\n",
    "         philautia_raw.append(par)\n",
    "    if  'CYN' in par:\n",
    "         cyntia_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercury = character_cleaner_by_name(mercury_raw, 'MER', 'xxxx', 'xxxx')\n",
    "echo = character_cleaner_by_name(echo_raw, 'ECHO', 'xxxx', 'xxxx')\n",
    "cupid = character_cleaner_by_name(cupid_raw, 'CUP', 'xxxx', 'xxxx')\n",
    "amorphus = character_cleaner_by_name(amorphus_raw, 'AMO', 'xxxx', 'xxxx')\n",
    "asotus = character_cleaner_by_name(asotus_raw, 'ASO', 'xxxx', 'xxxx')\n",
    "crites = character_cleaner_by_name(crites_raw, 'CRI', 'xxxx', 'xxxx')\n",
    "anaides = character_cleaner_by_name(anaides_raw, 'ANA', 'xxxx', 'xxxx')\n",
    "hedon = character_cleaner_by_name(hedon_raw, 'HED', 'xxxx', 'xxxx')\n",
    "arete = character_cleaner_by_name(arete_raw, 'ARE', 'xxxx', 'xxxx')\n",
    "phantase = character_cleaner_by_name(phantase_raw, 'PHA', 'xxxx', 'xxxx')\n",
    "philautia = character_cleaner_by_name(philautia_raw, 'PHI', 'xxxx', 'xxxx')\n",
    "cyntia = character_cleaner_by_name(cyntia_raw, 'CYN', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cynthias_revels_characters = {'Mercury':mercury, 'Echo':echo, 'Cupid':cupid, 'Amorphus':amorphus, 'Asotus':asotus, 'Crites':crites, 'Anaides':anaides, 'Hedon':hedon, 'Arete':arete, 'Phantase':phantase, 'Philautia':philautia, 'Cyntia':cyntia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercury contains 293 sentences and 4467 words\n",
      "Echo contains 22 sentences and 487 words\n",
      "Cupid contains 148 sentences and 2502 words\n",
      "Amorphus contains 389 sentences and 5878 words\n",
      "Asotus contains 216 sentences and 2257 words\n",
      "Crites contains 175 sentences and 4003 words\n",
      "Anaides contains 164 sentences and 1743 words\n",
      "Hedon contains 147 sentences and 1484 words\n",
      "Arete contains 37 sentences and 928 words\n",
      "Phantase contains 149 sentences and 1801 words\n",
      "Philautia contains 91 sentences and 984 words\n",
      "Cyntia contains 46 sentences and 1073 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(cynthias_revels_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cynthias_revels_characters['Echo']\n",
    "del cynthias_revels_characters['Hedon']\n",
    "del cynthias_revels_characters['Arete']\n",
    "del cynthias_revels_characters['Philautia']\n",
    "del cynthias_revels_characters['Cyntia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'cynthias_revels_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store cynthias_revels_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Every Man On His Humor - Ben Jonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_emohh = paragraphs_cleaner(\"every_man_on_his_humour_jonson.txt\", squared_braquets, squared_to_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_emohh = token_paragraphs_emohh[82:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "edknowell_raw = []\n",
    "stephen_raw = []\n",
    "mathew_raw = []\n",
    "cob_raw = []\n",
    "bobadill_raw = []\n",
    "tib_raw = []\n",
    "kitely_raw = []\n",
    "cash_raw = []\n",
    "downright_raw = []\n",
    "damekitely_raw = []\n",
    "brainworm_raw = []\n",
    "knowell_raw = []\n",
    "wellbred_raw = []\n",
    "for par in token_paragraphs_emohh:\n",
    "    if  'Know' in par and 'E.' in par[:1]:\n",
    "         edknowell_raw.append(par)\n",
    "    if  'Step' in par[:2]:\n",
    "         stephen_raw.append(par)\n",
    "    if  'Mat' in par[:2]:\n",
    "         mathew_raw.append(par)\n",
    "    if  'Cob' in par[:2]:\n",
    "         cob_raw.append(par)\n",
    "    if  'Bob' in par[:2]:\n",
    "         bobadill_raw.append(par)\n",
    "    if  'Tib' in par[:2]:\n",
    "         tib_raw.append(par)\n",
    "    if  'Kit' in par[:2]:\n",
    "         kitely_raw.append(par)\n",
    "    if  'Cash' in par[:2]:\n",
    "         cash_raw.append(par)\n",
    "    if  'Dow' in par[:2]:\n",
    "         downright_raw.append(par)\n",
    "    if  'Dame' in par[:2] and 'K.' in par[:3]:\n",
    "         damekitely_raw.append(par)\n",
    "    if  'Brai' in par[:2]:\n",
    "         brainworm_raw.append(par)\n",
    "    if  'Know' in par[:2] and not 'E.' in par:\n",
    "         knowell_raw.append(par)\n",
    "    if  'Wel' in par[:2]:\n",
    "         wellbred_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stephen = character_cleaner_by_name(stephen_raw, 'Step', 'xxxx', 'xxxx')\n",
    "edknowell = character_cleaner_by_name(edknowell_raw, 'E.', 'Know', 'xxxx')\n",
    "mathew = character_cleaner_by_name(mathew_raw, 'Mat', 'xxxx', 'xxxx')\n",
    "cob = character_cleaner_by_name(cob_raw, 'Cob', 'xxxx', 'xxxx')\n",
    "bobadill = character_cleaner_by_name(bobadill_raw, 'Bob', 'xxxx', 'xxxx')\n",
    "tib = character_cleaner_by_name(tib_raw, 'Tib', 'xxxx', 'xxxx')\n",
    "kitely = character_cleaner_by_name(kitely_raw, 'Kit', 'xxxx', 'xxxx')\n",
    "cash = character_cleaner_by_name(cash_raw, 'Cash', 'xxxx', 'xxxx')\n",
    "downright = character_cleaner_by_name(downright_raw, 'Dow', 'xxxx', 'xxxx')\n",
    "damekitely = character_cleaner_by_name(damekitely_raw, 'Dame', 'K', 'xxxx')\n",
    "brainworm = character_cleaner_by_name(brainworm_raw, 'Brai', 'xxxx', 'xxxx')\n",
    "knowell = character_cleaner_by_name(knowell_raw, 'Know', 'xxxx', 'xxxx')\n",
    "wellbred = character_cleaner_by_name(wellbred_raw, 'Wel', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_man_on_his_humour_characters = {'Stephen':stephen, 'Ed Knowell':edknowell, 'Mathew':mathew, 'Cob':cob, 'Bobadill':bobadill, 'Tib':tib, 'Kitely':kitely, 'Cash':cash, 'Downright':downright, 'Dame Kitely':damekitely, 'Brainworm':brainworm, 'Knowell':knowell, 'Wellbred':wellbred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stephen contains 170 sentences and 1753 words\n",
      "Ed Knowell contains 186 sentences and 2064 words\n",
      "Mathew contains 142 sentences and 1486 words\n",
      "Cob contains 148 sentences and 1987 words\n",
      "Bobadill contains 195 sentences and 3122 words\n",
      "Tib contains 31 sentences and 230 words\n",
      "Kitely contains 268 sentences and 3620 words\n",
      "Cash contains 75 sentences and 646 words\n",
      "Downright contains 107 sentences and 1152 words\n",
      "Dame Kitely contains 54 sentences and 560 words\n",
      "Brainworm contains 171 sentences and 2998 words\n",
      "Knowell contains 133 sentences and 2121 words\n",
      "Wellbred contains 145 sentences and 1718 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(every_man_on_his_humour_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "del every_man_on_his_humour_characters['Mathew']\n",
    "del every_man_on_his_humour_characters['Tib']\n",
    "del every_man_on_his_humour_characters['Cash']\n",
    "del every_man_on_his_humour_characters['Downright']\n",
    "del every_man_on_his_humour_characters['Dame Kitely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'every_man_on_his_humour_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store every_man_on_his_humour_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volpone, Or The Fox - Ben jonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_votf = paragraphs_cleaner(\"volpone_or_the_fox_jonson.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_votf = token_paragraphs_votf[110:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "volpone_raw = []\n",
    "mosca_raw = []\n",
    "nano_raw = []\n",
    "androgyno_raw = []\n",
    "voltore_raw = []\n",
    "corbaccio_raw = []\n",
    "corvino_raw = []\n",
    "peregrine_raw = []\n",
    "sirpolitick_raw = []\n",
    "bonario_raw = []\n",
    "ladywouldbe_raw = []\n",
    "for par in token_paragraphs_votf:\n",
    "    if  'VOLP' in par:\n",
    "         volpone_raw.append(par)\n",
    "    if  'MOS' in par:\n",
    "         mosca_raw.append(par)\n",
    "    if  'NAN' in par:\n",
    "         nano_raw.append(par)\n",
    "    if  'AND' in par and ':' in par[0:2]:\n",
    "         androgyno_raw.append(par)\n",
    "    if  'VOLT' in par:\n",
    "         voltore_raw.append(par)\n",
    "    if  'CORB' in par:\n",
    "         corbaccio_raw.append(par)\n",
    "    if  'CORV' in par:\n",
    "         corvino_raw.append(par)\n",
    "    if  'PER' in par:\n",
    "         peregrine_raw.append(par)\n",
    "    if  'SIR' in par and 'P' in par:\n",
    "         sirpolitick_raw.append(par)\n",
    "    if  'BON' in par:\n",
    "         bonario_raw.append(par)\n",
    "    if  'LADY' in par and 'P' in par:\n",
    "         ladywouldbe_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "volpone = character_cleaner(volpone_raw, 1)\n",
    "mosca = character_cleaner(mosca_raw, 2)\n",
    "nano = character_cleaner(nano_raw, 2)\n",
    "androgyno = character_cleaner(androgyno_raw, 2)\n",
    "voltore = character_cleaner(voltore_raw, 2)\n",
    "corbaccio = character_cleaner(corbaccio_raw, 2)\n",
    "corvino = character_cleaner(corvino_raw, 2)\n",
    "peregrine = character_cleaner(peregrine_raw, 2)\n",
    "sirpolitick = character_cleaner(sirpolitick_raw, 3)\n",
    "bonario = character_cleaner(bonario_raw, 2)\n",
    "ladywouldbe = character_cleaner(ladywouldbe_raw, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "volpone_or_the_fox_characters = {'Volpone':volpone, 'Mosca':mosca, 'Nano':nano, 'Androgyno':androgyno, 'Voltore':voltore, 'Corbaccio':corbaccio, 'Peregrine':peregrine, 'Sir Politick': sirpolitick, 'Bonario':bonario, 'Lady Would-be':ladywouldbe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volpone contains 444 sentences and 6690 words\n",
      "Mosca contains 498 sentences and 6904 words\n",
      "Nano contains 33 sentences and 670 words\n",
      "Androgyno contains 12 sentences and 143 words\n",
      "Voltore contains 113 sentences and 1486 words\n",
      "Corbaccio contains 136 sentences and 733 words\n",
      "Peregrine contains 148 sentences and 1322 words\n",
      "Sir Politick contains 148 sentences and 2335 words\n",
      "Bonario contains 38 sentences and 369 words\n",
      "Lady Would-be contains 108 sentences and 1428 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(volpone_or_the_fox_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "del volpone_or_the_fox_characters['Nano']\n",
    "del volpone_or_the_fox_characters['Androgyno']\n",
    "del volpone_or_the_fox_characters['Voltore']\n",
    "del volpone_or_the_fox_characters['Corbaccio']\n",
    "del volpone_or_the_fox_characters['Peregrine']\n",
    "del volpone_or_the_fox_characters['Bonario']\n",
    "del volpone_or_the_fox_characters['Lady Would-be']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'volpone_or_the_fox_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store volpone_or_the_fox_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Alchemist - Ben Jonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_ta = paragraphs_cleaner(\"the_alchemist_jonson.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_ta = token_paragraphs_ta[97:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_raw = []\n",
    "subtle_raw = []\n",
    "dol_raw = []\n",
    "dapper_raw = []\n",
    "drugger_raw = []\n",
    "mammon_raw = []\n",
    "surly_raw = []\n",
    "ananias_raw = []\n",
    "tribulation_raw = []\n",
    "kastril_raw = []\n",
    "for par in token_paragraphs_ta:\n",
    "    if  'FACE' in par:\n",
    "         face_raw.append(par)\n",
    "    if  'SUB' in par:\n",
    "         subtle_raw.append(par)\n",
    "    if  'DOL' in par:\n",
    "         dol_raw.append(par)\n",
    "    if  'DAP' in par:\n",
    "         dapper_raw.append(par)\n",
    "    if  'DRUG' in par:\n",
    "         drugger_raw.append(par)\n",
    "    if  'MAM' in par:\n",
    "         mammon_raw.append(par)\n",
    "    if  'SUR' in par:\n",
    "         surly_raw.append(par)\n",
    "    if  'ANA' in par:\n",
    "         ananias_raw.append(par)\n",
    "    if  'TRI' in par:\n",
    "         tribulation_raw.append(par)\n",
    "    if  'KAS' in par:\n",
    "         kastril_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = character_cleaner(face_raw, 2)\n",
    "subtle = character_cleaner(subtle_raw, 2)\n",
    "dol = character_cleaner(dol_raw, 2)\n",
    "dapper = character_cleaner(dapper_raw, 2)\n",
    "drugger = character_cleaner(drugger_raw, 2)\n",
    "mammon = character_cleaner(mammon_raw, 2)\n",
    "surly = character_cleaner(surly_raw, 2)\n",
    "ananias = character_cleaner(ananias_raw, 2)\n",
    "tribulation = character_cleaner(tribulation_raw, 2)\n",
    "kastril = character_cleaner(kastril_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_alchemist_characters = {'Face':face, 'Subtle':subtle, 'Dol':dol, 'Dapper':dapper, 'Drugger':drugger, 'Mammon':mammon, 'Surly': surly, 'Ananias':ananias, 'Tribulation':tribulation, 'Kastril':kastril}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face contains 814 sentences and 8561 words\n",
      "Subtle contains 669 sentences and 7226 words\n",
      "Dol contains 143 sentences and 1464 words\n",
      "Dapper contains 86 sentences and 573 words\n",
      "Drugger contains 44 sentences and 589 words\n",
      "Mammon contains 276 sentences and 3410 words\n",
      "Surly contains 139 sentences and 1568 words\n",
      "Ananias contains 64 sentences and 749 words\n",
      "Tribulation contains 45 sentences and 631 words\n",
      "Kastril contains 110 sentences and 860 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(the_alchemist_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "del the_alchemist_characters['Dol']\n",
    "del the_alchemist_characters['Dapper']\n",
    "del the_alchemist_characters['Drugger']\n",
    "del the_alchemist_characters['Ananias']\n",
    "del the_alchemist_characters['Tribulation']\n",
    "del the_alchemist_characters['Kastril']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'the_alchemist_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store the_alchemist_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macbeth - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_m = paragraphs_cleaner(\"macbeth_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the structural configuration of the file, the split has been made by simple slicing.\n",
    "macbeth_raw = token_paragraphs_m[:440]\n",
    "banquo_raw = token_paragraphs_m[440:541]\n",
    "malcom_raw = token_paragraphs_m[541:663]\n",
    "ladymacbeth_raw = token_paragraphs_m[663:842]\n",
    "macduff_raw = token_paragraphs_m[842:1021]\n",
    "ross_raw = token_paragraphs_m[1021:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth = speech_filter(macbeth_raw)\n",
    "banquo = speech_filter(banquo_raw)\n",
    "malcom = speech_filter(malcom_raw)\n",
    "ladymacbeth = speech_filter(ladymacbeth_raw)\n",
    "macduff = speech_filter(macduff_raw)\n",
    "ross = speech_filter(ross_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_characters = {'Macbeth':macbeth, 'Banquo':banquo, 'Malcom':malcom, 'Lady Macbeth':ladymacbeth, 'Macduff': macduff, 'Ross':ross}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macbeth contains 350 sentences and 5515 words\n",
      "Banquo contains 61 sentences and 805 words\n",
      "Malcom contains 73 sentences and 1543 words\n",
      "Lady Macbeth contains 135 sentences and 1965 words\n",
      "Macduff contains 109 sentences and 1209 words\n",
      "Ross contains 55 sentences and 946 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(macbeth_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "del macbeth_characters['Banquo']\n",
    "del macbeth_characters['Macduff']\n",
    "del macbeth_characters['Ross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'macbeth_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store macbeth_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Romeo And Juliet - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_raj = paragraphs_cleaner(\"romeo_and_juliet_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_raw = token_paragraphs_raj[:492]\n",
    "juliet_raw = token_paragraphs_raj[492:848]\n",
    "benvolio_raw = token_paragraphs_raj[848:1042]\n",
    "mercutio_raw = token_paragraphs_raj[1042:1230]\n",
    "nurse_raw = token_paragraphs_raj[1230:1502]\n",
    "capulet_raw = token_paragraphs_raj[1502:1657]\n",
    "ladycapulet_raw = token_paragraphs_raj[1657:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo = speech_filter(romeo_raw)\n",
    "juliet = speech_filter(juliet_raw)\n",
    "benvolio = speech_filter(benvolio_raw)\n",
    "mercutio = speech_filter(mercutio_raw)\n",
    "nurse = speech_filter(nurse_raw)\n",
    "capulet = speech_filter(capulet_raw)\n",
    "ladycapulet = speech_filter(ladycapulet_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet_characters = {'Romeo':romeo, 'Juliet':juliet, 'Benvolio': benvolio, 'Nurse':nurse, 'Capulet':capulet, 'Lady Capulet':ladycapulet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo contains 335 sentences and 4839 words\n",
      "Juliet contains 298 sentences and 4414 words\n",
      "Benvolio contains 77 sentences and 1190 words\n",
      "Nurse contains 213 sentences and 2300 words\n",
      "Capulet contains 168 sentences and 2237 words\n",
      "Lady Capulet contains 76 sentences and 907 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(romeo_and_juliet_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "del romeo_and_juliet_characters['Benvolio']\n",
    "del romeo_and_juliet_characters['Lady Capulet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'romeo_and_juliet_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store romeo_and_juliet_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Othello - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_o = paragraphs_cleaner(\"othello_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello_raw = token_paragraphs_o[:825]\n",
    "roderigo_raw = token_paragraphs_o[825:1004]\n",
    "iago_raw = token_paragraphs_o[1004:1822]\n",
    "cassio_raw = token_paragraphs_o[1822:2154]\n",
    "desdemona_raw = token_paragraphs_o[2154:2651]\n",
    "emilia_raw = token_paragraphs_o[2651:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello = speech_filter(othello_raw)\n",
    "roderigo = speech_filter(roderigo_raw)\n",
    "iago = speech_filter(iago_raw)\n",
    "cassio = speech_filter(cassio_raw)\n",
    "desdemona = speech_filter(desdemona_raw)\n",
    "emilia = speech_filter(emilia_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello_characters = {'Othello':othello, 'Roderigo':roderigo, 'Iago':iago, 'Cassio':cassio, 'Desdemona':desdemona, 'Emilia':emilia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Othello contains 539 sentences and 6473 words\n",
      "Roderigo contains 76 sentences and 881 words\n",
      "Iago contains 560 sentences and 8623 words\n",
      "Cassio contains 178 sentences and 2013 words\n",
      "Desdemona contains 238 sentences and 2830 words\n",
      "Emilia contains 178 sentences and 1865 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(othello_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "del othello_characters['Roderigo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'othello_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store othello_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamlet - William Sahakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_h =  paragraphs_cleaner(\"hamlet_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_raw = token_paragraphs_h[:500] + token_paragraphs_h[500:1077]\n",
    "ophelia_raw = token_paragraphs_h[1077:1253]\n",
    "polonius_raw = token_paragraphs_h[1253:1513]\n",
    "claudius_raw = token_paragraphs_h[1513:1821]\n",
    "horatio_raw = token_paragraphs_h[1821:2150]\n",
    "laertes_raw = token_paragraphs_h[2150:2338]\n",
    "gertrude_raw = token_paragraphs_h[2338:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = speech_filter(hamlet_raw)\n",
    "ophelia = speech_filter(ophelia_raw)\n",
    "polonius = speech_filter(polonius_raw)\n",
    "claudius = speech_filter(claudius_raw)\n",
    "horatio = speech_filter(horatio_raw)\n",
    "laertes = speech_filter(laertes_raw)\n",
    "gertrude = speech_filter(gertrude_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_characters = {'Hamlet':hamlet, 'Ophelia':ophelia, 'Polonius': polonius, 'Claudius': claudius, 'Horatio': horatio, 'Laertes': laertes, 'Gertrude':gertrude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet contains 1020 sentences and 12233 words\n",
      "Ophelia contains 106 sentences and 1261 words\n",
      "Polonius contains 218 sentences and 2750 words\n",
      "Claudius contains 299 sentences and 4234 words\n",
      "Horatio contains 184 sentences and 2127 words\n",
      "Laertes contains 131 sentences and 1493 words\n",
      "Gertrude contains 107 sentences and 1091 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(hamlet_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hamlet_characters['Ophelia']\n",
    "del hamlet_characters['Laertes']\n",
    "del hamlet_characters['Gertrude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'hamlet_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store hamlet_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### King Lear - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_kl = paragraphs_cleaner(\"king_lear_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "goneril_raw = token_paragraphs_kl[:161]\n",
    "edmund_raw = token_paragraphs_kl[161:400]\n",
    "regan_raw = token_paragraphs_kl[400:621]\n",
    "lear_raw = token_paragraphs_kl[621:1187]\n",
    "fool_raw = token_paragraphs_kl[1187:1363]\n",
    "earlofkent_raw = token_paragraphs_kl[1363:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "goneril = speech_filter(goneril_raw)\n",
    "edmund = speech_filter(edmund_raw)\n",
    "regan = speech_filter(regan_raw)\n",
    "lear = speech_filter(lear_raw)\n",
    "fool = speech_filter(fool_raw)\n",
    "earlofkent = speech_filter(earlofkent_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_lear_characters = {'Goneril':goneril, 'Edmund':edmund, 'Regan':regan,'Lear': lear, 'Fool': fool, 'Earl Of Kent':earlofkent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goneril contains 128 sentences and 1514 words\n",
      "Edmund contains 208 sentences and 2441 words\n",
      "Regan contains 146 sentences and 1460 words\n",
      "Lear contains 645 sentences and 5875 words\n",
      "Fool contains 131 sentences and 1827 words\n",
      "Earl Of Kent contains 237 sentences and 2708 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(king_lear_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "del king_lear_characters['Regan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'king_lear_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store king_lear_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## German Plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kabale und Liebe - Friedrich Schiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_kul = paragraphs_cleaner('kabale_und_liebe_schiller.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_kul = token_paragraphs_kul[22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "prsident_raw = []\n",
    "ferdinand_raw = []\n",
    "hofmarschall_raw = []\n",
    "ladymilford_raw = []\n",
    "wurm_raw = []\n",
    "miller_raw = []\n",
    "frau_raw = []\n",
    "luise_raw = []\n",
    "sophie_raw = []\n",
    "for par in token_paragraphs_kul:\n",
    "    if  'Prsident' in par[:1] and '.' in par[:2]:\n",
    "         prsident_raw.append(par)\n",
    "    if  'Ferdinand' in par[:1] and '.' in par[:2]:\n",
    "         ferdinand_raw.append(par)\n",
    "    if  'Hofmarschall' in par[:1] and '.' in par[:2]:\n",
    "         hofmarschall_raw.append(par)\n",
    "    if  'Lady' in par[:1] and '.' in par [:2]:\n",
    "         ladymilford_raw.append(par)\n",
    "    if  'Wurm' in par[:1] and '.' in par[:2]:\n",
    "         wurm_raw.append(par)\n",
    "    if  'Miller' in par[:1] and '.' in par[:2]:\n",
    "         miller_raw.append(par)\n",
    "    if  'Frau' in par[:1] and '.' in par[:2]:\n",
    "         frau_raw.append(par)\n",
    "    if  'Luise' in par[:1] and '.' in par[:2]:\n",
    "         luise_raw.append(par)\n",
    "    if  'Sophie' in par[:1] and '.' in par[:2]:\n",
    "         sophie_raw.append(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "prsident = character_cleaner(prsident_raw, 2)\n",
    "ferdinand = character_cleaner(ferdinand_raw, 2)\n",
    "hofmarschall = character_cleaner(hofmarschall_raw, 2)\n",
    "ladymilford = character_cleaner(ladymilford_raw, 2)\n",
    "wurm = character_cleaner(wurm_raw, 2)\n",
    "miller = character_cleaner(miller_raw, 2)\n",
    "frau = character_cleaner(frau_raw, 2)\n",
    "luise = character_cleaner(luise_raw, 2)\n",
    "sophie = character_cleaner(sophie_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "kabale_und_liebe_characters = {'Prsident':prsident, 'Ferdinand':ferdinand, 'Hofmarschall':hofmarschall, 'Lady Milford':ladymilford, 'Wurm':wurm, 'Miller':miller, 'Frau':frau, 'Luise':luise, 'Sophie':sophie}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prsident contains 307 sentences and 2716 words\n",
      "Ferdinand contains 607 sentences and 5730 words\n",
      "Hofmarschall contains 155 sentences and 1132 words\n",
      "Lady Milford contains 271 sentences and 3418 words\n",
      "Wurm contains 206 sentences and 2221 words\n",
      "Miller contains 389 sentences and 3586 words\n",
      "Frau contains 78 sentences and 633 words\n",
      "Luise contains 537 sentences and 4756 words\n",
      "Sophie contains 36 sentences and 356 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(kabale_und_liebe_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kabale_und_liebe_characters['Hofmarschall']\n",
    "del kabale_und_liebe_characters['Frau']\n",
    "del kabale_und_liebe_characters['Sophie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kabale_und_liebe_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store kabale_und_liebe_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Verschwoerung des Fiesco zu Genua - Friedrich Schiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_dvdfzg = paragraphs_cleaner('die_verschwoerung_des_fiesco_zu_genua_schiller.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_dvdfzg = token_paragraphs_dvdfzg[48:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "andreas_raw = []\n",
    "gianettino_raw = []\n",
    "fiesco_raw = []\n",
    "verrina_raw = []\n",
    "bourgognino_raw = []\n",
    "calcagno_raw = []\n",
    "sacco_raw = []\n",
    "lomellin_raw = []\n",
    "mohr_raw = []\n",
    "for par in token_paragraphs_dvdfzg:\n",
    "    if  'Andreas' in par[:1] and '.' in par[:2]:\n",
    "         andreas_raw.append(par)\n",
    "    if  'Gianettino' in par[:1] and '.' in par[:2]:\n",
    "         gianettino_raw.append(par)\n",
    "    if  'Fiesco' in par[:1] and '.' in par[:2]:\n",
    "         fiesco_raw.append(par)\n",
    "    if  'Verrina' in par[:1] and '.' in par [:2]:\n",
    "         verrina_raw.append(par)\n",
    "    if  'Bourgognino' in par[:1] and '.' in par[:2]:\n",
    "         bourgognino_raw.append(par)\n",
    "    if  'Calcagno' in par[:1] and '.' in par[:2]:\n",
    "         calcagno_raw.append(par)\n",
    "    if  'Sacco' in par[:1] and '.' in par[:2]:\n",
    "         sacco_raw.append(par)\n",
    "    if  'Lomellin' in par[:1] and '.' in par[:2]:\n",
    "         lomellin_raw.append(par)\n",
    "    if  'Mohr' in par[:1] and '.' in par[:2]:\n",
    "         mohr_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "andreas = character_cleaner(andreas_raw, 2)\n",
    "gianettino = character_cleaner(gianettino_raw, 2)\n",
    "fiesco = character_cleaner(fiesco_raw, 2)\n",
    "verrina = character_cleaner(verrina_raw, 2)\n",
    "bourgognino = character_cleaner(bourgognino_raw, 2)\n",
    "calcagno = character_cleaner(calcagno_raw, 2)\n",
    "sacco = character_cleaner(sacco_raw, 2)\n",
    "lomellin  = character_cleaner(lomellin_raw, 2)\n",
    "mohr = character_cleaner(mohr_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "die_verschwoerung_des_fiesco_zu_genua_characters = {'Andreas':andreas, 'Gianettino':gianettino, 'Fiesco':fiesco, 'Verrina':verrina, 'Bourgognino':bourgognino, 'Clacagno':calcagno, 'Sacco':sacco, 'Lomellon':lomellin, 'Mohr':mohr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andreas contains 68 sentences and 569 words\n",
      "Gianettino contains 172 sentences and 1251 words\n",
      "Fiesco contains 916 sentences and 7307 words\n",
      "Verrina contains 307 sentences and 2575 words\n",
      "Bourgognino contains 135 sentences and 843 words\n",
      "Clacagno contains 145 sentences and 1186 words\n",
      "Sacco contains 57 sentences and 484 words\n",
      "Lomellon contains 99 sentences and 713 words\n",
      "Mohr contains 260 sentences and 2057 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(die_verschwoerung_des_fiesco_zu_genua_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "del die_verschwoerung_des_fiesco_zu_genua_characters['Andreas']\n",
    "del die_verschwoerung_des_fiesco_zu_genua_characters['Gianettino']\n",
    "del die_verschwoerung_des_fiesco_zu_genua_characters['Bourgognino']\n",
    "del die_verschwoerung_des_fiesco_zu_genua_characters['Clacagno']\n",
    "del die_verschwoerung_des_fiesco_zu_genua_characters['Sacco']\n",
    "del die_verschwoerung_des_fiesco_zu_genua_characters['Lomellon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'die_verschwoerung_des_fiesco_zu_genua_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store die_verschwoerung_des_fiesco_zu_genua_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Ruber - Friedrich Schiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_dr = paragraphs_cleaner('die_ruber_schiller.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_dr = token_paragraphs_dr[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "karl_raw = []\n",
    "franz_raw = []\n",
    "amalia_raw = []\n",
    "spiegelberg_raw = []\n",
    "schweizer_raw = []\n",
    "grimm_raw = []\n",
    "razmann_raw = []\n",
    "schufterle_raw = []\n",
    "roller_raw = []\n",
    "kosisnsky_raw = []\n",
    "schwarz_raw = []\n",
    "moor_raw = []\n",
    "for par in token_paragraphs_dr:\n",
    "    if  '~Franz~' in par or '~Franz.~' in par:\n",
    "         franz_raw.append(par)\n",
    "    if  '~Amalia~' in par or '~Amalia.~' in par:\n",
    "         amalia_raw.append(par)\n",
    "    if  '~Spiegelberg~' in par or '~Spiegelberg.~' in par:\n",
    "         spiegelberg_raw.append(par)\n",
    "    if  '~Schweizer~' in par or '~Schweizer.~' in par:\n",
    "         schweizer_raw.append(par)\n",
    "    if  '~Grimm~' in par or '~Grimm.~' in par:\n",
    "         grimm_raw.append(par)\n",
    "    if  '~Razmann~' in par or '~Razmann.~' in par:\n",
    "         razmann_raw.append(par)\n",
    "    if  '~Schufterle~' in par or '~Schufterle.~' in par:\n",
    "         schufterle_raw.append(par)\n",
    "    if  '~Roller~' in par or '~Roller.~' in par:\n",
    "         roller_raw.append(par)\n",
    "    if  '~Kosinsky~' in par or '~Kosinsky.~' in par:\n",
    "         kosisnsky_raw.append(par)\n",
    "    if  '~Schwarz~' in par or '~Schwarz.~' in par:\n",
    "         schwarz_raw.append(par)\n",
    "    if  '~Moor~' in par or '~Moor.~' in par:\n",
    "         moor_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "franz = character_cleaner(franz_raw, 1)\n",
    "amalia = character_cleaner(amalia_raw, 1)\n",
    "spiegelberg = character_cleaner(spiegelberg_raw, 1)\n",
    "schweizer = character_cleaner(schweizer_raw, 1)\n",
    "grimm = character_cleaner(grimm_raw, 1)\n",
    "razmann = character_cleaner(razmann_raw, 1)\n",
    "schufterle = character_cleaner(schufterle_raw, 1)\n",
    "roller = character_cleaner(roller_raw, 1)\n",
    "kosisnsky = character_cleaner(kosisnsky_raw, 1)\n",
    "schwarz = character_cleaner(schwarz_raw, 1)\n",
    "moor = character_cleaner(moor_raw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "die_ruber_characters = { 'Franz': franz, 'Amalia':amalia, 'Spiegelberg':spiegelberg, 'Schweizer':schweizer, 'Grimm':grimm, 'Razmann':razmann, 'Schufterle':schufterle, 'Roller':roller, 'Kosisnky':kosisnsky, 'Schwartz':schwarz, 'Moor':moor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franz contains 670 sentences and 7937 words\n",
      "Amalia contains 269 sentences and 2183 words\n",
      "Spiegelberg contains 269 sentences and 3863 words\n",
      "Schweizer contains 166 sentences and 1550 words\n",
      "Grimm contains 50 sentences and 291 words\n",
      "Razmann contains 91 sentences and 867 words\n",
      "Schufterle contains 21 sentences and 303 words\n",
      "Roller contains 82 sentences and 877 words\n",
      "Kosisnky contains 69 sentences and 960 words\n",
      "Schwartz contains 73 sentences and 548 words\n",
      "Moor contains 621 sentences and 6569 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(die_ruber_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "del die_ruber_characters['Grimm']\n",
    "del die_ruber_characters['Razmann']\n",
    "del die_ruber_characters['Schufterle']\n",
    "del die_ruber_characters['Roller']\n",
    "del die_ruber_characters['Kosisnky']\n",
    "del die_ruber_characters['Schwartz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'die_ruber_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store die_ruber_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Jungfrau von Orleans - Friedrich Schiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_djvo = paragraphs_cleaner('die_jungfrau_von_orleans_schiller.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_djvo = token_paragraphs_djvo[84:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "karl_raw = []\n",
    "lahire_raw = []\n",
    "duchatel_raw = []\n",
    "dunois_raw = []\n",
    "johanna_raw = []\n",
    "talbot_raw = []\n",
    "lionel_raw = []\n",
    "burgund_raw = []\n",
    "raimund_raw = []\n",
    "sorel_raw = []\n",
    "for par in token_paragraphs_djvo:\n",
    "    if  'KARL' in par:\n",
    "         karl_raw.append(par)\n",
    "    if  'LA' in par:\n",
    "         lahire_raw.append(par)\n",
    "    if  'CHATEL' in par:\n",
    "         duchatel_raw.append(par)\n",
    "    if  'DUNOIS' in par:\n",
    "         dunois_raw.append(par)\n",
    "    if  'JOHANNA' in par:\n",
    "         johanna_raw.append(par)\n",
    "    if  'TALBOT' in par:\n",
    "         talbot_raw.append(par)\n",
    "    if  'LIONEL' in par:\n",
    "         lionel_raw.append(par)\n",
    "    if  'BURGUND' in par:\n",
    "         burgund_raw.append(par)\n",
    "    if  'RAIMOND' in par:\n",
    "         raimund_raw.append(par)\n",
    "    if  'SOREL' in par:\n",
    "         sorel_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "karl = character_cleaner(karl_raw, 2)\n",
    "lahire = character_cleaner(lahire_raw, 3)\n",
    "dunois = character_cleaner(dunois_raw, 2)\n",
    "johanna = character_cleaner(johanna_raw, 2)\n",
    "lionel = character_cleaner(lionel_raw, 2)\n",
    "burgund = character_cleaner(burgund_raw, 2)\n",
    "sorel = character_cleaner(sorel_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "die_jungfrau_von_orleans_characters = {'Karl':karl, 'La Hire':lahire, 'Dunois':dunois, 'Johanna':johanna, 'Lionel':lionel, 'Burgund':burgund, 'Sorel':sorel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karl contains 249 sentences and 2556 words\n",
      "La Hire contains 72 sentences and 794 words\n",
      "Dunois contains 160 sentences and 1787 words\n",
      "Johanna contains 474 sentences and 5687 words\n",
      "Lionel contains 105 sentences and 914 words\n",
      "Burgund contains 133 sentences and 1179 words\n",
      "Sorel contains 120 sentences and 1343 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(die_jungfrau_von_orleans_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "del die_jungfrau_von_orleans_characters['La Hire']\n",
    "del die_jungfrau_von_orleans_characters['Lionel']\n",
    "del die_jungfrau_von_orleans_characters['Burgund']\n",
    "del die_jungfrau_von_orleans_characters['Sorel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'die_jungfrau_von_orleans_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store die_jungfrau_von_orleans_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faust I - Johann Wolfgang von Goethe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_f1 = paragraphs_cleaner('faust_1_goethe.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_f1 = token_paragraphs_f1[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "faust_raw = []\n",
    "mephistopheles_raw = []\n",
    "margarete_raw = []\n",
    "diehexe_raw = []\n",
    "marthe_raw = []\n",
    "wagner_raw = []\n",
    "for par in token_paragraphs_f1:\n",
    "    if  'FAUST' in par:\n",
    "         faust_raw.append(par)\n",
    "    if  'MEPHISTOPHELES' in par:\n",
    "         mephistopheles_raw.append(par)\n",
    "    if  'MARGARETE' in par:\n",
    "         margarete_raw.append(par)\n",
    "    if  'DIE' in par:\n",
    "         diehexe_raw.append(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "faust = character_cleaner(faust_raw, 2)\n",
    "mephistopheles = character_cleaner(mephistopheles_raw, 2)\n",
    "margarete = character_cleaner(margarete_raw, 2)\n",
    "diehexe = character_cleaner(diehexe_raw, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "faust_1_characters = {'Faust':faust, 'Mephistopheles':mephistopheles, 'Margarete':margarete, 'Die Hexe':diehexe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faust contains 784 sentences and 8550 words\n",
      "Mephistopheles contains 703 sentences and 7973 words\n",
      "Margarete contains 234 sentences and 2041 words\n",
      "Die Hexe contains 59 sentences and 462 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(faust_1_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "del faust_1_characters['Die Hexe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'faust_1_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store faust_1_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faust II - Johann Wolfgang von Goethe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_f2 = paragraphs_cleaner('faust_2_goethe.txt', nothing, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_f2 = token_paragraphs_f2[45:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "mephistopheles2_raw = []\n",
    "kaiser_raw = []\n",
    "kanzler_raw = []\n",
    "gemurmel_raw = []\n",
    "herold_raw = []\n",
    "plutus_raw = []\n",
    "heermeister_raw = []\n",
    "marshalk_raw = []\n",
    "faust2_raw = []\n",
    "homunculus_raw = []\n",
    "phorkyas_raw = []\n",
    "sirenen_raw = []\n",
    "helena_raw = []\n",
    "for par in token_paragraphs_f2:\n",
    "    if  'MEPHISTOPHELES' in par:\n",
    "         mephistopheles2_raw.append(par)\n",
    "    if  'KAISER' in par:\n",
    "         kaiser_raw.append(par)\n",
    "    if  'KANZLER' in par:\n",
    "         kanzler_raw.append(par)\n",
    "    if  'GEMURMEL' in par:\n",
    "         gemurmel_raw.append(par)\n",
    "    if  'HEROLD' in par:\n",
    "         herold_raw.append(par)\n",
    "    if  'PLUTUS' in par:\n",
    "         plutus_raw.append(par)\n",
    "    if  'HEERMEISTER' in par:\n",
    "         heermeister_raw.append(par)\n",
    "    if  'MARSCHALK' in par:\n",
    "         marshalk_raw.append(par)\n",
    "    if  'FAUST' in par:\n",
    "         faust2_raw.append(par)\n",
    "    if  'HOMUNCULUS' in par:\n",
    "         homunculus_raw.append(par)\n",
    "    if  'PHORKYAS' in par:\n",
    "         phorkyas_raw.append(par)\n",
    "    if  'SIRENEN' in par:\n",
    "         sirenen_raw.append(par)\n",
    "    if  'HELENA' in par:\n",
    "         helena_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "mephistopheles2 = character_cleaner(mephistopheles2_raw, 2) \n",
    "kaiser = character_cleaner(kaiser_raw, 2)\n",
    "kanzler = character_cleaner(kanzler_raw, 2)\n",
    "gemurmel = character_cleaner(gemurmel_raw, 2)\n",
    "herold = character_cleaner(herold_raw, 2)\n",
    "plutus = character_cleaner(plutus_raw, 2)\n",
    "heermeister = character_cleaner(heermeister_raw, 2)\n",
    "marshalk = character_cleaner(marshalk_raw, 2)\n",
    "faust2 = character_cleaner(faust2_raw, 2)\n",
    "homunculus = character_cleaner(homunculus_raw, 2)\n",
    "phorkyas = character_cleaner(phorkyas_raw, 2)\n",
    "sirenen = character_cleaner(sirenen_raw, 2)\n",
    "helena = character_cleaner(helena_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "faust2_characters = {'Mephistopheles II':mephistopheles2, 'Kaiser':kaiser, 'Kanzler':kanzler, 'Gemurmel':gemurmel, 'Herold':herold, 'Plutus':plutus, 'Heer Meister':heermeister, 'Marcshalk':marshalk, 'Faust II':faust2, 'Homunculus':homunculus, 'Phorkyas':phorkyas, 'Sirenen':sirenen, 'Helena':helena}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mephistopheles II contains 655 sentences and 8073 words\n",
      "Kaiser contains 161 sentences and 2147 words\n",
      "Kanzler contains 28 sentences and 419 words\n",
      "Gemurmel contains 9 sentences and 196 words\n",
      "Herold contains 103 sentences and 1455 words\n",
      "Plutus contains 40 sentences and 444 words\n",
      "Heer Meister contains 8 sentences and 148 words\n",
      "Marcshalk contains 19 sentences and 308 words\n",
      "Faust II contains 429 sentences and 5306 words\n",
      "Homunculus contains 75 sentences and 876 words\n",
      "Phorkyas contains 155 sentences and 2122 words\n",
      "Sirenen contains 52 sentences and 616 words\n",
      "Helena contains 149 sentences and 2165 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(faust2_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "del faust2_characters['Kanzler']\n",
    "del faust2_characters['Gemurmel']\n",
    "del faust2_characters['Herold']\n",
    "del faust2_characters['Plutus']\n",
    "del faust2_characters['Heer Meister']\n",
    "del faust2_characters['Marcshalk']\n",
    "del faust2_characters['Homunculus']\n",
    "del faust2_characters['Sirenen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'faust2_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store faust2_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Egmont - Johann Wolfgang von Goethe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_e = paragraphs_cleaner('egmont_goethe.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_e = token_paragraphs_e[66:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "egmont_raw = []\n",
    "klrchen_raw = []\n",
    "mutter_raw = []\n",
    "machiavell_raw = []\n",
    "regentin_raw = []\n",
    "klare_raw = []\n",
    "brackenburg_raw = []\n",
    "soest_raw = []\n",
    "sekretr_raw = []\n",
    "for par in token_paragraphs_e:\n",
    "    if  'Egmont' in par[:1] and '.' in par[:2]:\n",
    "         egmont_raw.append(par)\n",
    "    if  'Klrchen' in par[:1] and '.' in par[:2]:\n",
    "         klrchen_raw.append(par)\n",
    "    if  'Mutter' in par[:1] and '.' in par[:2]:\n",
    "         mutter_raw.append(par)\n",
    "    if  'Machiavell' in par[:1] and '.' in par [:2]:\n",
    "         machiavell_raw.append(par)\n",
    "    if  'Regentin' in par[:1] and '.' in par[:2]:\n",
    "         regentin_raw.append(par)\n",
    "    if  'Klare' in par[:1] and '.' in par[:2]:\n",
    "         klare_raw.append(par)\n",
    "    if  'Brackenburg' in par[:1] and '.' in par[:2]:\n",
    "         brackenburg_raw.append(par)\n",
    "    if  'Soest' in par[:1] and '.' in par[:2]:\n",
    "         soest_raw.append(par)\n",
    "    if  'Sekretr' in par[:1] and '.' in par[:2]:\n",
    "         sekretr_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "egmont = character_cleaner(egmont_raw,2)\n",
    "klrchen = character_cleaner(klrchen_raw,2)\n",
    "mutter = character_cleaner(mutter_raw,2)\n",
    "machiavell = character_cleaner(machiavell_raw,2)\n",
    "regentin = character_cleaner(regentin_raw,2)\n",
    "klare = character_cleaner(klare_raw,2)\n",
    "brackenburg = character_cleaner(brackenburg_raw,2)\n",
    "soest = character_cleaner(soest_raw,2)\n",
    "sekretr = character_cleaner(sekretr_raw,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "egmont_characters = {'Egmont':egmont, 'Klrchen':klrchen, 'Mutter':mutter, 'Machiavel':machiavell, 'Regentin':regentin, 'Klare':klare, 'Brackenburg':brackenburg, 'Soest':soest, 'Sekretr':sekretr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egmont contains 492 sentences and 5974 words\n",
      "Klrchen contains 292 sentences and 2440 words\n",
      "Mutter contains 51 sentences and 386 words\n",
      "Machiavel contains 60 sentences and 697 words\n",
      "Regentin contains 133 sentences and 2073 words\n",
      "Klare contains 83 sentences and 815 words\n",
      "Brackenburg contains 131 sentences and 1203 words\n",
      "Soest contains 90 sentences and 645 words\n",
      "Sekretr contains 62 sentences and 594 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(egmont_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "del egmont_characters['Mutter']\n",
    "del egmont_characters['Machiavel']\n",
    "del egmont_characters['Klare']\n",
    "del egmont_characters['Brackenburg']\n",
    "del egmont_characters['Soest']\n",
    "del egmont_characters['Sekretr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'egmont_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store egmont_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iphigenie auf Tauris - Johann Wolfgang von Goethe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_iat = paragraphs_cleaner('iphigenie_auf_tauris_goethe.txt', normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_iat = token_paragraphs_iat[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphigenie_raw = []\n",
    "orest_raw = []\n",
    "thoas_raw = []\n",
    "pylades_raw = []\n",
    "arkas_raw = []\n",
    "for par in token_paragraphs_iat:\n",
    "    if  'Iphigenie' in par[:1] and '.' in par[:2]:\n",
    "         iphigenie_raw.append(par)\n",
    "    if  'Orest' in par[:1] and '.' in par[:2]:\n",
    "         orest_raw.append(par)\n",
    "    if  'Thoas' in par[:1] and '.' in par[:2]:\n",
    "         thoas_raw.append(par)\n",
    "    if  'Pylades' in par[:1] and '.' in par [:2]:\n",
    "         pylades_raw.append(par)\n",
    "    if  'Arkas' in par[:1] and '.' in par[:2]:\n",
    "         arkas_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphigenie = character_cleaner(iphigenie_raw, 2)\n",
    "orest = character_cleaner(orest_raw, 2)\n",
    "thoas = character_cleaner(thoas_raw, 2)\n",
    "pylades = character_cleaner(pylades_raw, 2)\n",
    "arkas = character_cleaner(arkas_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphigenie_auf_tauris_characters = {'Iphigenie':iphigenie, 'Orest':orest, 'Thoas':thoas, 'Pylades':pylades, 'Arkas':arkas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iphigenie contains 432 sentences and 6371 words\n",
      "Orest contains 211 sentences and 3032 words\n",
      "Thoas contains 97 sentences and 1347 words\n",
      "Pylades contains 174 sentences and 2457 words\n",
      "Arkas contains 80 sentences and 1240 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(iphigenie_auf_tauris_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "del iphigenie_auf_tauris_characters['Thoas']\n",
    "del iphigenie_auf_tauris_characters['Arkas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'iphigenie_auf_tauris_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store iphigenie_auf_tauris_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Die Laune des Verliebten - Johann Wolfgang von Goethe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_dldv = paragraphs_cleaner('die_laune_des_verliebten_goethe.txt', squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_dldv = token_paragraphs_dldv[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "egle_raw = []\n",
    "amine_raw = []\n",
    "eridon_raw = []\n",
    "lamon_raw = []\n",
    "for par in token_paragraphs_dldv:\n",
    "    if  'Egle' in par[:1]: \n",
    "         egle_raw.append(par)\n",
    "    if  'Amine' in par[:1]: \n",
    "         amine_raw.append(par)\n",
    "    if  'Eridon' in par[:1]: \n",
    "         eridon_raw.append(par)\n",
    "    if  'Lamon' in par[:1]: \n",
    "         lamon_raw.append(par)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "egle = character_cleaner(egle_raw, 2)\n",
    "amine = character_cleaner(amine_raw, 2)\n",
    "eridon = character_cleaner(eridon_raw, 2)\n",
    "lamon = character_cleaner(lamon_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "die_laune_des_verliebten_characters = {'Egle':egle, 'Amine':amine, 'Eridon':eridon, 'Lamon':lamon}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egle contains 256 sentences and 2434 words\n",
      "Amine contains 182 sentences and 1309 words\n",
      "Eridon contains 113 sentences and 910 words\n",
      "Lamon contains 42 sentences and 302 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(die_laune_des_verliebten_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "del die_laune_des_verliebten_characters['Amine']\n",
    "del die_laune_des_verliebten_characters['Eridon']\n",
    "del die_laune_des_verliebten_characters['Lamon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'die_laune_des_verliebten_characters' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store die_laune_des_verliebten_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
