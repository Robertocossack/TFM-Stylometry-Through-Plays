{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition (char_sens, n):\n",
    "    return [char_sens[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_split (play_characters, n):\n",
    "    play_characters_part = {}\n",
    "    for char in play_characters.keys():\n",
    "        play_characters_part[char] = partition(play_characters[char], n)\n",
    "    return play_characters_part  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_partitions (play_part):\n",
    "    part_1 = {}\n",
    "    part_2 = {}\n",
    "    part_3 = {}\n",
    "    part_4 = {}\n",
    "    part_5 = {}\n",
    "    for char in play_part:\n",
    "        for part in char:\n",
    "            part_1[char] = play_part[char][0] + play_part[char][2] + play_part[char][3] + play_part[char][4]\n",
    "            part_2[char] = play_part[char][0] + play_part[char][1] + play_part[char][3] + play_part[char][4]\n",
    "            part_3[char] = play_part[char][0] + play_part[char][1] + play_part[char][2] + play_part[char][4]\n",
    "            part_4[char] = play_part[char][0] + play_part[char][1] + play_part[char][2] + play_part[char][3]\n",
    "            part_5[char] = play_part[char][1] + play_part[char][2] + play_part[char][3] + play_part[char][4]\n",
    "    return part_1, part_2, part_3, part_4, part_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test (play_part):\n",
    "    test_1 = {}\n",
    "    test_2 = {}\n",
    "    test_3 = {}\n",
    "    test_4 = {}\n",
    "    test_5 = {}\n",
    "    for char in play_part:\n",
    "        for part in char:\n",
    "            test_1[char] = play_part[char][1]\n",
    "            test_2[char] = play_part[char][2]\n",
    "            test_3[char] = play_part[char][3]\n",
    "            test_4[char] = play_part[char][4]\n",
    "            test_5[char] = play_part[char][0]\n",
    "    return test_1, test_2, test_3, test_4, test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tok_no_punct (char):\n",
    "    result = []\n",
    "    for sen in char:\n",
    "        sen = sen.lower()\n",
    "        output = tokenizer.tokenize(sen)\n",
    "        result.append(output)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_unifier (character):\n",
    "    output = []\n",
    "    for sen in character:\n",
    "        for word in sen:\n",
    "            output.append(word)\n",
    "    one_string = \" \".join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_word_tokenizer (play_characters):\n",
    "    chars = list(play_characters.keys())\n",
    "    char_tokens = {}\n",
    "    for char in chars:\n",
    "        output = word_tok_no_punct(play_characters[char])\n",
    "        result = sentences_unifier(output)\n",
    "        char_tokens[char] = result\n",
    "    return char_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_tokenizer (play_characters, n):\n",
    "    chars = list(play_characters.keys())\n",
    "    char_bigram_tokens = {}\n",
    "    for char in chars:\n",
    "        output = ngrams(play_characters[char],n)\n",
    "        result = list(output)\n",
    "        char_bigram_tokens[char] = result\n",
    "    return char_bigram_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_corpus_generator (partition):\n",
    "    whole_corpus = []\n",
    "    for char in partition.keys():\n",
    "        for word in partition[char]:\n",
    "            whole_corpus.append(word)\n",
    "    return whole_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_generator (whole_corpus_freq, partition):\n",
    "    features = [word for word,freq in whole_corpus_freq]\n",
    "    feature_freqs = {}\n",
    "    for char in partition:\n",
    "        feature_freqs[char] = {} \n",
    "        overall = len(partition[char])\n",
    "        for feature in features:\n",
    "            presence = partition[char].count(feature)\n",
    "            feature_freqs[char][feature] = presence / overall\n",
    "    return  feature_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscores (df):\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        if type(col) == tuple:\n",
    "            join_col = col[0] + '-' + col[1]\n",
    "            col_zscore = join_col + '_zscore'\n",
    "        else:        \n",
    "            col_zscore = col + '_zscore'\n",
    "        df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
    "    df = df.drop(cols, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_distance (play_characters, test_zscores, part_zscores, character):    \n",
    "    chars = play_characters.keys()\n",
    "    delta = {}\n",
    "    for char in chars:\n",
    "        delta[char] = (abs(test_zscores.loc[character] - part_zscores.loc[char])).sum()/50\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas (writer_characters, test_zscores, train_zscores):\n",
    "    deltas = {}\n",
    "    for char in writer_characters.keys():\n",
    "        result = delta_distance(writer_characters, test_zscores, train_zscores, char)\n",
    "        deltas[char]= result\n",
    "        df = pd.DataFrame.from_dict(deltas)\n",
    "        df = df.reindex(sorted(df.columns), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions (plays_data, plays_test, n, plays_characters, column_name):\n",
    "   \n",
    "    plays_data_corpus = whole_corpus_generator(plays_data)\n",
    "    plays_data_corpus_freq = list(nltk.FreqDist(plays_data_corpus).most_common(n))\n",
    "    plays_data_features = features_generator(plays_data_corpus_freq, plays_data)\n",
    "    df_plays_data = pd.DataFrame.from_dict(plays_data_features, orient = 'index')\n",
    "    plays_data_zscores = zscores(df_plays_data)\n",
    "    plays_test_features = features_generator(plays_data_corpus_freq, plays_test)\n",
    "    df_plays_test = pd.DataFrame.from_dict(plays_test_features, orient = 'index')\n",
    "    plays_test_zscores = zscores(df_plays_test)\n",
    "    deltas = get_deltas(plays_characters, plays_test_zscores, plays_data_zscores)\n",
    "    predictions = deltas.idxmin()\n",
    "    df_predictions = pd.DataFrame(predictions, columns = [column_name])\n",
    "    \n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success_rate (author_results):\n",
    "    result = []\n",
    "    for char in author_results.index:\n",
    "        output = sum(list(author_results.loc[char] == char))/5\n",
    "        result.append(output)\n",
    "    author_results['Results'] = result\n",
    "    \n",
    "    return author_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burrows Delta Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oscar Wilde "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters (+1500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_characters = {**an_ideal_husband_characters, **a_woman_of_no_importance_characters, **lady_windermeres_fan_characters, **the_importance_of_being_earnest_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wilde_characters['Chasuble']\n",
    "del wilde_characters['Prism']\n",
    "del wilde_characters['Augustus']\n",
    "del wilde_characters['Hester']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wilde_characters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_characters_split = corpus_split(wilde_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_characters_partition = split_partitions(wilde_characters_split)\n",
    "wilde_characters_test = split_test(wilde_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_1 = dict_word_tokenizer(wilde_characters_partition[0])\n",
    "wilde_part_2 = dict_word_tokenizer(wilde_characters_partition[1])\n",
    "wilde_part_3 = dict_word_tokenizer(wilde_characters_partition[2])\n",
    "wilde_part_4 = dict_word_tokenizer(wilde_characters_partition[3])\n",
    "wilde_part_5 = dict_word_tokenizer(wilde_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_1 = dict_word_tokenizer(wilde_characters_test[0])\n",
    "wilde_test_2 = dict_word_tokenizer(wilde_characters_test[1])\n",
    "wilde_test_3 = dict_word_tokenizer(wilde_characters_test[2])\n",
    "wilde_test_4 = dict_word_tokenizer(wilde_characters_test[3])\n",
    "wilde_test_5 = dict_word_tokenizer(wilde_characters_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_partition[0]), 2)\n",
    "wilde_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_partition[1]), 2)\n",
    "wilde_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_partition[2]), 2)\n",
    "wilde_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_partition[3]), 2)\n",
    "wilde_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_test[0]), 2)\n",
    "wilde_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_test[1]), 2)\n",
    "wilde_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_test[2]), 2)\n",
    "wilde_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_test[3]), 2)\n",
    "wilde_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(wilde_characters_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 7 characters (+4000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_top_7_characters = ['Goring', 'Chiltern', 'Cheveley', 'Illingorth', 'Lady Windermere', 'Algernon', 'Jack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_top_7 = {}\n",
    "for key in wilde_characters:\n",
    "    if key in wilde_top_7_characters:\n",
    "        wilde_top_7[key] = wilde_characters[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Goring', 'Chiltern', 'Cheveley', 'Illingorth', 'Lady Windermere', 'Jack', 'Algernon'])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_top_7.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_1_corpus = whole_corpus_generator(wilde_part_1)\n",
    "wilde_part_1_corpus_freq = list(nltk.FreqDist(wilde_part_1_corpus).most_common(50))\n",
    "wilde_part_1_features = features_generator(wilde_part_1_corpus_freq, wilde_part_1)\n",
    "df_wilde_1 = pd.DataFrame.from_dict(wilde_part_1_features, orient = 'index')\n",
    "wilde_zscores_1 = zscores(df_wilde_1)\n",
    "wilde_zscores_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_1_features = features_generator(wilde_part_1_corpus_freq, wilde_test_1)\n",
    "df_wilde_test_1 = pd.DataFrame.from_dict(wilde_test_1_features, orient = 'index')\n",
    "wilde_zscores_test_1 = zscores(df_wilde_test_1)\n",
    "wilde_zscores_test_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_1_deltas = get_deltas(wilde_characters, wilde_zscores_test_1, wilde_zscores_1)\n",
    "predictions_wilde_1 = wilde_1_deltas.idxmin()\n",
    "wilde_df_1 = pd.DataFrame(predictions_wilde_1, columns = ['Part_1'])\n",
    "wilde_df_1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigram_df_1 = model_predictions(wilde_bigrams_part_1, wilde_bigrams_test_1, 50, wilde_characters, 'Part_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z- scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_2_corpus = whole_corpus_generator(wilde_part_2)\n",
    "wilde_part_2_corpus_freq = list(nltk.FreqDist(wilde_part_2_corpus).most_common(50))\n",
    "wilde_part_2_features = features_generator(wilde_part_2_corpus_freq, wilde_part_2)\n",
    "df_wilde_2 = pd.DataFrame.from_dict(wilde_part_2_features, orient = 'index')\n",
    "wilde_zscores_2 = zscores(df_wilde_2)\n",
    "wilde_zscores_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_2_features = features_generator(wilde_part_2_corpus_freq, wilde_test_2)\n",
    "df_wilde_test_2 = pd.DataFrame.from_dict(wilde_test_2_features, orient = 'index')\n",
    "wilde_zscores_test_2 = zscores(df_wilde_test_2)\n",
    "wilde_zscores_test_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_2_deltas = get_deltas(wilde_characters, wilde_zscores_test_2, wilde_zscores_2)\n",
    "predictions_wilde_2 = wilde_2_deltas.idxmin()\n",
    "wilde_df_2 = pd.DataFrame(predictions_wilde_2, columns = ['Part_2'])\n",
    "wilde_df_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigram_df_2 = model_predictions(wilde_bigrams_part_2, wilde_bigrams_test_2, 50, wilde_characters, 'Part_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_3_corpus = whole_corpus_generator(wilde_part_3)\n",
    "wilde_part_3_corpus_freq = list(nltk.FreqDist(wilde_part_3_corpus).most_common(50))\n",
    "wilde_part_3_features = features_generator(wilde_part_3_corpus_freq, wilde_part_3)\n",
    "df_wilde_3 = pd.DataFrame.from_dict(wilde_part_3_features, orient = 'index')\n",
    "wilde_zscores_3 = zscores(df_wilde_3)\n",
    "wilde_zscores_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_3_features = features_generator(wilde_part_3_corpus_freq, wilde_test_3)\n",
    "df_wilde_test_3 = pd.DataFrame.from_dict(wilde_test_3_features, orient = 'index')\n",
    "wilde_zscores_test_3 = zscores(df_wilde_test_3)\n",
    "wilde_zscores_test_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_3_deltas = get_deltas(wilde_characters, wilde_zscores_test_3, wilde_zscores_3)\n",
    "predictions_wilde_3 = wilde_3_deltas.idxmin()\n",
    "wilde_df_3 = pd.DataFrame(predictions_wilde_3, columns = ['Part_3'])\n",
    "wilde_df_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigram_df_3 = model_predictions(wilde_bigrams_part_3, wilde_bigrams_test_3, 50, wilde_characters, 'Part_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_4_corpus = whole_corpus_generator(wilde_part_4)\n",
    "wilde_part_4_corpus_freq = list(nltk.FreqDist(wilde_part_4_corpus).most_common(50))\n",
    "wilde_part_4_features = features_generator(wilde_part_4_corpus_freq, wilde_part_4)\n",
    "df_wilde_4 = pd.DataFrame.from_dict(wilde_part_4_features, orient = 'index')\n",
    "wilde_zscores_4 = zscores(df_wilde_4)\n",
    "wilde_zscores_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_4_features = features_generator(wilde_part_4_corpus_freq, wilde_test_4)\n",
    "df_wilde_test_4 = pd.DataFrame.from_dict(wilde_test_4_features, orient = 'index')\n",
    "wilde_zscores_test_4 = zscores(df_wilde_test_4)\n",
    "wilde_zscores_test_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_4_deltas = get_deltas(wilde_characters, wilde_zscores_test_4, wilde_zscores_4)\n",
    "predictions_wilde_4 = wilde_4_deltas.idxmin()\n",
    "wilde_df_4 = pd.DataFrame(predictions_wilde_4, columns = ['Part_4'])\n",
    "wilde_df_4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigram_df_4 = model_predictions(wilde_bigrams_part_4, wilde_bigrams_test_4, 50, wilde_characters, 'Part_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_5_corpus = whole_corpus_generator(wilde_part_5)\n",
    "wilde_part_5_corpus_freq = list(nltk.FreqDist(wilde_part_5_corpus).most_common(50))\n",
    "wilde_part_5_features = features_generator(wilde_part_5_corpus_freq, wilde_part_5)\n",
    "df_wilde_5 = pd.DataFrame.from_dict(wilde_part_5_features, orient = 'index')\n",
    "wilde_zscores_5 = zscores(df_wilde_5)\n",
    "wilde_zscores_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_5_features = features_generator(wilde_part_5_corpus_freq, wilde_test_5)\n",
    "df_wilde_test_5 = pd.DataFrame.from_dict(wilde_test_5_features, orient = 'index')\n",
    "wilde_zscores_test_5 = zscores(df_wilde_test_5)\n",
    "wilde_zscores_test_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_5_deltas = get_deltas(wilde_characters, wilde_zscores_test_5, wilde_zscores_5)\n",
    "predictions_wilde_5 = wilde_5_deltas.idxmin()\n",
    "wilde_df_5 = pd.DataFrame(predictions_wilde_5, columns = ['Part_5'])\n",
    "wilde_df_5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigram_df_5 = model_predictions(wilde_bigrams_part_5, wilde_bigrams_test_5, 50, wilde_characters, 'Part_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oscar Wilde Characters Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algernon</th>\n",
       "      <td>Jack</td>\n",
       "      <td>Gwendolen</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allonby</th>\n",
       "      <td>Goring</td>\n",
       "      <td>Illingorth</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Allonby</td>\n",
       "      <td>Allonby</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berwick</th>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>Berwick</td>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>Berwick</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bracknell</th>\n",
       "      <td>Bracknell</td>\n",
       "      <td>Bracknell</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Bracknell</td>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caversham</th>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Caversham</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cecily</th>\n",
       "      <td>Cecily</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>Cecily</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Jack</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheveley</th>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chiltern</th>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Cecily</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Darlington</th>\n",
       "      <td>Erlynne</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>Goring</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erlynne</th>\n",
       "      <td>Cecily</td>\n",
       "      <td>Erlynne</td>\n",
       "      <td>Erlynne</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Goring</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerald</th>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Gerald</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Gerald</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goring</th>\n",
       "      <td>Illingorth</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Cecily</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gwendolen</th>\n",
       "      <td>Gwendolen</td>\n",
       "      <td>Gwendolen</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hunstanton</th>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>Mabel</td>\n",
       "      <td>Hunstanton</td>\n",
       "      <td>Goring</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illingorth</th>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Illingorth</td>\n",
       "      <td>Illingorth</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jack</th>\n",
       "      <td>Goring</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady Chiltern</th>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Lady Chiltern</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Lady Chiltern</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady Windermere</th>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lord Windermere</th>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Erlynne</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mabel</th>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Mabel</td>\n",
       "      <td>Mabel</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs Artbuthnot</th>\n",
       "      <td>Lady Chiltern</td>\n",
       "      <td>Mrs Artbuthnot</td>\n",
       "      <td>Mrs Artbuthnot</td>\n",
       "      <td>Mrs Artbuthnot</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Part_1           Part_2           Part_3  \\\n",
       "Algernon                    Jack        Gwendolen         Algernon   \n",
       "Allonby                   Goring       Illingorth         Chiltern   \n",
       "Berwick               Hunstanton          Berwick       Hunstanton   \n",
       "Bracknell              Bracknell        Bracknell           Goring   \n",
       "Caversham                 Goring           Goring        Caversham   \n",
       "Cecily                    Cecily         Algernon           Cecily   \n",
       "Cheveley                Cheveley         Cheveley           Goring   \n",
       "Chiltern                Chiltern           Cecily         Chiltern   \n",
       "Darlington               Erlynne         Cheveley       Darlington   \n",
       "Erlynne                   Cecily          Erlynne          Erlynne   \n",
       "Gerald           Lady Windermere           Goring           Gerald   \n",
       "Goring                Illingorth           Goring           Cecily   \n",
       "Gwendolen              Gwendolen        Gwendolen             Jack   \n",
       "Hunstanton            Hunstanton       Hunstanton            Mabel   \n",
       "Illingorth                Goring           Goring           Goring   \n",
       "Jack                      Goring             Jack             Jack   \n",
       "Lady Chiltern    Lady Windermere           Goring    Lady Chiltern   \n",
       "Lady Windermere  Lady Windermere  Lady Windermere  Lady Windermere   \n",
       "Lord Windermere  Lady Windermere          Erlynne  Lady Windermere   \n",
       "Mabel                   Cheveley           Goring            Mabel   \n",
       "Mrs Artbuthnot     Lady Chiltern   Mrs Artbuthnot   Mrs Artbuthnot   \n",
       "\n",
       "                          Part_4           Part_5  Results  \n",
       "Algernon                    Jack         Algernon      0.4  \n",
       "Allonby                  Allonby          Allonby      0.4  \n",
       "Berwick               Hunstanton          Berwick      0.4  \n",
       "Bracknell              Bracknell       Hunstanton      0.6  \n",
       "Caversham        Lady Windermere         Cheveley      0.2  \n",
       "Cecily                    Goring             Jack      0.4  \n",
       "Cheveley                Cheveley         Cheveley      0.8  \n",
       "Chiltern                Chiltern         Chiltern      0.8  \n",
       "Darlington            Darlington           Goring      0.4  \n",
       "Erlynne          Lady Windermere           Goring      0.4  \n",
       "Gerald           Lady Windermere           Gerald      0.4  \n",
       "Goring                    Goring           Goring      0.6  \n",
       "Gwendolen               Chiltern         Algernon      0.4  \n",
       "Hunstanton            Hunstanton           Goring      0.6  \n",
       "Illingorth            Illingorth       Illingorth      0.4  \n",
       "Jack                        Jack         Algernon      0.6  \n",
       "Lady Chiltern           Cheveley    Lady Chiltern      0.4  \n",
       "Lady Windermere  Lady Windermere  Lady Windermere      1.0  \n",
       "Lord Windermere  Lady Windermere  Lady Windermere      0.0  \n",
       "Mabel                      Mabel         Cheveley      0.4  \n",
       "Mrs Artbuthnot    Mrs Artbuthnot  Lady Windermere      0.6  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_results = pd.concat([wilde_df_1, wilde_df_2, wilde_df_3, wilde_df_4, wilde_df_5], axis=1)\n",
    "wilde_results = success_rate(wilde_results)\n",
    "wilde_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48571428571428577"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Goring</th>\n",
       "      <td>Illingorth</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Cecily</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chiltern</th>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Cecily</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>Chiltern</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cheveley</th>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>Cheveley</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illingorth</th>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Goring</td>\n",
       "      <td>Illingorth</td>\n",
       "      <td>Illingorth</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady Windermere</th>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>Lady Windermere</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algernon</th>\n",
       "      <td>Jack</td>\n",
       "      <td>Gwendolen</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jack</th>\n",
       "      <td>Goring</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Algernon</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Part_1           Part_2           Part_3  \\\n",
       "Goring                Illingorth           Goring           Cecily   \n",
       "Chiltern                Chiltern           Cecily         Chiltern   \n",
       "Cheveley                Cheveley         Cheveley           Goring   \n",
       "Illingorth                Goring           Goring           Goring   \n",
       "Lady Windermere  Lady Windermere  Lady Windermere  Lady Windermere   \n",
       "Algernon                    Jack        Gwendolen         Algernon   \n",
       "Jack                      Goring             Jack             Jack   \n",
       "\n",
       "                          Part_4           Part_5  Results  \n",
       "Goring                    Goring           Goring      0.6  \n",
       "Chiltern                Chiltern         Chiltern      0.8  \n",
       "Cheveley                Cheveley         Cheveley      0.8  \n",
       "Illingorth            Illingorth       Illingorth      0.4  \n",
       "Lady Windermere  Lady Windermere  Lady Windermere      1.0  \n",
       "Algernon                    Jack         Algernon      0.4  \n",
       "Jack                        Jack         Algernon      0.6  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_top_7_results = wilde_results.filter(items = wilde_top_7_characters, axis=0)\n",
    "wilde_top_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571428571428571"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_top_7_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41904761904761906"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_bigram_results = pd.concat([wilde_bigram_df_1, wilde_bigram_df_2, wilde_bigram_df_3, wilde_bigram_df_4, wilde_bigram_df_5], axis =1)\n",
    "wilde_bigram_results = success_rate(wilde_bigram_results)\n",
    "wilde_bigram_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# George Bernard Shaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters (+1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_characters = {**pygmalion_characters, **androcles_and_the_lion_characters, **caesar_and_cleopatra_characters, **candida_characters, **man_and_superman_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shaw_characters['Mrs Higgins']\n",
    "del shaw_characters['Megaera']\n",
    "del shaw_characters['Centurion']\n",
    "del shaw_characters['Spintho']\n",
    "del shaw_characters['Ferrovius']\n",
    "del shaw_characters['Pothinus']\n",
    "del shaw_characters['Ftatateeta']\n",
    "del shaw_characters['Proserpine']\n",
    "del shaw_characters['Miss Ramsden']\n",
    "del shaw_characters['Hector']\n",
    "del shaw_characters['Straker']\n",
    "del shaw_characters['Dona Ana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shaw_characters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_characters_split = corpus_split(shaw_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_characters_partition = split_partitions(shaw_characters_split)\n",
    "shaw_characters_test = split_test(shaw_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_part_1 = dict_word_tokenizer(shaw_characters_partition[0])\n",
    "shaw_part_2 = dict_word_tokenizer(shaw_characters_partition[1])\n",
    "shaw_part_3 = dict_word_tokenizer(shaw_characters_partition[2])\n",
    "shaw_part_4 = dict_word_tokenizer(shaw_characters_partition[3])\n",
    "shaw_part_5 = dict_word_tokenizer(shaw_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_test_1 = dict_word_tokenizer(shaw_characters_test[0])\n",
    "shaw_test_2 = dict_word_tokenizer(shaw_characters_test[1])\n",
    "shaw_test_3 = dict_word_tokenizer(shaw_characters_test[2])\n",
    "shaw_test_4 = dict_word_tokenizer(shaw_characters_test[3])\n",
    "shaw_test_5 = dict_word_tokenizer(shaw_characters_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_partition[0]), 2)\n",
    "shaw_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_partition[1]), 2)\n",
    "shaw_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_partition[2]), 2)\n",
    "shaw_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_partition[3]), 2)\n",
    "shaw_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_test[0]), 2)\n",
    "shaw_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_test[1]), 2)\n",
    "shaw_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_test[2]), 2)\n",
    "shaw_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_test[3]), 2)\n",
    "shaw_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(shaw_characters_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 7 characters (+4000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_top_7_characters = ['Higgins', 'Liza', 'Caesar', 'Cleopatra', 'Morell', 'Tanner', 'Don Juan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_top_7 = {}\n",
    "for key in shaw_characters:\n",
    "    if key in shaw_top_7_characters:\n",
    "        shaw_top_7[key] = shaw_characters[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_part_1_corpus = whole_corpus_generator(shaw_part_1)\n",
    "shaw_part_1_corpus_freq = list(nltk.FreqDist(shaw_part_1_corpus).most_common(50))\n",
    "shaw_part_1_features = features_generator(shaw_part_1_corpus_freq, shaw_part_1)\n",
    "df_shaw_1 = pd.DataFrame.from_dict(shaw_part_1_features, orient = 'index')\n",
    "shaw_zscores_1 = zscores(df_shaw_1)\n",
    "shaw_zscores_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_test_1_features = features_generator(shaw_part_1_corpus_freq, shaw_test_1)\n",
    "df_shaw_test_1 = pd.DataFrame.from_dict(shaw_test_1_features, orient = 'index')\n",
    "shaw_zscores_test_1 = zscores(df_shaw_test_1)\n",
    "shaw_zscores_test_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_1_deltas = get_deltas(shaw_characters, shaw_zscores_test_1, shaw_zscores_1)\n",
    "predictions_shaw_1 = shaw_1_deltas.idxmin()\n",
    "shaw_df_1 = pd.DataFrame(predictions_shaw_1, columns = ['Part_1'])\n",
    "shaw_df_1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigram_df_1 = model_predictions(shaw_bigrams_part_1, shaw_bigrams_test_1, 50, shaw_characters, 'Part_1')\n",
    "shaw_bigram_df_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_part_2_corpus = whole_corpus_generator(shaw_part_2)\n",
    "shaw_part_2_corpus_freq = list(nltk.FreqDist(shaw_part_2_corpus).most_common(50))\n",
    "shaw_part_2_features = features_generator(shaw_part_2_corpus_freq, shaw_part_2)\n",
    "df_shaw_2 = pd.DataFrame.from_dict(shaw_part_2_features, orient = 'index')\n",
    "shaw_zscores_2 = zscores(df_shaw_2)\n",
    "shaw_zscores_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_test_2_features = features_generator(shaw_part_2_corpus_freq, shaw_test_2)\n",
    "df_shaw_test_2 = pd.DataFrame.from_dict(shaw_test_2_features, orient = 'index')\n",
    "shaw_zscores_test_2 = zscores(df_shaw_test_2)\n",
    "shaw_zscores_test_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_2_deltas = get_deltas(shaw_characters, shaw_zscores_test_2, shaw_zscores_2)\n",
    "predictions_shaw_2 = shaw_2_deltas.idxmin()\n",
    "shaw_df_2 = pd.DataFrame(predictions_shaw_2, columns = ['Part_2'])\n",
    "shaw_df_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigram_df_2 = model_predictions(shaw_bigrams_part_2, shaw_bigrams_test_2, 50, shaw_characters, 'Part_2')\n",
    "shaw_bigram_df_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_part_3_corpus = whole_corpus_generator(shaw_part_3)\n",
    "shaw_part_3_corpus_freq = list(nltk.FreqDist(shaw_part_3_corpus).most_common(50))\n",
    "shaw_part_3_features = features_generator(shaw_part_3_corpus_freq, shaw_part_3)\n",
    "df_shaw_3 = pd.DataFrame.from_dict(shaw_part_3_features, orient = 'index')\n",
    "shaw_zscores_3 = zscores(df_shaw_3)\n",
    "shaw_zscores_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_test_3_features = features_generator(shaw_part_3_corpus_freq, shaw_test_3)\n",
    "df_shaw_test_3 = pd.DataFrame.from_dict(shaw_test_3_features, orient = 'index')\n",
    "shaw_zscores_test_3 = zscores(df_shaw_test_3)\n",
    "shaw_zscores_test_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_3_deltas = get_deltas(shaw_characters, shaw_zscores_test_3, shaw_zscores_3)\n",
    "predictions_shaw_3 = shaw_3_deltas.idxmin()\n",
    "shaw_df_3 = pd.DataFrame(predictions_shaw_3, columns = ['Part_3'])\n",
    "shaw_df_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigram_df_3 = model_predictions(shaw_bigrams_part_3, shaw_bigrams_test_3, 50, shaw_characters, 'Part_3')\n",
    "shaw_bigram_df_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_part_4_corpus = whole_corpus_generator(shaw_part_4)\n",
    "shaw_part_4_corpus_freq = list(nltk.FreqDist(shaw_part_4_corpus).most_common(50))\n",
    "shaw_part_4_features = features_generator(shaw_part_4_corpus_freq, shaw_part_4)\n",
    "df_shaw_4 = pd.DataFrame.from_dict(shaw_part_4_features, orient = 'index')\n",
    "shaw_zscores_4 = zscores(df_shaw_4)\n",
    "shaw_zscores_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_test_4_features = features_generator(shaw_part_4_corpus_freq, shaw_test_4)\n",
    "df_shaw_test_4 = pd.DataFrame.from_dict(shaw_test_4_features, orient = 'index')\n",
    "shaw_zscores_test_4 = zscores(df_shaw_test_4)\n",
    "shaw_zscores_test_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_4_deltas = get_deltas(shaw_characters, shaw_zscores_test_4, shaw_zscores_4)\n",
    "predictions_shaw_4 = shaw_4_deltas.idxmin()\n",
    "shaw_df_4 = pd.DataFrame(predictions_shaw_4, columns = ['Part_4'])\n",
    "shaw_df_4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigram_df_4 = model_predictions(shaw_bigrams_part_4, shaw_bigrams_test_4, 50, shaw_characters, 'Part_4')\n",
    "shaw_bigram_df_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_part_5_corpus = whole_corpus_generator(shaw_part_5)\n",
    "shaw_part_5_corpus_freq = list(nltk.FreqDist(shaw_part_5_corpus).most_common(50))\n",
    "shaw_part_5_features = features_generator(shaw_part_5_corpus_freq, shaw_part_5)\n",
    "df_shaw_5 = pd.DataFrame.from_dict(shaw_part_5_features, orient = 'index')\n",
    "shaw_zscores_5 = zscores(df_shaw_5)\n",
    "shaw_zscores_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_test_5_features = features_generator(shaw_part_5_corpus_freq, shaw_test_5)\n",
    "df_shaw_test_5 = pd.DataFrame.from_dict(shaw_test_5_features, orient = 'index')\n",
    "shaw_zscores_test_5 = zscores(df_shaw_test_5)\n",
    "shaw_zscores_test_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_5_deltas = get_deltas(shaw_characters, shaw_zscores_test_5, shaw_zscores_5)\n",
    "predictions_shaw_5 = shaw_5_deltas.idxmin()\n",
    "shaw_df_5 = pd.DataFrame(predictions_shaw_5, columns = ['Part_5'])\n",
    "shaw_df_5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaw_bigram_df_5 = model_predictions(shaw_bigrams_part_5, shaw_bigrams_test_5, 50, shaw_characters, 'Part_5')\n",
    "shaw_bigram_df_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## George Bernard Shaw Characters Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Androcles</th>\n",
       "      <td>Tanner</td>\n",
       "      <td>Androcles</td>\n",
       "      <td>Lavinia</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Androcles</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ann</th>\n",
       "      <td>Ann</td>\n",
       "      <td>Ann</td>\n",
       "      <td>Ann</td>\n",
       "      <td>Ann</td>\n",
       "      <td>Ann</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apollodorus</th>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>Apollodorus</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>Apollodorus</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>Morell</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>Burgess</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caesar</th>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Candida</th>\n",
       "      <td>Morell</td>\n",
       "      <td>Candida</td>\n",
       "      <td>Candida</td>\n",
       "      <td>Candida</td>\n",
       "      <td>Candida</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Captain</th>\n",
       "      <td>Captain</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Captain</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Captain</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleopatra</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don Juan</th>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doolittle</th>\n",
       "      <td>Doolittle</td>\n",
       "      <td>Doolittle</td>\n",
       "      <td>Doolittle</td>\n",
       "      <td>Doolittle</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Higgins</th>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lavinia</th>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Lavinia</td>\n",
       "      <td>Morell</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liza</th>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marchbanks</th>\n",
       "      <td>Marchbanks</td>\n",
       "      <td>Marchbanks</td>\n",
       "      <td>Marchbanks</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Marchbanks</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mendoza</th>\n",
       "      <td>Mendoza</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morell</th>\n",
       "      <td>Tanner</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Octavius</th>\n",
       "      <td>Marchbanks</td>\n",
       "      <td>Octavius</td>\n",
       "      <td>Ramsden</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Octavius</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickering</th>\n",
       "      <td>Pickering</td>\n",
       "      <td>Pickering</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>Pickering</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ramsden</th>\n",
       "      <td>Morell</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Ramsden</td>\n",
       "      <td>Ramsden</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufio</th>\n",
       "      <td>Tanner</td>\n",
       "      <td>Rufio</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Rufio</td>\n",
       "      <td>Rufio</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanner</th>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Devil</th>\n",
       "      <td>The Devil</td>\n",
       "      <td>The Devil</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>The Devil</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Violet</th>\n",
       "      <td>Ann</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Candida</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Part_1      Part_2       Part_3     Part_4       Part_5  \\\n",
       "Androcles        Tanner   Androcles      Lavinia     Morell    Androcles   \n",
       "Ann                 Ann         Ann          Ann        Ann          Ann   \n",
       "Apollodorus    Don Juan     Mendoza  Apollodorus    Mendoza  Apollodorus   \n",
       "Burgess          Morell     Burgess      Burgess    Burgess      Burgess   \n",
       "Caesar           Caesar      Caesar       Caesar     Caesar       Caesar   \n",
       "Candida          Morell     Candida      Candida    Candida      Candida   \n",
       "Captain         Captain      Caesar      Captain     Caesar      Captain   \n",
       "Cleopatra     Cleopatra   Cleopatra    Cleopatra  Cleopatra    Cleopatra   \n",
       "Don Juan       Don Juan    Don Juan     Don Juan   Don Juan     Don Juan   \n",
       "Doolittle     Doolittle   Doolittle    Doolittle  Doolittle       Tanner   \n",
       "Higgins         Higgins     Higgins      Higgins    Higgins      Higgins   \n",
       "Lavinia          Morell      Morell       Caesar    Lavinia       Morell   \n",
       "Liza               Liza        Liza         Liza       Liza         Liza   \n",
       "Marchbanks   Marchbanks  Marchbanks   Marchbanks     Morell   Marchbanks   \n",
       "Mendoza         Mendoza      Tanner       Tanner     Tanner     Don Juan   \n",
       "Morell           Tanner      Morell       Morell     Morell       Morell   \n",
       "Octavius     Marchbanks    Octavius      Ramsden     Morell     Octavius   \n",
       "Pickering     Pickering   Pickering      Higgins    Mendoza    Pickering   \n",
       "Ramsden          Morell      Tanner      Ramsden    Ramsden       Tanner   \n",
       "Rufio            Tanner       Rufio       Tanner      Rufio        Rufio   \n",
       "Tanner           Tanner      Tanner       Tanner     Tanner       Tanner   \n",
       "The Devil     The Devil   The Devil     Don Juan   Don Juan    The Devil   \n",
       "Violet              Ann      Morell      Candida     Morell       Morell   \n",
       "\n",
       "             Results  \n",
       "Androcles        0.4  \n",
       "Ann              1.0  \n",
       "Apollodorus      0.4  \n",
       "Burgess          0.8  \n",
       "Caesar           1.0  \n",
       "Candida          0.8  \n",
       "Captain          0.6  \n",
       "Cleopatra        1.0  \n",
       "Don Juan         1.0  \n",
       "Doolittle        0.8  \n",
       "Higgins          1.0  \n",
       "Lavinia          0.2  \n",
       "Liza             1.0  \n",
       "Marchbanks       0.8  \n",
       "Mendoza          0.2  \n",
       "Morell           0.8  \n",
       "Octavius         0.4  \n",
       "Pickering        0.6  \n",
       "Ramsden          0.4  \n",
       "Rufio            0.6  \n",
       "Tanner           1.0  \n",
       "The Devil        0.6  \n",
       "Violet           0.0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_results = pd.concat([shaw_df_1, shaw_df_2, shaw_df_3, shaw_df_4, shaw_df_5], axis=1)\n",
    "shaw_results = success_rate(shaw_results)\n",
    "shaw_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6695652173913043"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Higgins</th>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liza</th>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>Liza</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caesar</th>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>Caesar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleopatra</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morell</th>\n",
       "      <td>Tanner</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>Morell</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanner</th>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>Tanner</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don Juan</th>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>Don Juan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Part_1     Part_2     Part_3     Part_4     Part_5  Results\n",
       "Higgins      Higgins    Higgins    Higgins    Higgins    Higgins      1.0\n",
       "Liza            Liza       Liza       Liza       Liza       Liza      1.0\n",
       "Caesar        Caesar     Caesar     Caesar     Caesar     Caesar      1.0\n",
       "Cleopatra  Cleopatra  Cleopatra  Cleopatra  Cleopatra  Cleopatra      1.0\n",
       "Morell        Tanner     Morell     Morell     Morell     Morell      0.8\n",
       "Tanner        Tanner     Tanner     Tanner     Tanner     Tanner      1.0\n",
       "Don Juan    Don Juan   Don Juan   Don Juan   Don Juan   Don Juan      1.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_top_7_results = shaw_results.filter(items = shaw_top_7_characters, axis=0)\n",
    "shaw_top_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_top_7_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32173913043478264"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_bigram_results = pd.concat([shaw_bigram_df_1, shaw_bigram_df_2, shaw_bigram_df_3, shaw_bigram_df_4, shaw_bigram_df_5], axis =1)\n",
    "shaw_bigram_results = success_rate(shaw_bigram_results)\n",
    "shaw_bigram_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben Jonson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters (+1500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_characters = {**cynthias_revels_characters, **every_man_on_his_humour_characters, **volpone_or_the_fox_characters, **the_alchemist_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del jonson_characters['Echo']\n",
    "del jonson_characters['Hedon']\n",
    "del jonson_characters['Arete']\n",
    "del jonson_characters['Philautia']\n",
    "del jonson_characters['Cyntia']\n",
    "del jonson_characters['Mathew']\n",
    "del jonson_characters['Tib']\n",
    "del jonson_characters['Cash']\n",
    "del jonson_characters['Downright']\n",
    "del jonson_characters['Dame Kitely']\n",
    "del jonson_characters['Nano']\n",
    "del jonson_characters['Androgyno']\n",
    "del jonson_characters['Voltore']\n",
    "del jonson_characters['Corbaccio']\n",
    "del jonson_characters['Peregrine']\n",
    "del jonson_characters['Bonario']\n",
    "del jonson_characters['Lady Would-be']\n",
    "del jonson_characters['Dol']\n",
    "del jonson_characters['Dapper']\n",
    "del jonson_characters['Drugger']\n",
    "del jonson_characters['Ananias']\n",
    "del jonson_characters['Tribulation']\n",
    "del jonson_characters['Kastril']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jonson_characters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_characters_split = corpus_split(jonson_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_characters_partition = split_partitions(jonson_characters_split)\n",
    "jonson_characters_test = split_test(jonson_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_part_1 = dict_word_tokenizer(jonson_characters_partition[0])\n",
    "jonson_part_2 = dict_word_tokenizer(jonson_characters_partition[1])\n",
    "jonson_part_3 = dict_word_tokenizer(jonson_characters_partition[2])\n",
    "jonson_part_4 = dict_word_tokenizer(jonson_characters_partition[3])\n",
    "jonson_part_5 = dict_word_tokenizer(jonson_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_test_1 = dict_word_tokenizer(jonson_characters_test[0])\n",
    "jonson_test_2 = dict_word_tokenizer(jonson_characters_test[1])\n",
    "jonson_test_3 = dict_word_tokenizer(jonson_characters_test[2])\n",
    "jonson_test_4 = dict_word_tokenizer(jonson_characters_test[3])\n",
    "jonson_test_5 = dict_word_tokenizer(jonson_characters_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_partition[0]), 2)\n",
    "jonson_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_partition[1]), 2)\n",
    "jonson_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_partition[2]), 2)\n",
    "jonson_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_partition[3]), 2)\n",
    "jonson_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_test[0]), 2)\n",
    "jonson_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_test[1]), 2)\n",
    "jonson_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_test[2]), 2)\n",
    "jonson_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_test[3]), 2)\n",
    "jonson_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(jonson_characters_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Top 7 characters (+4000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_top_7_characters = ['Mercury', 'Amorphus', 'Crites', 'Volpone', 'Mosca', 'Face', 'Subtle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_top_7 = {}\n",
    "for key in jonson_characters:\n",
    "    if key in jonson_top_7_characters:\n",
    "        jonson_top_7[key] = jonson_characters[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - sccores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_part_1_corpus = whole_corpus_generator(jonson_part_1)\n",
    "jonson_part_1_corpus_freq = list(nltk.FreqDist(jonson_part_1_corpus).most_common(50))\n",
    "jonson_part_1_features = features_generator(jonson_part_1_corpus_freq, jonson_part_1)\n",
    "df_jonson_1 = pd.DataFrame.from_dict(jonson_part_1_features, orient = 'index')\n",
    "jonson_zscores_1 = zscores(df_jonson_1)\n",
    "jonson_zscores_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_test_1_features = features_generator(jonson_part_1_corpus_freq, jonson_test_1)\n",
    "df_jonson_test_1 = pd.DataFrame.from_dict(jonson_test_1_features, orient = 'index')\n",
    "jonson_zscores_test_1 = zscores(df_jonson_test_1)\n",
    "jonson_zscores_test_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_1_deltas = get_deltas(jonson_characters, jonson_zscores_test_1, jonson_zscores_1)\n",
    "predictions_jonson_1 = jonson_1_deltas.idxmin()\n",
    "jonson_df_1 = pd.DataFrame(predictions_jonson_1, columns = ['Part_1'])\n",
    "jonson_df_1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigram_df_1 = model_predictions(jonson_bigrams_part_1, jonson_bigrams_test_1, 50, jonson_characters, 'Part_1')\n",
    "jonson_bigram_df_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_part_2_corpus = whole_corpus_generator(jonson_part_2)\n",
    "jonson_part_2_corpus_freq = list(nltk.FreqDist(jonson_part_2_corpus).most_common(50))\n",
    "jonson_part_2_features = features_generator(jonson_part_2_corpus_freq, jonson_part_2)\n",
    "df_jonson_2 = pd.DataFrame.from_dict(jonson_part_2_features, orient = 'index')\n",
    "jonson_zscores_2 = zscores(df_jonson_2)\n",
    "jonson_zscores_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_test_2_features = features_generator(jonson_part_2_corpus_freq, jonson_test_2)\n",
    "df_jonson_test_2 = pd.DataFrame.from_dict(jonson_test_2_features, orient = 'index')\n",
    "jonson_zscores_test_2 = zscores(df_jonson_test_2)\n",
    "jonson_zscores_test_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_2_deltas = get_deltas(jonson_characters, jonson_zscores_test_2, jonson_zscores_2)\n",
    "predictions_jonson_2 = jonson_2_deltas.idxmin()\n",
    "jonson_df_2 = pd.DataFrame(predictions_jonson_2, columns = ['Part_2'])\n",
    "jonson_df_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigram_df_2 = model_predictions(jonson_bigrams_part_2, jonson_bigrams_test_2, 50, jonson_characters, 'Part_2')\n",
    "jonson_bigram_df_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_part_3_corpus = whole_corpus_generator(jonson_part_3)\n",
    "jonson_part_3_corpus_freq = list(nltk.FreqDist(jonson_part_3_corpus).most_common(50))\n",
    "jonson_part_3_features = features_generator(jonson_part_3_corpus_freq, jonson_part_3)\n",
    "df_jonson_3 = pd.DataFrame.from_dict(jonson_part_3_features, orient = 'index')\n",
    "jonson_zscores_3 = zscores(df_jonson_3)\n",
    "jonson_zscores_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_test_3_features = features_generator(jonson_part_3_corpus_freq, jonson_test_3)\n",
    "df_jonson_test_3 = pd.DataFrame.from_dict(jonson_test_3_features, orient = 'index')\n",
    "jonson_zscores_test_3 = zscores(df_jonson_test_3)\n",
    "jonson_zscores_test_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_3_deltas = get_deltas(jonson_characters, jonson_zscores_test_3, jonson_zscores_3)\n",
    "predictions_jonson_3 = jonson_3_deltas.idxmin()\n",
    "jonson_df_3 = pd.DataFrame(predictions_jonson_3, columns = ['Part_3'])\n",
    "jonson_df_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigram_df_3 = model_predictions(jonson_bigrams_part_3, jonson_bigrams_test_3, 50, jonson_characters, 'Part_3')\n",
    "jonson_bigram_df_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_part_4_corpus = whole_corpus_generator(jonson_part_4)\n",
    "jonson_part_4_corpus_freq = list(nltk.FreqDist(jonson_part_4_corpus).most_common(50))\n",
    "jonson_part_4_features = features_generator(jonson_part_4_corpus_freq, jonson_part_4)\n",
    "df_jonson_4 = pd.DataFrame.from_dict(jonson_part_4_features, orient = 'index')\n",
    "jonson_zscores_4 = zscores(df_jonson_4)\n",
    "jonson_zscores_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_test_4_features = features_generator(jonson_part_4_corpus_freq, jonson_test_4)\n",
    "df_jonson_test_4 = pd.DataFrame.from_dict(jonson_test_4_features, orient = 'index')\n",
    "jonson_zscores_test_4 = zscores(df_jonson_test_4)\n",
    "jonson_zscores_test_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_4_deltas = get_deltas(jonson_characters, jonson_zscores_test_4, jonson_zscores_4)\n",
    "predictions_jonson_4 = jonson_4_deltas.idxmin()\n",
    "jonson_df_4 = pd.DataFrame(predictions_jonson_4, columns = ['Part_4'])\n",
    "jonson_df_4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigram_df_4 = model_predictions(jonson_bigrams_part_4, jonson_bigrams_test_4, 50, jonson_characters, 'Part_4')\n",
    "jonson_bigram_df_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_part_5_corpus = whole_corpus_generator(jonson_part_5)\n",
    "jonson_part_5_corpus_freq = list(nltk.FreqDist(jonson_part_5_corpus).most_common(50))\n",
    "jonson_part_5_features = features_generator(jonson_part_5_corpus_freq, jonson_part_5)\n",
    "df_jonson_5 = pd.DataFrame.from_dict(jonson_part_5_features, orient = 'index')\n",
    "jonson_zscores_5 = zscores(df_jonson_5)\n",
    "jonson_zscores_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_test_5_features = features_generator(jonson_part_5_corpus_freq, jonson_test_5)\n",
    "df_jonson_test_5 = pd.DataFrame.from_dict(jonson_test_5_features, orient = 'index')\n",
    "jonson_zscores_test_5 = zscores(df_jonson_test_5)\n",
    "jonson_zscores_test_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_5_deltas = get_deltas(jonson_characters, jonson_zscores_test_5, jonson_zscores_5)\n",
    "predictions_jonson_5 = jonson_5_deltas.idxmin()\n",
    "jonson_df_5 = pd.DataFrame(predictions_jonson_5, columns = ['Part_5'])\n",
    "jonson_df_5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_bigram_df_5 = model_predictions(jonson_bigrams_part_5, jonson_bigrams_test_5, 50, jonson_characters, 'Part_5')\n",
    "jonson_bigram_df_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ben Jonson Characters Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "jonson_results = pd.concat([jonson_df_1, jonson_df_2, jonson_df_3, jonson_df_4, jonson_df_5], axis=1)\n",
    "jonson_results = success_rate(jonson_results)\n",
    "jonson_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49090909090909096"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jonson_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mercury</th>\n",
       "      <td>Mercury</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amorphus</th>\n",
       "      <td>Amorphus</td>\n",
       "      <td>Amorphus</td>\n",
       "      <td>Amorphus</td>\n",
       "      <td>Amorphus</td>\n",
       "      <td>Subtle</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crites</th>\n",
       "      <td>Crites</td>\n",
       "      <td>Volpone</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>Crites</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volpone</th>\n",
       "      <td>Volpone</td>\n",
       "      <td>Volpone</td>\n",
       "      <td>Volpone</td>\n",
       "      <td>Volpone</td>\n",
       "      <td>Volpone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mosca</th>\n",
       "      <td>Mosca</td>\n",
       "      <td>Mosca</td>\n",
       "      <td>Mosca</td>\n",
       "      <td>Mosca</td>\n",
       "      <td>Mosca</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Face</th>\n",
       "      <td>Face</td>\n",
       "      <td>Face</td>\n",
       "      <td>Face</td>\n",
       "      <td>Face</td>\n",
       "      <td>Face</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtle</th>\n",
       "      <td>Subtle</td>\n",
       "      <td>Subtle</td>\n",
       "      <td>Subtle</td>\n",
       "      <td>Subtle</td>\n",
       "      <td>Subtle</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Part_1    Part_2    Part_3    Part_4   Part_5  Results\n",
       "Mercury    Mercury   Mercury   Mercury   Mercury  Mercury      1.0\n",
       "Amorphus  Amorphus  Amorphus  Amorphus  Amorphus   Subtle      0.8\n",
       "Crites      Crites   Volpone   Mercury    Crites  Mercury      0.4\n",
       "Volpone    Volpone   Volpone   Volpone   Volpone  Volpone      1.0\n",
       "Mosca        Mosca     Mosca     Mosca     Mosca    Mosca      1.0\n",
       "Face          Face      Face      Face      Face     Face      1.0\n",
       "Subtle      Subtle    Subtle    Subtle    Subtle   Subtle      1.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jonson_top_7_results = jonson_results.filter(items = jonson_top_7_characters, axis=0)\n",
    "jonson_top_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857142857142858"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jonson_top_7_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21818181818181817"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jonson_bigram_results = pd.concat([jonson_bigram_df_1, jonson_bigram_df_2, jonson_bigram_df_3, jonson_bigram_df_4, jonson_bigram_df_5], axis =1)\n",
    "jonson_bigram_results = success_rate(jonson_bigram_results)\n",
    "jonson_bigram_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# William Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters (+1500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_characters = {**macbeth_characters, **romeo_and_juliet_characters, **othello_characters, **hamlet_characters, **king_lear_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shakespeare_characters['Banquo']\n",
    "del shakespeare_characters['Macduff']\n",
    "del shakespeare_characters['Ross']\n",
    "del shakespeare_characters['Benvolio']\n",
    "del shakespeare_characters['Lady Capulet']\n",
    "del shakespeare_characters['Roderigo']\n",
    "del shakespeare_characters['Ophelia']\n",
    "del shakespeare_characters['Laertes']\n",
    "del shakespeare_characters['Gertrude']\n",
    "del shakespeare_characters['Regan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shakespeare_characters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_characters_split = corpus_split(shakespeare_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_characters_partition = split_partitions(shakespeare_characters_split)\n",
    "shakespeare_characters_test = split_test(shakespeare_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_part_1 = dict_word_tokenizer(shakespeare_characters_partition[0])\n",
    "shakespeare_part_2 = dict_word_tokenizer(shakespeare_characters_partition[1])\n",
    "shakespeare_part_3 = dict_word_tokenizer(shakespeare_characters_partition[2])\n",
    "shakespeare_part_4 = dict_word_tokenizer(shakespeare_characters_partition[3])\n",
    "shakespeare_part_5 = dict_word_tokenizer(shakespeare_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_test_1 = dict_word_tokenizer(shakespeare_characters_test[0])\n",
    "shakespeare_test_2 = dict_word_tokenizer(shakespeare_characters_test[1])\n",
    "shakespeare_test_3 = dict_word_tokenizer(shakespeare_characters_test[2])\n",
    "shakespeare_test_4 = dict_word_tokenizer(shakespeare_characters_test[3])\n",
    "shakespeare_test_5 = dict_word_tokenizer(shakespeare_characters_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_partition[0]), 2)\n",
    "shakespeare_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_partition[1]), 2)\n",
    "shakespeare_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_partition[2]), 2)\n",
    "shakespeare_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_partition[3]), 2)\n",
    "shakespeare_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_test[0]), 2)\n",
    "shakespeare_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_test[1]), 2)\n",
    "shakespeare_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_test[2]), 2)\n",
    "shakespeare_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_test[3]), 2)\n",
    "shakespeare_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(shakespeare_characters_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 7 characters (+4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_top_7_characters = ['Macbeth', 'Romeo', 'Juliet', 'Othello', 'Iago', 'Hamlet', 'Lear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_top_7 = {}\n",
    "for key in shakespeare_characters:\n",
    "    if key in shakespeare_top_7_characters:\n",
    "        shakespeare_top_7[key] = shakespeare_characters[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_part_1_corpus = whole_corpus_generator(shakespeare_part_1)\n",
    "shakespeare_part_1_corpus_freq = list(nltk.FreqDist(shakespeare_part_1_corpus).most_common(50))\n",
    "shakespeare_part_1_features = features_generator(shakespeare_part_1_corpus_freq, shakespeare_part_1)\n",
    "df_shakespeare_1 = pd.DataFrame.from_dict(shakespeare_part_1_features, orient = 'index')\n",
    "shakespeare_zscores_1 = zscores(df_shakespeare_1)\n",
    "shakespeare_zscores_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_test_1_features = features_generator(shakespeare_part_1_corpus_freq, shakespeare_test_1)\n",
    "df_shakespeare_test_1 = pd.DataFrame.from_dict(shakespeare_test_1_features, orient = 'index')\n",
    "shakespeare_zscores_test_1 = zscores(df_shakespeare_test_1)\n",
    "shakespeare_zscores_test_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_1_deltas = get_deltas(shakespeare_characters, shakespeare_zscores_test_1, shakespeare_zscores_1)\n",
    "predictions_shakespeare_1 = shakespeare_1_deltas.idxmin()\n",
    "shakespeare_df_1 = pd.DataFrame(predictions_shakespeare_1, columns = ['Part_1'])\n",
    "shakespeare_df_1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigram_df_1 = model_predictions(shakespeare_bigrams_part_5, shakespeare_bigrams_test_5, 50, shakespeare_characters, 'Part_1')\n",
    "shakespeare_bigram_df_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_part_2_corpus = whole_corpus_generator(shakespeare_part_2)\n",
    "shakespeare_part_2_corpus_freq = list(nltk.FreqDist(shakespeare_part_2_corpus).most_common(50))\n",
    "shakespeare_part_2_features = features_generator(shakespeare_part_2_corpus_freq, shakespeare_part_2)\n",
    "df_shakespeare_2 = pd.DataFrame.from_dict(shakespeare_part_2_features, orient = 'index')\n",
    "shakespeare_zscores_2 = zscores(df_shakespeare_2)\n",
    "shakespeare_zscores_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_test_2_features = features_generator(shakespeare_part_2_corpus_freq, shakespeare_test_2)\n",
    "df_shakespeare_test_2 = pd.DataFrame.from_dict(shakespeare_test_2_features, orient = 'index')\n",
    "shakespeare_zscores_test_2 = zscores(df_shakespeare_test_2)\n",
    "shakespeare_zscores_test_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_2_deltas = get_deltas(shakespeare_characters, shakespeare_zscores_test_2, shakespeare_zscores_2)\n",
    "predictions_shakespeare_2 = shakespeare_2_deltas.idxmin()\n",
    "shakespeare_df_2 = pd.DataFrame(predictions_shakespeare_2, columns = ['Part_2'])\n",
    "shakespeare_df_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigram_df_2 = model_predictions(shakespeare_bigrams_part_2, shakespeare_bigrams_test_2, 50, shakespeare_characters, 'Part_2')\n",
    "shakespeare_bigram_df_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_part_3_corpus = whole_corpus_generator(shakespeare_part_3)\n",
    "shakespeare_part_3_corpus_freq = list(nltk.FreqDist(shakespeare_part_3_corpus).most_common(50))\n",
    "shakespeare_part_3_features = features_generator(shakespeare_part_3_corpus_freq, shakespeare_part_3)\n",
    "df_shakespeare_3 = pd.DataFrame.from_dict(shakespeare_part_3_features, orient = 'index')\n",
    "shakespeare_zscores_3 = zscores(df_shakespeare_3)\n",
    "shakespeare_zscores_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_test_3_features = features_generator(shakespeare_part_3_corpus_freq, shakespeare_test_3)\n",
    "df_shakespeare_test_3 = pd.DataFrame.from_dict(shakespeare_test_3_features, orient = 'index')\n",
    "shakespeare_zscores_test_3 = zscores(df_shakespeare_test_3)\n",
    "shakespeare_zscores_test_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_3_deltas = get_deltas(shakespeare_characters, shakespeare_zscores_test_3, shakespeare_zscores_3)\n",
    "predictions_shakespeare_3 = shakespeare_3_deltas.idxmin()\n",
    "shakespeare_df_3 = pd.DataFrame(predictions_shakespeare_3, columns = ['Part_3'])\n",
    "shakespeare_df_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigram_df_3 = model_predictions(shakespeare_bigrams_part_3, shakespeare_bigrams_test_3, 50, shakespeare_characters, 'Part_3')\n",
    "shakespeare_bigram_df_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_part_4_corpus = whole_corpus_generator(shakespeare_part_4)\n",
    "shakespeare_part_4_corpus_freq = list(nltk.FreqDist(shakespeare_part_4_corpus).most_common(50))\n",
    "shakespeare_part_4_features = features_generator(shakespeare_part_4_corpus_freq, shakespeare_part_4)\n",
    "df_shakespeare_4 = pd.DataFrame.from_dict(shakespeare_part_4_features, orient = 'index')\n",
    "shakespeare_zscores_4 = zscores(df_shakespeare_4)\n",
    "shakespeare_zscores_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_test_4_features = features_generator(shakespeare_part_4_corpus_freq, shakespeare_test_4)\n",
    "df_shakespeare_test_4 = pd.DataFrame.from_dict(shakespeare_test_4_features, orient = 'index')\n",
    "shakespeare_zscores_test_4 = zscores(df_shakespeare_test_4)\n",
    "shakespeare_zscores_test_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_4_deltas = get_deltas(shakespeare_characters, shakespeare_zscores_test_4, shakespeare_zscores_4)\n",
    "predictions_shakespeare_4 = shakespeare_4_deltas.idxmin()\n",
    "shakespeare_df_4 = pd.DataFrame(predictions_shakespeare_4, columns = ['Part_4'])\n",
    "shakespeare_df_4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigram_df_4 = model_predictions(shakespeare_bigrams_part_4, shakespeare_bigrams_test_4, 50, shakespeare_characters, 'Part_4')\n",
    "shakespeare_bigram_df_4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_part_5_corpus = whole_corpus_generator(shakespeare_part_5)\n",
    "shakespeare_part_5_corpus_freq = list(nltk.FreqDist(shakespeare_part_5_corpus).most_common(50))\n",
    "shakespeare_part_5_features = features_generator(shakespeare_part_5_corpus_freq, shakespeare_part_5)\n",
    "df_shakespeare_5 = pd.DataFrame.from_dict(shakespeare_part_5_features, orient = 'index')\n",
    "shakespeare_zscores_5 = zscores(df_shakespeare_5)\n",
    "shakespeare_zscores_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_test_5_features = features_generator(shakespeare_part_5_corpus_freq, shakespeare_test_5)\n",
    "df_shakespeare_test_5 = pd.DataFrame.from_dict(shakespeare_test_5_features, orient = 'index')\n",
    "shakespeare_zscores_test_5 = zscores(df_shakespeare_test_5)\n",
    "shakespeare_zscores_test_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_5_deltas = get_deltas(shakespeare_characters, shakespeare_zscores_test_5, shakespeare_zscores_5)\n",
    "predictions_shakespeare_5 = shakespeare_5_deltas.idxmin()\n",
    "shakespeare_df_5 = pd.DataFrame(predictions_shakespeare_5, columns = ['Part_5'])\n",
    "shakespeare_df_5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_bigram_df_5 = model_predictions(shakespeare_bigrams_part_5, shakespeare_bigrams_test_5, 50, shakespeare_characters, 'Part_5')\n",
    "shakespeare_bigram_df_5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## William Shakespeare Characters Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_results = pd.concat([shakespeare_df_1, shakespeare_df_2, shakespeare_df_3, shakespeare_df_4, shakespeare_df_5], axis=1)\n",
    "shakespeare_results = success_rate(shakespeare_results)\n",
    "shakespeare_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5142857142857143"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_top_7_results = shakespeare_results.filter(items = shakespeare_top_7_characters, axis=0)\n",
    "shakespeare_top_7_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_top_7_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21904761904761907"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_bigram_results = pd.concat([shakespeare_bigram_df_1, shakespeare_bigram_df_2, shakespeare_bigram_df_3, shakespeare_bigram_df_4, shakespeare_bigram_df_5], axis =1)\n",
    "shakespeare_bigram_results = success_rate(shakespeare_bigram_results)\n",
    "shakespeare_bigram_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All top 7 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_7 = {**wilde_top_7, **shaw_top_7, **jonson_top_7, **shakespeare_top_7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top = corpus_split(all_top_7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_partition = split_partitions(all_top)\n",
    "all_top_test = split_test(all_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_part_1 = dict_word_tokenizer(all_top_partition[0])\n",
    "all_top_part_2 = dict_word_tokenizer(all_top_partition[1])\n",
    "all_top_part_3 = dict_word_tokenizer(all_top_partition[2])\n",
    "all_top_part_4 = dict_word_tokenizer(all_top_partition[3])\n",
    "all_top_part_5 = dict_word_tokenizer(all_top_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_test_1 = dict_word_tokenizer(all_top_test[0])\n",
    "all_top_test_2 = dict_word_tokenizer(all_top_test[1])\n",
    "all_top_test_3 = dict_word_tokenizer(all_top_test[2])\n",
    "all_top_test_4 = dict_word_tokenizer(all_top_test[3])\n",
    "all_top_test_5 = dict_word_tokenizer(all_top_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(all_top_partition[0]), 2)\n",
    "all_top_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(all_top_partition[1]), 2)\n",
    "all_top_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(all_top_partition[2]), 2)\n",
    "all_top_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(all_top_partition[3]), 2)\n",
    "all_top_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(all_top_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(all_top_test[0]), 2)\n",
    "all_top_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(all_top_test[1]), 2)\n",
    "all_top_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(all_top_test[2]), 2)\n",
    "all_top_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(all_top_test[3]), 2)\n",
    "all_top_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(all_top_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deltas Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burrows Delta Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_1 = model_predictions(all_top_part_1, all_top_test_1, 100, all_top_7, 'Part_1')\n",
    "all_df_2 = model_predictions(all_top_part_2, all_top_test_2, 100, all_top_7, 'Part_2')\n",
    "all_df_3 = model_predictions(all_top_part_3, all_top_test_3, 100, all_top_7, 'Part_3')\n",
    "all_df_4 = model_predictions(all_top_part_4, all_top_test_4, 100, all_top_7, 'Part_4')\n",
    "all_df_5 = model_predictions(all_top_part_5, all_top_test_5, 100, all_top_7, 'Part_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_df = pd.concat([all_df_1, all_df_2, all_df_3, all_df_4, all_df_5], axis = 1)\n",
    "all_top_df = success_rate(all_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285715"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_top_df['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_in_all_results = all_top_df.filter(items = wilde_top_7_characters, axis=0)\n",
    "shaw_in_all_results = all_top_df.filter(items = shaw_top_7_characters, axis=0)\n",
    "jonson_in_all_results = all_top_df.filter(items = jonson_top_7_characters, axis=0)\n",
    "shakespeare_in_all_results = all_top_df.filter(items = shakespeare_top_7_characters, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714285714285714"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9142857142857143"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jonson_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burrows Delta Method Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams_df_1 = model_predictions(all_top_bigrams_part_1, all_top_bigrams_test_1, 100, all_top_7, 'Part_1')\n",
    "all_bigrams_df_2 = model_predictions(all_top_bigrams_part_2, all_top_bigrams_test_2, 100, all_top_7, 'Part_2')\n",
    "all_bigrams_df_3 = model_predictions(all_top_bigrams_part_3, all_top_bigrams_test_3, 100, all_top_7, 'Part_3')\n",
    "all_bigrams_df_4 = model_predictions(all_top_bigrams_part_4, all_top_bigrams_test_4, 100, all_top_7, 'Part_4')\n",
    "all_bigrams_df_5 = model_predictions(all_top_bigrams_part_5, all_top_bigrams_test_5, 100, all_top_7, 'Part_5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_bigrams_df = pd.concat([all_bigrams_df_1, all_bigrams_df_2, all_bigrams_df_3, all_bigrams_df_4, all_bigrams_df_5], axis = 1)\n",
    "all_top_bigrams_df = success_rate(all_top_bigrams_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45000000000000007"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_top_bigrams_df['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_bigrams_in_all_results = all_top_bigrams_df.filter(items = wilde_top_7_characters, axis=0)\n",
    "shaw_bigrams_in_all_results = all_top_bigrams_df.filter(items = shaw_top_7_characters, axis=0)\n",
    "jonson_bigrams_in_all_results = all_top_bigrams_df.filter(items = jonson_top_7_characters, axis=0)\n",
    "shakespeare_bigrams_in_all_results = all_top_bigrams_df.filter(items = shakespeare_top_7_characters, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4571428571428572"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_bigrams_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571428571428571"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw_bigrams_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34285714285714286"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jonson_bigrams_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34285714285714286"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_bigrams_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedrich Schiller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters (+1500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_characters = {**kabale_und_liebe_characters, **die_verschwoerung_des_fiesco_zu_genua_characters, **die_räuber_characters, **die_jungfrau_von_orleans_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del schiller_characters['Frau']\n",
    "del schiller_characters['Sophie']\n",
    "del schiller_characters['Andreas']\n",
    "del schiller_characters['Bourgognino']\n",
    "del schiller_characters['Lomellon']\n",
    "del schiller_characters['Sacco']\n",
    "del schiller_characters['Grimm']\n",
    "del schiller_characters['Razmann']\n",
    "del schiller_characters['Schufterle']\n",
    "del schiller_characters['Roller']\n",
    "del schiller_characters['Kosisnky']\n",
    "del schiller_characters['Schwartz']\n",
    "del schiller_characters['La Hire']\n",
    "del schiller_characters['Lionel']\n",
    "del schiller_characters['Hofmarschall']\n",
    "del schiller_characters['Gianettino']\n",
    "del schiller_characters['Clacagno']\n",
    "del schiller_characters['Burgund']\n",
    "del schiller_characters['Sorel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(schiller_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_characters_split = corpus_split(schiller_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_characters_partition = split_partitions(schiller_characters_split)\n",
    "schiller_characters_test = split_test(schiller_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_part_1 = dict_word_tokenizer(schiller_characters_partition[0])\n",
    "schiller_part_2 = dict_word_tokenizer(schiller_characters_partition[1])\n",
    "schiller_part_3 = dict_word_tokenizer(schiller_characters_partition[2])\n",
    "schiller_part_4 = dict_word_tokenizer(schiller_characters_partition[3])\n",
    "schiller_part_5 = dict_word_tokenizer(schiller_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_test_1 = dict_word_tokenizer(schiller_characters_test[0])\n",
    "schiller_test_2 = dict_word_tokenizer(schiller_characters_test[1])\n",
    "schiller_test_3 = dict_word_tokenizer(schiller_characters_test[2])\n",
    "schiller_test_4 = dict_word_tokenizer(schiller_characters_test[3])\n",
    "schiller_test_5 = dict_word_tokenizer(schiller_characters_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_partition[0]), 2)\n",
    "schiller_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_partition[1]), 2)\n",
    "schiller_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_partition[2]), 2)\n",
    "schiller_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_partition[3]), 2)\n",
    "schiller_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_test[0]), 2)\n",
    "schiller_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_test[1]), 2)\n",
    "schiller_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_test[2]), 2)\n",
    "schiller_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_test[3]), 2)\n",
    "schiller_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(schiller_characters_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 6 characters (+4000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_top_6_characters = ['Ferdinand', 'Luise', 'Fiesco', 'Franz', 'Moor', 'Johanna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_top_6 = {}\n",
    "for key in schiller_characters:\n",
    "    if key in schiller_top_6_characters:\n",
    "        schiller_top_6[key] = schiller_characters[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burrows Delta Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_df_1 = model_predictions(schiller_part_1, schiller_test_1, 50, schiller_characters, 'Part_1')\n",
    "schiller_df_2 = model_predictions(schiller_part_2, schiller_test_2, 50, schiller_characters, 'Part_2')\n",
    "schiller_df_3 = model_predictions(schiller_part_3, schiller_test_3, 50, schiller_characters, 'Part_3')\n",
    "schiller_df_4 = model_predictions(schiller_part_4, schiller_test_4, 50, schiller_characters, 'Part_4')\n",
    "schiller_df_5 = model_predictions(schiller_part_5, schiller_test_5, 50, schiller_characters, 'Part_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_bigrams_df_1 = model_predictions(schiller_bigrams_part_1, schiller_bigrams_test_1, 50, schiller_characters, 'Part_1')\n",
    "schiller_bigrams_df_2 = model_predictions(schiller_bigrams_part_2, schiller_bigrams_test_2, 50, schiller_characters, 'Part_2')\n",
    "schiller_bigrams_df_3 = model_predictions(schiller_bigrams_part_3, schiller_bigrams_test_3, 50, schiller_characters, 'Part_3')\n",
    "schiller_bigrams_df_4 = model_predictions(schiller_bigrams_part_4, schiller_bigrams_test_4, 50, schiller_characters, 'Part_4')\n",
    "schiller_bigrams_df_5 = model_predictions(schiller_bigrams_part_5, schiller_bigrams_test_5, 50, schiller_characters, 'Part_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_results = pd.concat([schiller_df_1, schiller_df_2, schiller_df_3, schiller_df_4, schiller_df_5], axis = 1)\n",
    "schiller_results = success_rate(schiller_results)\n",
    "schiller_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529411764705882"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schiller_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_bigrams_results = pd.concat([schiller_bigrams_df_1, schiller_bigrams_df_2, schiller_bigrams_df_3, schiller_bigrams_df_4, schiller_bigrams_df_5], axis = 1)\n",
    "schiller_bigrams_results = success_rate(schiller_bigrams_results)\n",
    "schiller_bigrams_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10588235294117647"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schiller_bigrams_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ferdinand</th>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luise</th>\n",
       "      <td>Luise</td>\n",
       "      <td>Luise</td>\n",
       "      <td>Luise</td>\n",
       "      <td>Luise</td>\n",
       "      <td>Luise</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiesco</th>\n",
       "      <td>Fiesco</td>\n",
       "      <td>Fiesco</td>\n",
       "      <td>Verrina</td>\n",
       "      <td>Fiesco</td>\n",
       "      <td>Fiesco</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franz</th>\n",
       "      <td>Franz</td>\n",
       "      <td>Fiesco</td>\n",
       "      <td>Franz</td>\n",
       "      <td>Franz</td>\n",
       "      <td>Franz</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moor</th>\n",
       "      <td>Moor</td>\n",
       "      <td>Moor</td>\n",
       "      <td>Franz</td>\n",
       "      <td>Moor</td>\n",
       "      <td>Moor</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Johanna</th>\n",
       "      <td>Johanna</td>\n",
       "      <td>Johanna</td>\n",
       "      <td>Johanna</td>\n",
       "      <td>Fiesco</td>\n",
       "      <td>Johanna</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Part_1     Part_2     Part_3     Part_4     Part_5  Results\n",
       "Ferdinand  Ferdinand  Ferdinand  Ferdinand  Ferdinand  Ferdinand      1.0\n",
       "Luise          Luise      Luise      Luise      Luise      Luise      1.0\n",
       "Fiesco        Fiesco     Fiesco    Verrina     Fiesco     Fiesco      0.8\n",
       "Franz          Franz     Fiesco      Franz      Franz      Franz      0.8\n",
       "Moor            Moor       Moor      Franz       Moor       Moor      0.8\n",
       "Johanna      Johanna    Johanna    Johanna     Fiesco    Johanna      0.8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schiller_top_6_results = schiller_results.filter(items = schiller_top_6_characters, axis=0)\n",
    "schiller_top_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666666"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schiller_top_6_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Johann Wolfgang von Goethe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters (+1500 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_characters = {**faust_1_characters, **faust2_characters, **egmont_characters, **iphigenie_auf_tauris_characters, **die_laune_des_verliebten_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del goethe_characters['Die Hexe']\n",
    "del goethe_characters['Kanzler']\n",
    "del goethe_characters['Gemurmel']\n",
    "del goethe_characters['Herold']\n",
    "del goethe_characters['Plutus']\n",
    "del goethe_characters['Heer Meister']\n",
    "del goethe_characters['Marcshalk']\n",
    "del goethe_characters['Homunculus']\n",
    "del goethe_characters['Sirenen']\n",
    "del goethe_characters['Mutter']\n",
    "del goethe_characters['Machiavel']\n",
    "del goethe_characters['Klare']\n",
    "del goethe_characters['Brackenburg']\n",
    "del goethe_characters['Soest']\n",
    "del goethe_characters['Sekretär']\n",
    "del goethe_characters['Thoas']\n",
    "del goethe_characters['Arkas']\n",
    "del goethe_characters['Amine']\n",
    "del goethe_characters['Eridon']\n",
    "del goethe_characters['Lamon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(goethe_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_characters_split = corpus_split(goethe_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_characters_partition = split_partitions(goethe_characters_split)\n",
    "goethe_characters_test = split_test(goethe_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_part_1 = dict_word_tokenizer(goethe_characters_partition[0])\n",
    "goethe_part_2 = dict_word_tokenizer(goethe_characters_partition[1])\n",
    "goethe_part_3 = dict_word_tokenizer(goethe_characters_partition[2])\n",
    "goethe_part_4 = dict_word_tokenizer(goethe_characters_partition[3])\n",
    "goethe_part_5 = dict_word_tokenizer(goethe_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_test_1 = dict_word_tokenizer(goethe_characters_test[0])\n",
    "goethe_test_2 = dict_word_tokenizer(goethe_characters_test[1])\n",
    "goethe_test_3 = dict_word_tokenizer(goethe_characters_test[2])\n",
    "goethe_test_4 = dict_word_tokenizer(goethe_characters_test[3])\n",
    "goethe_test_5 = dict_word_tokenizer(goethe_characters_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_partition[0]), 2)\n",
    "goethe_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_partition[1]), 2)\n",
    "goethe_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_partition[2]), 2)\n",
    "goethe_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_partition[3]), 2)\n",
    "goethe_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_test[0]), 2)\n",
    "goethe_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_test[1]), 2)\n",
    "goethe_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_test[2]), 2)\n",
    "goethe_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_test[3]), 2)\n",
    "goethe_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(goethe_characters_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tp 6 characters (+4000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_top_6_characters = ['Faust', 'Mephistopheles', 'Faust II', 'Mephistopheles II', 'Egmont', 'Iphigenie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_top_6 = {}\n",
    "for key in goethe_characters:\n",
    "    if key in goethe_top_6_characters:\n",
    "        goethe_top_6[key] = goethe_characters[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burrows Delta Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_df_1 = model_predictions(goethe_part_1, goethe_test_1, 50, goethe_characters, 'Part_1')\n",
    "goethe_df_2 = model_predictions(goethe_part_2, goethe_test_2, 50, goethe_characters, 'Part_2')\n",
    "goethe_df_3 = model_predictions(goethe_part_3, goethe_test_3, 50, goethe_characters, 'Part_3')\n",
    "goethe_df_4 = model_predictions(goethe_part_4, goethe_test_4, 50, goethe_characters, 'Part_4')\n",
    "goethe_df_5 = model_predictions(goethe_part_5, goethe_test_5, 50, goethe_characters, 'Part_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_bigrams_df_1 = model_predictions(goethe_bigrams_part_1, goethe_bigrams_test_1, 50, goethe_characters, 'Part_1')\n",
    "goethe_bigrams_df_2 = model_predictions(goethe_bigrams_part_2, goethe_bigrams_test_2, 50, goethe_characters, 'Part_2')\n",
    "goethe_bigrams_df_3 = model_predictions(goethe_bigrams_part_3, goethe_bigrams_test_3, 50, goethe_characters, 'Part_3')\n",
    "goethe_bigrams_df_4 = model_predictions(goethe_bigrams_part_4, goethe_bigrams_test_4, 50, goethe_characters, 'Part_4')\n",
    "goethe_bigrams_df_5 = model_predictions(goethe_bigrams_part_5, goethe_bigrams_test_5, 50, goethe_characters, 'Part_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_results = pd.concat([goethe_df_1, goethe_df_2, goethe_df_3, goethe_df_4, goethe_df_5], axis = 1)\n",
    "goethe_results = success_rate(goethe_results)\n",
    "goethe_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933333333333334"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goethe_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "goethe_bigrams_results = pd.concat([goethe_bigrams_df_1, goethe_bigrams_df_2, goethe_bigrams_df_3, goethe_bigrams_df_4, goethe_bigrams_df_5], axis = 1)\n",
    "goethe_bigrams_results = success_rate(goethe_bigrams_results)\n",
    "goethe_bigrams_results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14666666666666667"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goethe_bigrams_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_1</th>\n",
       "      <th>Part_2</th>\n",
       "      <th>Part_3</th>\n",
       "      <th>Part_4</th>\n",
       "      <th>Part_5</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Faust</th>\n",
       "      <td>Faust</td>\n",
       "      <td>Faust</td>\n",
       "      <td>Faust</td>\n",
       "      <td>Faust</td>\n",
       "      <td>Faust</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mephistopheles</th>\n",
       "      <td>Mephistopheles</td>\n",
       "      <td>Mephistopheles</td>\n",
       "      <td>Mephistopheles</td>\n",
       "      <td>Mephistopheles</td>\n",
       "      <td>Mephistopheles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faust II</th>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>Faust II</td>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>Faust</td>\n",
       "      <td>Faust II</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mephistopheles II</th>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>Mephistopheles II</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Egmont</th>\n",
       "      <td>Egmont</td>\n",
       "      <td>Egmont</td>\n",
       "      <td>Egmont</td>\n",
       "      <td>Egmont</td>\n",
       "      <td>Egmont</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iphigenie</th>\n",
       "      <td>Faust</td>\n",
       "      <td>Iphigenie</td>\n",
       "      <td>Iphigenie</td>\n",
       "      <td>Iphigenie</td>\n",
       "      <td>Iphigenie</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Part_1             Part_2             Part_3  \\\n",
       "Faust                          Faust              Faust              Faust   \n",
       "Mephistopheles        Mephistopheles     Mephistopheles     Mephistopheles   \n",
       "Faust II           Mephistopheles II           Faust II  Mephistopheles II   \n",
       "Mephistopheles II  Mephistopheles II  Mephistopheles II  Mephistopheles II   \n",
       "Egmont                        Egmont             Egmont             Egmont   \n",
       "Iphigenie                      Faust          Iphigenie          Iphigenie   \n",
       "\n",
       "                              Part_4             Part_5  Results  \n",
       "Faust                          Faust              Faust      1.0  \n",
       "Mephistopheles        Mephistopheles     Mephistopheles      1.0  \n",
       "Faust II                       Faust           Faust II      0.4  \n",
       "Mephistopheles II  Mephistopheles II  Mephistopheles II      1.0  \n",
       "Egmont                        Egmont             Egmont      1.0  \n",
       "Iphigenie                  Iphigenie          Iphigenie      0.8  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goethe_top_6_results = goethe_results.filter(items = goethe_top_6_characters, axis=0)\n",
    "goethe_top_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goethe_top_6_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both top 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_6 = {**schiller_top_6, **goethe_top_6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top = corpus_split(both_top_6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_partition = split_partitions(both_top)\n",
    "both_top_test = split_test(both_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_part_1 = dict_word_tokenizer(both_top_partition[0])\n",
    "both_top_part_2 = dict_word_tokenizer(both_top_partition[1])\n",
    "both_top_part_3 = dict_word_tokenizer(both_top_partition[2])\n",
    "both_top_part_4 = dict_word_tokenizer(both_top_partition[3])\n",
    "both_top_part_5 = dict_word_tokenizer(both_top_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_test_1 = dict_word_tokenizer(both_top_test[0])\n",
    "both_top_test_2 = dict_word_tokenizer(both_top_test[1])\n",
    "both_top_test_3 = dict_word_tokenizer(both_top_test[2])\n",
    "both_top_test_4 = dict_word_tokenizer(both_top_test[3])\n",
    "both_top_test_5 = dict_word_tokenizer(both_top_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_bigrams_part_1 = ngrams_tokenizer(dict_word_tokenizer(both_top_partition[0]), 2)\n",
    "both_top_bigrams_part_2 = ngrams_tokenizer(dict_word_tokenizer(both_top_partition[1]), 2)\n",
    "both_top_bigrams_part_3 = ngrams_tokenizer(dict_word_tokenizer(both_top_partition[2]), 2)\n",
    "both_top_bigrams_part_4 = ngrams_tokenizer(dict_word_tokenizer(both_top_partition[3]), 2)\n",
    "both_top_bigrams_part_5 = ngrams_tokenizer(dict_word_tokenizer(both_top_partition[4]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_bigrams_test_1 = ngrams_tokenizer(dict_word_tokenizer(both_top_test[0]), 2)\n",
    "both_top_bigrams_test_2 = ngrams_tokenizer(dict_word_tokenizer(both_top_test[1]), 2)\n",
    "both_top_bigrams_test_3 = ngrams_tokenizer(dict_word_tokenizer(both_top_test[2]), 2)\n",
    "both_top_bigrams_test_4 = ngrams_tokenizer(dict_word_tokenizer(both_top_test[3]), 2)\n",
    "both_top_bigrams_test_5 = ngrams_tokenizer(dict_word_tokenizer(both_top_test[4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burrows Delta Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df_1 = model_predictions(both_top_part_1, both_top_test_1, 100, both_top_6, 'Part_1')\n",
    "both_df_2 = model_predictions(both_top_part_2, both_top_test_2, 100, both_top_6, 'Part_2')\n",
    "both_df_3 = model_predictions(both_top_part_3, both_top_test_3, 100, both_top_6, 'Part_3')\n",
    "both_df_4 = model_predictions(both_top_part_4, both_top_test_4, 100, both_top_6, 'Part_4')\n",
    "both_df_5 = model_predictions(both_top_part_5, both_top_test_5, 100, both_top_6, 'Part_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_df = pd.concat([both_df_1, both_df_2, both_df_3, both_df_4, both_df_5], axis = 1)\n",
    "both_top_df = success_rate(both_top_df)\n",
    "both_top_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_top_df['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "schiller_in_all_results = both_top_df.filter(items = schiller_top_6_characters, axis=0)\n",
    "goethe_in_all_results = both_top_df.filter(items = goethe_top_6_characters, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schiller_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goethe_in_all_results['Results'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burrows Delta Method Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_bigrams_df_1 = model_predictions(both_top_bigrams_part_1, both_top_bigrams_test_1, 100, both_top_6, 'Part_1')\n",
    "both_bigrams_df_2 = model_predictions(both_top_bigrams_part_2, both_top_bigrams_test_2, 100, both_top_6, 'Part_2')\n",
    "both_bigrams_df_3 = model_predictions(both_top_bigrams_part_3, both_top_bigrams_test_3, 100, both_top_6, 'Part_3')\n",
    "both_bigrams_df_4 = model_predictions(both_top_bigrams_part_4, both_top_bigrams_test_4, 100, both_top_6, 'Part_4')\n",
    "both_bigrams_df_5 = model_predictions(both_top_bigrams_part_5, both_top_bigrams_test_5, 100, both_top_6, 'Part_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_top_bigrams_df = pd.concat([both_bigrams_df_1, both_bigrams_df_2, both_bigrams_df_3, both_bigrams_df_4, both_bigrams_df_5], axis = 1)\n",
    "both_top_bigrams_df = success_rate(both_top_bigrams_df)\n",
    "both_top_bigrams_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23333333333333336"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_top_bigrams_df['Results'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
