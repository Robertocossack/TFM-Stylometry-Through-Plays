{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_braquets = \"\\[.*?]\"\n",
    "normal_braquets = \"\\(.*?\\)\"\n",
    "squared_to_point = \"\\\\[.*?\\.\"\n",
    "normal_to_point = \"\\\\(.*?\\.\"\n",
    "nothing = \"xxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraphs_cleaner(file, regex1, regex2): #Two in one function\n",
    "    f = open(file, \"r\")\n",
    "    contents = f.read()         \n",
    "    f.close()     \n",
    "    paragraph_cutter = re.sub('\\n{2,}', '\\n\\n', contents) #Paragraph identifier\n",
    "    paragraphs = paragraph_cutter.split('\\n\\n') #It cuts the paragraphs by the identifier points\n",
    "    clean_result = []\n",
    "    for par in paragraphs:\n",
    "        output = re.sub(\"\\\\n\", \" \", par) # Removes the new-line characters within the paragraphs\n",
    "        pseudo_clean = re.sub(regex1 , \"\", output) # Removes the additional text in brackets\n",
    "        clean = re.sub(regex2 , \"\", pseudo_clean)\n",
    "        clean_result.append(clean)\n",
    "    result = []\n",
    "    for par in clean_result:\n",
    "        output = nltk.word_tokenize(par) #Word tokenizer for each paragraph\n",
    "        result.append(output)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters_details (play_characters):\n",
    "    for key in play_characters:\n",
    "        word_count = 0\n",
    "        for sen in play_characters[key]:\n",
    "            output = len(re.findall(r\"\\w+\", sen))\n",
    "            word_count += output\n",
    "        print ('%s contains %d sentences and %d words'%(key, len(play_characters[key]), word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_cleaner (character_raw, n): #With positional name cutter\n",
    "    no_name = []\n",
    "    for sen in character_raw:\n",
    "        output = sen[n:]\n",
    "        no_name.append(output)\n",
    "    output = []\n",
    "    for par in no_name:\n",
    "        for word in par:\n",
    "            output.append(word)\n",
    "    one_string = \" \".join(output)\n",
    "    result = nltk.sent_tokenize(one_string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_cleaner_by_name (character_raw, name1, name2, name3):\n",
    "    for sen in character_raw:\n",
    "        if name1 in sen:\n",
    "            sen.remove(name1)\n",
    "    for sen in character_raw:\n",
    "        if name2 in sen:\n",
    "            sen.remove(name2)\n",
    "    for sen in character_raw:\n",
    "        if name3 in sen:\n",
    "            sen.remove(name3)\n",
    "    output = string_joiner(character_raw)\n",
    "    for sen in  output: #Removes the single points sentences for a best estimation of the lenghth\n",
    "        if sen == '.':\n",
    "            output.remove(sen)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def string_joiner(strings):\n",
    "    output = []\n",
    "    for string in strings:\n",
    "        for word in string:\n",
    "            output.append(word)\n",
    "    one_string = \" \".join(output)\n",
    "    result = nltk.sent_tokenize(one_string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_filter (character):\n",
    "    output = []\n",
    "    for sen in character:\n",
    "        if len(sen) > 1:\n",
    "            output.append(sen)\n",
    "    result = string_joiner(output)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Ideal Husband - Oscar Wilde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aih = paragraphs_cleaner(\"an_ideal_husband_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aih = token_paragraphs_aih[48:]  #Comienzo de la obra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "caversham_raw = []\n",
    "goring_raw = []\n",
    "chiltern_raw = []\n",
    "ladychiltern_raw = []\n",
    "mabel_raw = []\n",
    "cheveley_raw = []\n",
    "for par in token_paragraphs_aih:\n",
    "    if 'CAVERSHAM' in par:\n",
    "        caversham_raw.append(par)\n",
    "    if 'GORING' in par:\n",
    "        goring_raw.append(par)\n",
    "    if 'ROBERT' in par:\n",
    "        chiltern_raw.append(par)\n",
    "    if 'LADY' and 'CHILTERN' in par and not 'MABEL' in par and not 'SIR' in par:\n",
    "        ladychiltern_raw.append(par)\n",
    "    if 'MABEL' in par:\n",
    "        mabel_raw.append(par)\n",
    "    if 'CHEVELEY' in par:\n",
    "        cheveley_raw.append(par)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "caversham = character_cleaner(caversham_raw, 3)\n",
    "goring = character_cleaner(goring_raw, 3)\n",
    "chiltern = character_cleaner(chiltern_raw, 4)\n",
    "ladychiltern = character_cleaner(ladychiltern_raw, 3)\n",
    "mabel = character_cleaner(mabel_raw, 3)\n",
    "cheveley = character_cleaner(cheveley_raw, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ideal_husband_characters = {'Caversham':caversham, 'Goring':goring, 'Chiltern':chiltern, 'Lady Chiltern':ladychiltern, 'Mabel':mabel, 'Cheveley':cheveley}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caversham contains 213 sentences and 1507 words\n",
      "Goring contains 796 sentences and 6233 words\n",
      "Chiltern contains 537 sentences and 4937 words\n",
      "Lady Chiltern contains 381 sentences and 2917 words\n",
      "Mabel contains 242 sentences and 1937 words\n",
      "Cheveley contains 534 sentences and 4380 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(an_ideal_husband_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Woman of No Importance - Oscar Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_awoni = paragraphs_cleaner(\"a_woman_of_no_importance_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    " token_paragraphs_awoni = token_paragraphs_awoni[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "illingworth_raw = []\n",
    "allonby_raw = []\n",
    "gerald_raw = []\n",
    "mrsarbuthnot_raw = []\n",
    "hunstanton_raw = []\n",
    "hester_raw = []\n",
    "\n",
    "for par in token_paragraphs_awoni:\n",
    "    if 'ILLINGWORTH' in par:\n",
    "        illingworth_raw.append(par)\n",
    "    if 'ALLONBY' in par:\n",
    "        allonby_raw.append(par)\n",
    "    if 'GERALD' in par:\n",
    "        gerald_raw.append(par)\n",
    "    if 'MRS' and 'ARBUTHNOT' in par:\n",
    "        mrsarbuthnot_raw.append(par)\n",
    "    if 'HUNSTANTON' in par:\n",
    "        hunstanton_raw.append(par)\n",
    "    if 'HESTER' in par:\n",
    "        hester_raw.append(par)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "illingworth = character_cleaner(illingworth_raw, 3)\n",
    "allonby = character_cleaner(allonby_raw, 3)\n",
    "gerald = character_cleaner(gerald_raw, 2)\n",
    "mrsarbuthnot = character_cleaner(mrsarbuthnot_raw, 2)\n",
    "hunstanton = character_cleaner(hunstanton_raw, 2)\n",
    "hester = character_cleaner(hester_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_woman_of_no_importance_characters = {'Illingorth':illingworth, 'Allonby':allonby, 'Gerald':gerald, 'Mrs Artbuthnot':mrsarbuthnot, 'Hunstanton':hunstanton, 'Hester':hester}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illingorth contains 428 sentences and 4183 words\n",
      "Allonby contains 213 sentences and 2091 words\n",
      "Gerald contains 259 sentences and 2427 words\n",
      "Mrs Artbuthnot contains 498 sentences and 3079 words\n",
      "Hunstanton contains 479 sentences and 3658 words\n",
      "Hester contains 142 sentences and 1342 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(a_woman_of_no_importance_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Lady Windermer's Fan - Oscar Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_lwf = paragraphs_cleaner(\"lady_windermeres_fan_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_lwf = token_paragraphs_lwf[47:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lordwindermere_raw = []\n",
    "erlynne_raw = []\n",
    "augustus_raw = []\n",
    "windermere_raw = []\n",
    "darlington_raw = []\n",
    "berwick_raw = []\n",
    "for par in token_paragraphs_lwf:\n",
    "    if 'LORD' and 'WINDERMERE' in par and not 'LADY' in par:\n",
    "        lordwindermere_raw.append(par)\n",
    "    if 'ERLYNNE' in par:\n",
    "        erlynne_raw.append(par)\n",
    "    if 'AUGUSTUS' in par:\n",
    "        augustus_raw.append(par)\n",
    "    if 'LADY' and 'WINDERMERE' in par:\n",
    "        windermere_raw.append(par)\n",
    "    if 'DARLINGTON' in par:\n",
    "        darlington_raw.append(par)\n",
    "    if 'BERWICK' in par:\n",
    "        berwick_raw.append(par)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lordwindermere = character_cleaner(lordwindermere_raw, 3)\n",
    "erlynne = character_cleaner(erlynne_raw, 3)\n",
    "augustus = character_cleaner(augustus_raw, 3)\n",
    "windermere = character_cleaner(windermere_raw, 3)\n",
    "darlington = character_cleaner(darlington_raw,3)\n",
    "berwick = character_cleaner(berwick_raw, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lady_windermeres_fan_characters = {'Lord Windermere':lordwindermere, 'Erlynne':erlynne, 'Augustus':augustus, 'Lady Windermere':windermere, 'Darlington':darlington, 'Berwick':berwick}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord Windermere contains 234 sentences and 2138 words\n",
      "Erlynne contains 395 sentences and 3521 words\n",
      "Augustus contains 95 sentences and 628 words\n",
      "Lady Windermere contains 743 sentences and 6027 words\n",
      "Darlington contains 192 sentences and 1704 words\n",
      "Berwick contains 234 sentences and 2037 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(lady_windermeres_fan_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Importance of Being Earnest - Oscar Wilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_tiobe = paragraphs_cleaner(\"the_importance_of_being_earnest_wilde.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_tiobe = token_paragraphs_tiobe[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "jack_raw = []\n",
    "algernon_raw = []\n",
    "gwendolen_raw = []\n",
    "bracknell_raw = []\n",
    "cecily_raw = []\n",
    "prism_raw = []\n",
    "chasuble_raw = []\n",
    "for par in token_paragraphs_tiobe:\n",
    "    if 'Jack' in par[0:1]:\n",
    "        jack_raw.append(par)\n",
    "    if 'Algernon' in par[0:1]:\n",
    "        algernon_raw.append(par)\n",
    "    if 'Gwendolen' in par[0:1]:\n",
    "        gwendolen_raw.append(par)\n",
    "    if 'Bracknell' in par[0:2]:\n",
    "        bracknell_raw.append(par)\n",
    "    if 'Cecily' in par[0:1]:\n",
    "        cecily_raw.append(par)\n",
    "    if 'Prism' in par[0:2]:\n",
    "        prism_raw.append(par)\n",
    "    if 'Chasuble' in par[0:1]:\n",
    "        chasuble_raw.append(par)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jack = character_cleaner(jack_raw, 2)\n",
    "algernon = character_cleaner(algernon_raw, 2)\n",
    "gwendolen = character_cleaner(gwendolen_raw, 2)\n",
    "bracknell = character_cleaner(bracknell_raw, 3)\n",
    "cecily = character_cleaner(cecily_raw, 3)\n",
    "prism = character_cleaner(prism_raw, 3)\n",
    "chasuble = character_cleaner(chasuble_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_importance_of_being_earnest_characters = {'Jack':jack, 'Algernon':algernon, 'Gwendolen':gwendolen, 'Bracknell':bracknell, 'Cecily':cecily, 'Prism':prism, 'Chasuble':chasuble}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack contains 492 sentences and 4161 words\n",
      "Algernon contains 451 sentences and 4116 words\n",
      "Gwendolen contains 247 sentences and 2242 words\n",
      "Bracknell contains 285 sentences and 2936 words\n",
      "Cecily contains 296 sentences and 2638 words\n",
      "Prism contains 102 sentences and 960 words\n",
      "Chasuble contains 82 sentences and 778 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(the_importance_of_being_earnest_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pygmalion - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_p = paragraphs_cleaner(\"pygmalion_shaw.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_p = token_paragraphs_p[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickering_raw = []\n",
    "higgins_raw = []\n",
    "liza_raw = []\n",
    "gentleman_raw = []\n",
    "taker_raw = []\n",
    "girl_raw = []\n",
    "mrshiggins_raw = []\n",
    "doolittle_raw = []\n",
    "for par in token_paragraphs_p:\n",
    "    if 'PICKERING' in par:\n",
    "        pickering_raw.append(par)\n",
    "    if 'HIGGINS' in par and not 'MRS.'in par:\n",
    "        higgins_raw.append(par)\n",
    "    if 'LIZA' in par:\n",
    "        liza_raw.append(par)\n",
    "    if 'GENTLEMAN' in par:\n",
    "        gentleman_raw.append(par)\n",
    "    if 'TAKER' in par:\n",
    "        taker_raw.append(par)\n",
    "    if 'GIRL' in par:\n",
    "        girl_raw.append(par)\n",
    "    if 'MRS.' in par and 'HIGGINS' in par[0:2]:\n",
    "        mrshiggins_raw.append(par)\n",
    "    if 'DOOLITTLE' in par:\n",
    "        doolittle_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickering = character_cleaner_by_name(pickering_raw, 'PICKERING', 'xxxxxx', 'xxxxxx')\n",
    "higgins = character_cleaner_by_name(higgins_raw, 'HIGGINS', 'xxxxx', 'xxxxx')\n",
    "liza = character_cleaner_by_name(liza_raw, 'LIZA', 'xxxxx', 'xxxxx')\n",
    "gentelman = character_cleaner_by_name(gentleman_raw, 'THE', 'GENTLEMAN', 'xxxxx')\n",
    "taker = character_cleaner_by_name(taker_raw, 'THE', 'NOTE', 'TAKER')\n",
    "girl = character_cleaner_by_name(girl_raw, 'THE', 'FLOWER', 'GIRL')\n",
    "mrshiggins = character_cleaner_by_name(mrshiggins_raw, 'MRS', 'MRS.', 'HIGGINS')\n",
    "doolittle = character_cleaner_by_name(doolittle_raw, 'DOOLITTLE', 'xxxxxx', 'xxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same characters, just been joined afterwards due to computational convenience\n",
    "pickering = pickering + gentelman\n",
    "higgins = higgins + taker\n",
    "liza = liza + girl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygmalion_character = {'Pickering':pickering, 'Higgins':higgins, 'Liza':liza, 'Mrs Higgins':mrshiggins, 'Doolittle':doolittle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickering contains 251 sentences and 1774 words\n",
      "Higgins contains 869 sentences and 7394 words\n",
      "Liza contains 495 sentences and 4820 words\n",
      "Mrs Higgins contains 178 sentences and 1466 words\n",
      "Doolittle contains 285 sentences and 2950 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(pygmalion_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Androcles and the Lion - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aatl = paragraphs_cleaner(\"androcles_and_the_lion_shaw.txt\", normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_aatl = token_paragraphs_aatl[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavinia_raw = []\n",
    "captain_raw = []\n",
    "androcles_raw = []\n",
    "megaera_raw = []\n",
    "centurion_raw = []\n",
    "spintho_raw = []\n",
    "ferrovius_raw = []\n",
    "for par in token_paragraphs_aatl:\n",
    "    if 'LAVINIA' in par:\n",
    "        lavinia_raw.append(par)\n",
    "    if 'CAPTAIN' in par:\n",
    "        captain_raw.append(par)\n",
    "    if 'ANDROCLES' in par:\n",
    "        androcles_raw.append(par)\n",
    "    if 'MEGAERA' in par:\n",
    "        megaera_raw.append(par)\n",
    "    if 'CENTURION' in par:\n",
    "        centurion_raw.append(par)\n",
    "    if 'SPINTHO' in par:\n",
    "        spintho_raw.append(par)\n",
    "    if 'FERROVIUS' in par:\n",
    "        ferrovius_raw.append(par)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lavinia = character_cleaner_by_name(lavinia_raw, 'LAVINIA', 'xxxx', 'xxxx')\n",
    "captain = character_cleaner_by_name(captain_raw, 'CAPTAIN', 'xxxx', 'xxxx')\n",
    "androcles = character_cleaner_by_name(androcles_raw, 'ANDROCLES', 'xxxx', 'xxxx')\n",
    "megaera = character_cleaner_by_name(megaera_raw, 'MEGAERA', 'xxxx', 'xxxx')\n",
    "centurion = character_cleaner_by_name(centurion_raw, 'CENTURION', 'xxxx', 'xxxx')\n",
    "spintho = character_cleaner_by_name(spintho_raw, 'SPINTHO', 'xxxx', 'xxxx')\n",
    "ferrovius = character_cleaner_by_name(ferrovius_raw, 'FERROVIUS', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "androcles_and_the_lion_characters = {'Lavinia':lavinia, 'Captain':captain, 'Androcles':androcles, 'Megaera':megaera, 'Centurion':centurion, 'Spintho':spintho, 'Ferrovius':ferrovius}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lavinia contains 173 sentences and 1637 words\n",
      "Captain contains 155 sentences and 1548 words\n",
      "Androcles contains 219 sentences and 1864 words\n",
      "Megaera contains 68 sentences and 671 words\n",
      "Centurion contains 93 sentences and 590 words\n",
      "Spintho contains 57 sentences and 390 words\n",
      "Ferrovius contains 184 sentences and 1454 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(androcles_and_the_lion_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caesar and Cleopatra - George Bernard Shaw    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cac = paragraphs_cleaner(\"caesar_and_cleopatra_shaw.txt\", normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cac = token_paragraphs_cac[18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_raw = []\n",
    "cleopatra_raw = []\n",
    "pothinus_raw = []\n",
    "rufio_raw = []\n",
    "ftatateeta_raw =[]\n",
    "apollodorus_raw = []\n",
    "for par in token_paragraphs_cac:\n",
    "    if 'CAESAR' in par:\n",
    "        caesar_raw.append(par)\n",
    "    if 'CLEOPATRA' in par:\n",
    "        cleopatra_raw.append(par)\n",
    "    if 'POTHINUS' in par:\n",
    "        pothinus_raw.append(par)\n",
    "    if 'RUFIO' in par:\n",
    "        rufio_raw.append(par)\n",
    "    if 'FTATATEETA' in par:\n",
    "        ftatateeta_raw.append(par)\n",
    "    if 'APOLLODORUS' in par:\n",
    "        apollodorus_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar = character_cleaner_by_name(caesar_raw, 'CAESAR', 'xxxx', 'xxxx')\n",
    "cleopatra = character_cleaner_by_name(cleopatra_raw, 'CLEOPATRA', 'xxxx', 'xxxx')\n",
    "pothinus = character_cleaner_by_name(pothinus_raw, 'POTHINUS', 'xxxx', 'xxxx')\n",
    "rufio = character_cleaner_by_name(rufio_raw, 'RUFIO', 'xxxx', 'xxxx')\n",
    "ftatateeta = character_cleaner_by_name(ftatateeta_raw, 'FTATATEETA', 'xxxx', 'xxxx')\n",
    "apollodorus = character_cleaner_by_name(apollodorus_raw, 'APOLLODORUS', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar_and_cleopatra_characters = {'Caesar':caesar, 'Cleopatra':cleopatra, 'Pothinus':pothinus, 'Rufio':rufio, 'Ftatateeta':ftatateeta, 'Apollodorus':apollodorus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caesar contains 756 sentences and 6016 words\n",
      "Cleopatra contains 554 sentences and 4494 words\n",
      "Pothinus contains 118 sentences and 1163 words\n",
      "Rufio contains 268 sentences and 2067 words\n",
      "Ftatateeta contains 110 sentences and 1012 words\n",
      "Apollodorus contains 188 sentences and 1653 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(caesar_and_cleopatra_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candida - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_can = paragraphs_cleaner(\"candida_shaw.txt\", normal_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_can = token_paragraphs_can[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "candida_raw = []\n",
    "marchbanks_raw =[]\n",
    "morell_raw = []\n",
    "burgess_raw = []\n",
    "proserpine_raw = []\n",
    "for par in token_paragraphs_can:\n",
    "    if 'CANDIDA' in par:\n",
    "        candida_raw.append(par)\n",
    "    if 'MARCHBANKS' in par:\n",
    "        marchbanks_raw.append(par)\n",
    "    if 'MORELL' in par:\n",
    "        morell_raw.append(par)\n",
    "    if 'BURGESS' in par:\n",
    "        burgess_raw.append(par)\n",
    "    if 'PROSERPINE' in par:\n",
    "        proserpine_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "candida = character_cleaner_by_name(candida_raw, 'CANDIDA', 'xxxx', 'xxxx')\n",
    "marchbanks = character_cleaner_by_name(marchbanks_raw, 'MARCHBANKS', 'xxxx', 'xxxx')\n",
    "morell = character_cleaner_by_name(morell_raw, 'MORELL', 'xxxx', 'xxxx')\n",
    "burgess = character_cleaner_by_name(burgess_raw, 'BURGESS', 'xxxx', 'xxxx')\n",
    "proserpine = character_cleaner_by_name(proserpine_raw, 'PROSERPINE', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "candida_characters = {'Candida':candida, 'Marchbanks':marchbanks, 'Morell':morell, 'Burgess':burgess, 'Proserpine':proserpine}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candida contains 354 sentences and 3208 words\n",
      "Marchbanks contains 388 sentences and 3832 words\n",
      "Morell contains 443 sentences and 4022 words\n",
      "Burgess contains 238 sentences and 2237 words\n",
      "Proserpine contains 147 sentences and 1195 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(candida_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Man And Superman - George Bernard Shaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_mas = paragraphs_cleaner(\"man_and_superman_shaw.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_mas = token_paragraphs_mas[54:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsden_raw = []\n",
    "octavius_raw = []\n",
    "tanner_raw = []\n",
    "ann_raw = []\n",
    "whitefield_raw = []\n",
    "missramsden_raw = []\n",
    "violet_raw = []\n",
    "hector_raw = []\n",
    "straker_raw = []\n",
    "mendoza_raw = []\n",
    "juan_raw = []\n",
    "devil_raw = []\n",
    "ana_raw = []\n",
    "for par in token_paragraphs_mas:\n",
    "    if  'RAMSDEN' in par:\n",
    "         ramsden_raw.append(par)\n",
    "    if  'OCTAVIUS' in par:\n",
    "         octavius_raw.append(par)\n",
    "    if  'TANNER' in par:\n",
    "         tanner_raw.append(par)\n",
    "    if  'ANN' in par:\n",
    "         ann_raw.append(par)\n",
    "    if  'WHITEFIELD' in par and 'MRS' or 'MRS.' in par:\n",
    "         whitefield_raw.append(par)\n",
    "    if  'RAMSDEN' in par and 'MISS' in par:\n",
    "         missramsden_raw.append(par)\n",
    "    if  'VIOLET' in par:\n",
    "         violet_raw.append(par)\n",
    "    if  'HECTOR' in par:\n",
    "         hector_raw.append(par)\n",
    "    if  'STRAKER' in par:\n",
    "         straker_raw.append(par)\n",
    "    if  'MENDOZA' in par:\n",
    "         mendoza_raw.append(par)\n",
    "    if  'JUAN' in par:\n",
    "         juan_raw.append(par)\n",
    "    if  'DEVIL' in par:\n",
    "         devil_raw.append(par)\n",
    "    if  'ANA' in par:\n",
    "         ana_raw.append(par)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramsden = character_cleaner_by_name(ramsden_raw, 'RAMSDEN', 'xxxx', 'xxxx')\n",
    "octavius = character_cleaner_by_name(octavius_raw, 'OCTAVIUS', 'xxxx', 'xxxx')\n",
    "tanner = character_cleaner_by_name(tanner_raw, 'TANNER', 'xxxx', 'xxxx')\n",
    "ann = character_cleaner_by_name(ann_raw, 'ANN', 'xxxx', 'xxxx')\n",
    "missramsden = character_cleaner_by_name(whitefield_raw, 'WHITEFIELD', 'MRS', 'MRS.')\n",
    "violet = character_cleaner_by_name(violet_raw, 'VIOLET', 'xxxx', 'xxxx')\n",
    "hector = character_cleaner_by_name(hector_raw, 'HECTOR', 'xxxx', 'xxxx')\n",
    "straker = character_cleaner_by_name(straker_raw, 'STRAKER', 'xxxx', 'xxxx')\n",
    "mendoza = character_cleaner_by_name(mendoza_raw, 'MENDOZA', 'xxxx', 'xxxx')\n",
    "juan = character_cleaner_by_name(juan_raw, 'JUAN', 'DON', 'xxxx')\n",
    "devil = character_cleaner_by_name(devil_raw, 'DEVIL', 'THE', 'xxxx')\n",
    "ana = character_cleaner_by_name(ana_raw, 'ANA', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_and_superman_characters = {'Ramsden':ramsden, 'Octavius':octavius, 'Tanner':tanner, 'Ann':ann, 'Miss Ramsden':missramsden, 'Violet':violet, 'Hector':hector, 'Straker':straker, 'Mendoza':mendoza, 'Don Juan':juan, 'The Devil':devil, 'Dona Ana':ana}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramsden contains 293 sentences and 2706 words\n",
      "Octavius contains 267 sentences and 2402 words\n",
      "Tanner contains 970 sentences and 10945 words\n",
      "Ann contains 419 sentences and 3675 words\n",
      "Miss Ramsden contains 97 sentences and 1056 words\n",
      "Violet contains 162 sentences and 1526 words\n",
      "Hector contains 128 sentences and 1258 words\n",
      "Straker contains 159 sentences and 1359 words\n",
      "Mendoza contains 192 sentences and 1943 words\n",
      "Don Juan contains 516 sentences and 8995 words\n",
      "The Devil contains 237 sentences and 3511 words\n",
      "Dona Ana contains 131 sentences and 1062 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(man_and_superman_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyntia's Revels - Ben Jonson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cr = paragraphs_cleaner(\"cynthias_revels_jonson.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_cr = token_paragraphs_cr[153:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercury_raw = []\n",
    "echo_raw = []\n",
    "cupid_raw = []\n",
    "amorphus_raw = []\n",
    "asotus_raw = []\n",
    "crites_raw = []\n",
    "anaides_raw = []\n",
    "hedon_raw = []\n",
    "arete_raw = []\n",
    "phantase_raw = []\n",
    "philautia_raw = []\n",
    "cyntia_raw = []\n",
    "for par in token_paragraphs_cr:\n",
    "    if  'MER' in par:\n",
    "         mercury_raw.append(par)\n",
    "    if  'ECHO' in par:\n",
    "         echo_raw.append(par)\n",
    "    if  'CUP' in par:\n",
    "         cupid_raw.append(par)\n",
    "    if  'AMO' in par:\n",
    "         amorphus_raw.append(par)\n",
    "    if  'ASO' in par:\n",
    "         asotus_raw.append(par)\n",
    "    if  'CRI' in par:\n",
    "         crites_raw.append(par)\n",
    "    if  'ANA' in par:\n",
    "         anaides_raw.append(par)\n",
    "    if  'HED' in par:\n",
    "         hedon_raw.append(par)\n",
    "    if  'ARE' in par:\n",
    "         arete_raw.append(par)\n",
    "    if  'PHA' in par:\n",
    "         phantase_raw.append(par)\n",
    "    if  'PHI' in par:\n",
    "         philautia_raw.append(par)\n",
    "    if  'CYN' in par:\n",
    "         cyntia_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercury = character_cleaner_by_name(mercury_raw, 'MER', 'xxxx', 'xxxx')\n",
    "echo = character_cleaner_by_name(echo_raw, 'ECHO', 'xxxx', 'xxxx')\n",
    "cupid = character_cleaner_by_name(cupid_raw, 'CUP', 'xxxx', 'xxxx')\n",
    "amorphus = character_cleaner_by_name(amorphus_raw, 'AMO', 'xxxx', 'xxxx')\n",
    "asotus = character_cleaner_by_name(asotus_raw, 'ASO', 'xxxx', 'xxxx')\n",
    "crites = character_cleaner_by_name(crites_raw, 'CRI', 'xxxx', 'xxxx')\n",
    "anaides = character_cleaner_by_name(anaides_raw, 'ANA', 'xxxx', 'xxxx')\n",
    "hedon = character_cleaner_by_name(hedon_raw, 'HED', 'xxxx', 'xxxx')\n",
    "arete = character_cleaner_by_name(arete_raw, 'ARE', 'xxxx', 'xxxx')\n",
    "phantase = character_cleaner_by_name(phantase_raw, 'PHA', 'xxxx', 'xxxx')\n",
    "philautia = character_cleaner_by_name(philautia_raw, 'PHI', 'xxxx', 'xxxx')\n",
    "cyntia = character_cleaner_by_name(cyntia_raw, 'CYN', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "cynthias_revels_characters = {'Mercury':mercury, 'Echo':echo, 'Cupid':cupid, 'Amorphus':amorphus, 'Asotus':asotus, 'Crites':crites, 'Anaides':anaides, 'Hedon':hedon, 'Arete':arete, 'Phantase':phantase, 'Philautia':philautia, 'Cyntia':cyntia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercury contains 293 sentences and 4467 words\n",
      "Echo contains 22 sentences and 487 words\n",
      "Cupid contains 148 sentences and 2502 words\n",
      "Amorphus contains 389 sentences and 5878 words\n",
      "Asotus contains 216 sentences and 2257 words\n",
      "Crites contains 175 sentences and 4003 words\n",
      "Anaides contains 164 sentences and 1743 words\n",
      "Hedon contains 147 sentences and 1484 words\n",
      "Arete contains 37 sentences and 928 words\n",
      "Phantase contains 149 sentences and 1801 words\n",
      "Philautia contains 91 sentences and 984 words\n",
      "Cyntia contains 46 sentences and 1073 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(cynthias_revels_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Every Man On His Humor - Ben Jonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_emohh = paragraphs_cleaner(\"every_man_on_his_humour_jonson.txt\", squared_braquets, squared_to_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_emohh = token_paragraphs_emohh[82:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "edknowell_raw = []\n",
    "stephen_raw = []\n",
    "mathew_raw = []\n",
    "cob_raw = []\n",
    "bobadill_raw = []\n",
    "tib_raw = []\n",
    "kitely_raw = []\n",
    "cash_raw = []\n",
    "downright_raw = []\n",
    "damekitely_raw = []\n",
    "brainworm_raw = []\n",
    "knowell_raw = []\n",
    "wellbred_raw = []\n",
    "for par in token_paragraphs_emohh:\n",
    "    if  'Know' in par and 'E.' in par[:1]:\n",
    "         edknowell_raw.append(par)\n",
    "    if  'Step' in par[:2]:\n",
    "         stephen_raw.append(par)\n",
    "    if  'Mat' in par[:2]:\n",
    "         mathew_raw.append(par)\n",
    "    if  'Cob' in par[:2]:\n",
    "         cob_raw.append(par)\n",
    "    if  'Bob' in par[:2]:\n",
    "         bobadill_raw.append(par)\n",
    "    if  'Tib' in par[:2]:\n",
    "         tib_raw.append(par)\n",
    "    if  'Kit' in par[:2]:\n",
    "         kitely_raw.append(par)\n",
    "    if  'Cash' in par[:2]:\n",
    "         cash_raw.append(par)\n",
    "    if  'Dow' in par[:2]:\n",
    "         downright_raw.append(par)\n",
    "    if  'Dame' in par[:2] and 'K.' in par[:3]:\n",
    "         damekitely_raw.append(par)\n",
    "    if  'Brai' in par[:2]:\n",
    "         brainworm_raw.append(par)\n",
    "    if  'Know' in par[:2] and not 'E.' in par:\n",
    "         knowell_raw.append(par)\n",
    "    if  'Wel' in par[:2]:\n",
    "         wellbred_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stephen = character_cleaner_by_name(stephen_raw, 'Step', 'xxxx', 'xxxx')\n",
    "edknowell = character_cleaner_by_name(edknowell_raw, 'E.', 'Know', 'xxxx')\n",
    "mathew = character_cleaner_by_name(mathew_raw, 'Mat', 'xxxx', 'xxxx')\n",
    "cob = character_cleaner_by_name(cob_raw, 'Cob', 'xxxx', 'xxxx')\n",
    "bobadill = character_cleaner_by_name(bobadill_raw, 'Bob', 'xxxx', 'xxxx')\n",
    "tib = character_cleaner_by_name(tib_raw, 'Tib', 'xxxx', 'xxxx')\n",
    "kitely = character_cleaner_by_name(kitely_raw, 'Kit', 'xxxx', 'xxxx')\n",
    "cash = character_cleaner_by_name(cash_raw, 'Cash', 'xxxx', 'xxxx')\n",
    "downright = character_cleaner_by_name(downright_raw, 'Dow', 'xxxx', 'xxxx')\n",
    "damekitely = character_cleaner_by_name(damekitely_raw, 'Dame', 'K', 'xxxx')\n",
    "brainworm = character_cleaner_by_name(brainworm_raw, 'Brai', 'xxxx', 'xxxx')\n",
    "knowell = character_cleaner_by_name(knowell_raw, 'Know', 'xxxx', 'xxxx')\n",
    "wellbred = character_cleaner_by_name(wellbred_raw, 'Wel', 'xxxx', 'xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_man_on_his_humour_characters = {'Stephen':stephen, 'Ed Knowell':edknowell, 'Mathew':mathew, 'Cob':cob, 'Bobadill':bobadill, 'Tib':tib, 'Kitely':kitely, 'Cash':cash, 'Downright':downright, 'Dame Kitely':damekitely, 'Brainworm':brainworm, 'Knowell':knowell, 'Wellbred':wellbred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stephen contains 170 sentences and 1753 words\n",
      "Ed Knowell contains 186 sentences and 2064 words\n",
      "Mathew contains 142 sentences and 1486 words\n",
      "Cob contains 148 sentences and 1987 words\n",
      "Bobadill contains 195 sentences and 3122 words\n",
      "Tib contains 31 sentences and 230 words\n",
      "Kitely contains 268 sentences and 3620 words\n",
      "Cash contains 75 sentences and 646 words\n",
      "Downright contains 107 sentences and 1152 words\n",
      "Dame Kitely contains 54 sentences and 560 words\n",
      "Brainworm contains 171 sentences and 2998 words\n",
      "Knowell contains 133 sentences and 2121 words\n",
      "Wellbred contains 145 sentences and 1718 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(every_man_on_his_humour_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volpone, Or The Fox - Ben jonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_votf = paragraphs_cleaner(\"volpone_or_the_fox_jonson.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_votf = token_paragraphs_votf[110:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "volpone_raw = []\n",
    "mosca_raw = []\n",
    "nano_raw = []\n",
    "androgyno_raw = []\n",
    "voltore_raw = []\n",
    "corbaccio_raw = []\n",
    "corvino_raw = []\n",
    "peregrine_raw = []\n",
    "sirpolitick_raw = []\n",
    "bonario_raw = []\n",
    "ladywouldbe_raw = []\n",
    "for par in token_paragraphs_votf:\n",
    "    if  'VOLP' in par:\n",
    "         volpone_raw.append(par)\n",
    "    if  'MOS' in par:\n",
    "         mosca_raw.append(par)\n",
    "    if  'NAN' in par:\n",
    "         nano_raw.append(par)\n",
    "    if  'AND' in par and ':' in par[0:2]:\n",
    "         androgyno_raw.append(par)\n",
    "    if  'VOLT' in par:\n",
    "         voltore_raw.append(par)\n",
    "    if  'CORB' in par:\n",
    "         corbaccio_raw.append(par)\n",
    "    if  'CORV' in par:\n",
    "         corvino_raw.append(par)\n",
    "    if  'PER' in par:\n",
    "         peregrine_raw.append(par)\n",
    "    if  'SIR' in par and 'P' in par:\n",
    "         sirpolitick_raw.append(par)\n",
    "    if  'BON' in par:\n",
    "         bonario_raw.append(par)\n",
    "    if  'LADY' in par and 'P' in par:\n",
    "         ladywouldbe_raw.append(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "volpone = character_cleaner(volpone_raw, 1)\n",
    "mosca = character_cleaner(mosca_raw, 2)\n",
    "nano = character_cleaner(nano_raw, 2)\n",
    "androgyno = character_cleaner(androgyno_raw, 2)\n",
    "voltore = character_cleaner(voltore_raw, 2)\n",
    "corbaccio = character_cleaner(corbaccio_raw, 2)\n",
    "corvino = character_cleaner(corvino_raw, 2)\n",
    "peregrine = character_cleaner(peregrine_raw, 2)\n",
    "sirpolitick = character_cleaner(sirpolitick_raw, 3)\n",
    "bonario = character_cleaner(bonario_raw, 2)\n",
    "ladywouldbe = character_cleaner(ladywouldbe_raw, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "volpone_or_the_fox_jonson_characters = {'Volpone':volpone, 'Mosca':mosca, 'Nano':nano, 'Androgyno':androgyno, 'Voltore':voltore, 'Corbaccio':corbaccio, 'Peregrine':peregrine, 'Sir Politick': sirpolitick, 'Bonario':bonario, 'Lady Would-be':ladywouldbe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volpone contains 444 sentences and 6690 words\n",
      "Mosca contains 498 sentences and 6904 words\n",
      "Nano contains 33 sentences and 670 words\n",
      "Androgyno contains 12 sentences and 143 words\n",
      "Voltore contains 113 sentences and 1486 words\n",
      "Corbaccio contains 136 sentences and 733 words\n",
      "Peregrine contains 148 sentences and 1322 words\n",
      "Sir Politick contains 148 sentences and 2335 words\n",
      "Bonario contains 38 sentences and 369 words\n",
      "Lady Would-be contains 108 sentences and 1428 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(volpone_or_the_fox_jonson_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Alchemist - Ben Jonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_ta = paragraphs_cleaner(\"the_alchemist_jonson.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_ta = token_paragraphs_ta[97:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_raw = []\n",
    "subtle_raw = []\n",
    "dol_raw = []\n",
    "dapper_raw = []\n",
    "drugger_raw = []\n",
    "mammon_raw = []\n",
    "surly_raw = []\n",
    "ananias_raw = []\n",
    "tribulation_raw = []\n",
    "kastril_raw = []\n",
    "for par in token_paragraphs_ta:\n",
    "    if  'FACE' in par:\n",
    "         face_raw.append(par)\n",
    "    if  'SUB' in par:\n",
    "         subtle_raw.append(par)\n",
    "    if  'DOL' in par:\n",
    "         dol_raw.append(par)\n",
    "    if  'DAP' in par:\n",
    "         dapper_raw.append(par)\n",
    "    if  'DRUG' in par:\n",
    "         drugger_raw.append(par)\n",
    "    if  'MAM' in par:\n",
    "         mammon_raw.append(par)\n",
    "    if  'SUR' in par:\n",
    "         surly_raw.append(par)\n",
    "    if  'ANA' in par:\n",
    "         ananias_raw.append(par)\n",
    "    if  'TRI' in par:\n",
    "         tribulation_raw.append(par)\n",
    "    if  'KAS' in par:\n",
    "         kastril_raw.append(par)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = character_cleaner(face_raw, 2)\n",
    "subtle = character_cleaner(subtle_raw, 2)\n",
    "dol = character_cleaner(dol_raw, 2)\n",
    "dapper = character_cleaner(dapper_raw, 2)\n",
    "drugger = character_cleaner(drugger_raw, 2)\n",
    "mammon = character_cleaner(mammon_raw, 2)\n",
    "surly = character_cleaner(surly_raw, 2)\n",
    "ananias = character_cleaner(ananias_raw, 2)\n",
    "tribulation = character_cleaner(tribulation_raw, 2)\n",
    "kastril = character_cleaner(kastril_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_alchemist_characters = {'Face':face, 'Subtle':subtle, 'Dol':dol, 'Dapper':dapper, 'Drugger':drugger, 'Mammon':mammon, 'Surly': surly, 'Ananias':ananias, 'Tribulation':tribulation, 'Kastril':kastril}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face contains 815 sentences and 8561 words\n",
      "Subtle contains 669 sentences and 7226 words\n",
      "Dol contains 143 sentences and 1464 words\n",
      "Dapper contains 86 sentences and 573 words\n",
      "Drugger contains 44 sentences and 589 words\n",
      "Mammon contains 276 sentences and 3410 words\n",
      "Surly contains 139 sentences and 1568 words\n",
      "Ananias contains 64 sentences and 749 words\n",
      "Tribulation contains 45 sentences and 631 words\n",
      "Kastril contains 110 sentences and 860 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(the_alchemist_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Macbeth - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_m = paragraphs_cleaner(\"macbeth_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_raw = token_paragraphs_m[:440]\n",
    "banquo_raw = token_paragraphs_m[440:541]\n",
    "malcom_raw = token_paragraphs_m[541:663]\n",
    "ladymacbeth_raw = token_paragraphs_m[663:842]\n",
    "macduff_raw = token_paragraphs_m[842:1021]\n",
    "ross_raw = token_paragraphs_m[1021:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth = speech_filter(macbeth_raw)\n",
    "banquo = speech_filter(banquo_raw)\n",
    "malcom = speech_filter(malcom_raw)\n",
    "ladymacbeth = speech_filter(ladymacbeth_raw)\n",
    "macduff = speech_filter(macduff_raw)\n",
    "ross = speech_filter(ross_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "macbeth_characters = {'Macbeth':macbeth, 'Banquo':banquo, 'Malcom':malcom, 'Lady Macbeth':ladymacbeth, 'Macduff': macduff, 'Ross':ross}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macbeth contains 350 sentences and 5515 words\n",
      "Banquo contains 61 sentences and 805 words\n",
      "Malcom contains 73 sentences and 1543 words\n",
      "Lady Macbeth contains 135 sentences and 1965 words\n",
      "Macduff contains 109 sentences and 1209 words\n",
      "Ross contains 55 sentences and 946 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(macbeth_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Romeo And Juliet - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_raj = paragraphs_cleaner(\"romeo_and_juliet_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_raw = token_paragraphs_raj[:492]\n",
    "juliet_raw = token_paragraphs_raj[492:848]\n",
    "benvolio_raw = token_paragraphs_raj[848:1042]\n",
    "mercutio_raw = token_paragraphs_raj[1042:1230]\n",
    "nurse_raw = token_paragraphs_raj[1230:1502]\n",
    "capulet_raw = token_paragraphs_raj[1502:1657]\n",
    "ladycapulet_raw = token_paragraphs_raj[1657:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo = speech_filter(romeo_raw)\n",
    "juliet = speech_filter(juliet_raw)\n",
    "benvolio = speech_filter(benvolio_raw)\n",
    "mercutio = speech_filter(mercutio_raw)\n",
    "nurse = speech_filter(nurse_raw)\n",
    "capulet = speech_filter(capulet_raw)\n",
    "ladycapulet = speech_filter(ladycapulet_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(335, 298, 77, 213, 168, 76)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(romeo), len(juliet), len(benvolio), len(nurse), len(capulet), len(ladycapulet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet_characters = {'Romeo':romeo, 'Juliet':juliet, 'Benvolio': benvolio, 'Nurse':nurse, 'Capulet':capulet, 'Lady Capulet':ladycapulet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo contains 335 sentences and 4839 words\n",
      "Juliet contains 298 sentences and 4414 words\n",
      "Benvolio contains 77 sentences and 1190 words\n",
      "Nurse contains 213 sentences and 2300 words\n",
      "Capulet contains 168 sentences and 2237 words\n",
      "Lady Capulet contains 76 sentences and 907 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(romeo_and_juliet_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Othello - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_o = paragraphs_cleaner(\"othello_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello_raw = token_paragraphs_o[:825]\n",
    "roderigo_raw = token_paragraphs_o[825:1004]\n",
    "iago_raw = token_paragraphs_o[1004:1822]\n",
    "cassio_raw = token_paragraphs_o[1822:2154]\n",
    "desdemona_raw = token_paragraphs_o[2154:2651]\n",
    "emilia_raw = token_paragraphs_o[2651:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello = speech_filter(othello_raw)\n",
    "roderigo = speech_filter(roderigo_raw)\n",
    "iago = speech_filter(iago_raw)\n",
    "cassio = speech_filter(cassio_raw)\n",
    "desdemona = speech_filter(desdemona_raw)\n",
    "emilia = speech_filter(emilia_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539, 76, 560, 178, 238, 178)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(othello), len(roderigo), len(iago), len(cassio), len(desdemona), len(emilia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "othello_characters = {'Othello':othello, 'Roderigo':roderigo, 'Iago':iago, 'Cassio':cassio, 'Desdemona':desdemona, 'Emilia':emilia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Othello contains 539 sentences and 6473 words\n",
      "Roderigo contains 76 sentences and 881 words\n",
      "Iago contains 560 sentences and 8623 words\n",
      "Cassio contains 178 sentences and 2013 words\n",
      "Desdemona contains 238 sentences and 2830 words\n",
      "Emilia contains 178 sentences and 1865 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(othello_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamlet - William Sahakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_h =  paragraphs_cleaner(\"hamlet_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_raw = token_paragraphs_h[:500] + token_paragraphs_h[500:1077]\n",
    "ophelia_raw = token_paragraphs_h[1077:1253]\n",
    "polonius_raw = token_paragraphs_h[1253:1513]\n",
    "claudius_raw = token_paragraphs_h[1513:1821]\n",
    "horatio_raw = token_paragraphs_h[1821:2150]\n",
    "laertes_raw = token_paragraphs_h[2150:2338]\n",
    "gertrude_raw = token_paragraphs_h[2338:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = speech_filter(hamlet_raw)\n",
    "ophelia = speech_filter(ophelia_raw)\n",
    "polonius = speech_filter(polonius_raw)\n",
    "claudius = speech_filter(claudius_raw)\n",
    "horatio = speech_filter(horatio_raw)\n",
    "laertes = speech_filter(laertes_raw)\n",
    "gertrude = speech_filter(gertrude_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 106, 218, 299, 184, 131, 107)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hamlet), len(ophelia), len(polonius), len(claudius), len(horatio), len(laertes), len(gertrude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_characters = {'Hamlet':hamlet, 'Ophelia':ophelia, 'Polonius': polonius, 'Claudius': claudius, 'Horatio': horatio, 'Laertes': laertes, 'Gertrude':gertrude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet contains 1020 sentences and 12233 words\n",
      "Ophelia contains 106 sentences and 1261 words\n",
      "Polonius contains 218 sentences and 2750 words\n",
      "Claudius contains 299 sentences and 4234 words\n",
      "Horatio contains 184 sentences and 2127 words\n",
      "Laertes contains 131 sentences and 1493 words\n",
      "Gertrude contains 107 sentences and 1091 words\n"
     ]
    }
   ],
   "source": [
    "characters_details(hamlet_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### King Lear - William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_paragraphs_kl = paragraphs_cleaner(\"king_lear_characters_shakespeare.txt\", squared_braquets, nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "goneril_raw = token_paragraphs_kl[:161]\n",
    "edmund_raw = token_paragraphs_kl[161:400]\n",
    "regan_raw = token_paragraphs_kl[400:621]\n",
    "lear_raw = token_paragraphs_kl[621:1187]\n",
    "fool_raw = token_paragraphs_kl[1187:1363]\n",
    "earlofkent_raw = token_paragraphs_kl[1363:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "goneril = speech_filter(goneril_raw)\n",
    "edmund = speech_filter(edmund_raw)\n",
    "regan = speech_filter(regan_raw)\n",
    "lear = speech_filter(lear_raw)\n",
    "fool = speech_filter(fool_raw)\n",
    "earlofkent = speech_filter(earlofkent_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_lear_characters = {'Goneril':goneril, 'Edmund':edmund, 'Regan':regan,'Lear': lear, 'Fool': fool, 'Earl Of Kent':earlofkent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goneril contains 128 sentences and 1514 words\n",
      "Edmund contains 208 sentences and 2441 words\n",
      "Regan contains 146 sentences and 1460 words\n",
      "Lear contains 645 sentences and 5875 words\n",
      "Fool contains 131 sentences and 1827 words\n",
      "Earl Of Kent contains 237 sentences and 2708 words\n"
     ]
    }
   ],
   "source": [
    "character_details(king_lear_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
