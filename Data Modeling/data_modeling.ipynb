{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition (char_sens, n):\n",
    "    random.seed(123)\n",
    "    random.shuffle(char_sens)\n",
    "    return [char_sens[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_split (play_characters, n):\n",
    "    play_characters_part = {}\n",
    "    for char in play_characters.keys():\n",
    "        play_characters_part[char] = partition(play_characters[char], n)\n",
    "    return play_characters_part  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_partitions (play_part):\n",
    "    part_1 = {}\n",
    "    part_2 = {}\n",
    "    part_3 = {}\n",
    "    part_4 = {}\n",
    "    part_5 = {}\n",
    "    for char in play_part:\n",
    "        for part in char:\n",
    "            part_1[char] = play_part[char][0] + play_part[char][2] + play_part[char][3] + play_part[char][4]\n",
    "            part_2[char] = play_part[char][0] + play_part[char][1] + play_part[char][3] + play_part[char][4]\n",
    "            part_3[char] = play_part[char][0] + play_part[char][1] + play_part[char][2] + play_part[char][4]\n",
    "            part_4[char] = play_part[char][0] + play_part[char][1] + play_part[char][2] + play_part[char][3]\n",
    "            part_5[char] = play_part[char][1] + play_part[char][2] + play_part[char][3] + play_part[char][4]\n",
    "    return part_1, part_2, part_3, part_4, part_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test (play_part):\n",
    "    test_1 = {}\n",
    "    test_2 = {}\n",
    "    test_3 = {}\n",
    "    test_4 = {}\n",
    "    test_5 = {}\n",
    "    for char in play_part:\n",
    "        for part in char:\n",
    "            test_1[char] = play_part[char][1]\n",
    "            test_2[char] = play_part[char][2]\n",
    "            test_3[char] = play_part[char][3]\n",
    "            test_4[char] = play_part[char][4]\n",
    "            test_5[char] = play_part[char][0]\n",
    "    return test_1, test_2, test_3, test_4, test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tok_no_punct (char):\n",
    "    result = []\n",
    "    for sen in char:\n",
    "        sen = sen.lower()\n",
    "        output = tokenizer.tokenize(sen)\n",
    "        result.append(output)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_unifier (character):\n",
    "    output = []\n",
    "    for sen in character:\n",
    "        for word in sen:\n",
    "            output.append(word)\n",
    "    one_string = \" \".join(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_word_tokenizer (play_characters):\n",
    "    chars = list(play_characters.keys())\n",
    "    char_tokens = {}\n",
    "    for char in chars:\n",
    "        output = char_tok_no_punct(play_characters[char])\n",
    "        result = sentences_unifier(output)\n",
    "        char_tokens[char] = result\n",
    "    return char_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_corpus_generator (partition):\n",
    "    whole_corpus = []\n",
    "    for char in partition.keys():\n",
    "        for word in partition[char]:\n",
    "            word = word.lower()\n",
    "            whole_corpus.append(word)\n",
    "    return whole_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_generator (whole_corpus_freq, partition):\n",
    "    features = [word for word,freq in whole_corpus_freq]\n",
    "    feature_freqs = {}\n",
    "    for char in partition:\n",
    "        feature_freqs[char] = {} \n",
    "        overall = len(partition[char])\n",
    "        for feature in features:\n",
    "            presence = partition[char].count(feature)\n",
    "            feature_freqs[char][feature] = presence / overall\n",
    "    return  feature_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscores (df):\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        col_zscore = col + '_zscore'\n",
    "        df[col_zscore] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
    "    df = df.drop(cols, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_distance (play_characters, test_zscores, part_zscores, character):    \n",
    "    chars = play_characters.keys()\n",
    "    delta = {}\n",
    "    for char in chars:\n",
    "        delta[char] = (abs(test_zscores.loc[character] - part_zscores.loc[char])).sum()/50\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas (writer_characters, test_zscores, train_zscores):\n",
    "    deltas = {}\n",
    "    for char in writer_characters.keys():\n",
    "        result = delta_distance(writer_characters, test_zscores, train_zscores, char)\n",
    "        deltas[char]= result\n",
    "        df = pd.DataFrame.from_dict(deltas)\n",
    "        df = df.reindex(sorted(df.columns), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burrows Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oscar Wilde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_characters = {**an_ideal_husband_characters, **a_woman_of_no_importance_characters, **lady_windermeres_fan_characters, **the_importance_of_being_earnest_characters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wilde_characters['Chasuble']\n",
    "del wilde_characters['Prism']\n",
    "del wilde_characters['Augustus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wilde_characters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_characters_split = corpus_split(wilde_characters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_characters_partition = split_partitions(wilde_characters_split)\n",
    "wilde_characters_test = split_test(wilde_characters_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_1 = dict_word_tokenizer(wilde_characters_partition[0])\n",
    "wilde_part_2 = dict_word_tokenizer(wilde_characters_partition[1])\n",
    "wilde_part_3 = dict_word_tokenizer(wilde_characters_partition[2])\n",
    "wilde_part_4 = dict_word_tokenizer(wilde_characters_partition[3])\n",
    "wilde_part_5 = dict_word_tokenizer(wilde_characters_partition[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_1 = dict_word_tokenizer(wilde_characters_test[0])\n",
    "wilde_test_2 = dict_word_tokenizer(wilde_characters_test[1])\n",
    "wilde_test_3 = dict_word_tokenizer(wilde_characters_test[2])\n",
    "wilde_test_4 = dict_word_tokenizer(wilde_characters_test[3])\n",
    "wilde_test_5 = dict_word_tokenizer(wilde_characters_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_1_corpus = whole_corpus_generator(wilde_part_1)\n",
    "wilde_part_1_corpus_freq = list(nltk.FreqDist(wilde_part_1_corpus).most_common(50))\n",
    "wilde_part_1_features = features_generator(wilde_part_1_corpus_freq, wilde_part_1)\n",
    "df_wilde_1 = pd.DataFrame.from_dict(wilde_part_1_features, orient = 'index')\n",
    "wilde_zscores_1 = zscores(df_wilde_1)\n",
    "wilde_zscores_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_1 = dict_word_tokenizer(wilde_test_1)\n",
    "wilde_test_1_features = features_generator(wilde_part_1_corpus_freq, wilde_test_1)\n",
    "df_wilde_test_1 = pd.DataFrame.from_dict(wilde_test_1_features, orient = 'index')\n",
    "wilde_zscores_test_1 = zscores(df_wilde_test_1)\n",
    "wilde_zscores_test_1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algernon                  Algernon\n",
       "Allonby                    Allonby\n",
       "Berwick                   Cheveley\n",
       "Bracknell                Bracknell\n",
       "Caversham                Bracknell\n",
       "Cecily                      Goring\n",
       "Cheveley                    Goring\n",
       "Chiltern                    Goring\n",
       "Darlington                Chiltern\n",
       "Erlynne            Lady Windermere\n",
       "Gerald             Lady Windermere\n",
       "Goring                      Goring\n",
       "Gwendolen                 Cheveley\n",
       "Hester                      Gerald\n",
       "Hunstanton                  Goring\n",
       "Illingorth              Illingorth\n",
       "Jack                          Jack\n",
       "Lady Chiltern               Goring\n",
       "Lady Windermere    Lady Windermere\n",
       "Lord Windermere    Lord Windermere\n",
       "Mabel                       Goring\n",
       "Mrs Artbuthnot      Mrs Artbuthnot\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_1_deltas = get_deltas(wilde_characters, wilde_zscores_test_1, wilde_zscores_1)\n",
    "predictions_wilde_1 = wilde_1_deltas.idxmin()\n",
    "predictions_wilde_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train z- scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_2_corpus = whole_corpus_generator(wilde_part_2)\n",
    "wilde_part_2_corpus_freq = list(nltk.FreqDist(wilde_part_2_corpus).most_common(50))\n",
    "wilde_part_2_features = features_generator(wilde_part_2_corpus_freq, wilde_part_2)\n",
    "df_wilde_2 = pd.DataFrame.from_dict(wilde_part_2_features, orient = 'index')\n",
    "wilde_zscores_2 = zscores(df_wilde_2)\n",
    "wilde_zscores_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_2 = dict_word_tokenizer(wilde_test_2)\n",
    "wilde_test_2_features = features_generator(wilde_part_2_corpus_freq, wilde_test_2)\n",
    "df_wilde_test_2 = pd.DataFrame.from_dict(wilde_test_2_features, orient = 'index')\n",
    "wilde_zscores_test_2 = zscores(df_wilde_test_2)\n",
    "wilde_zscores_test_2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algernon                  Algernon\n",
       "Allonby                     Goring\n",
       "Berwick                 Hunstanton\n",
       "Bracknell                   Goring\n",
       "Caversham                 Algernon\n",
       "Cecily                    Algernon\n",
       "Cheveley                    Goring\n",
       "Chiltern                  Chiltern\n",
       "Darlington              Illingorth\n",
       "Erlynne                   Algernon\n",
       "Gerald                     Erlynne\n",
       "Goring                      Goring\n",
       "Gwendolen                   Cecily\n",
       "Hester                      Hester\n",
       "Hunstanton              Hunstanton\n",
       "Illingorth                Cheveley\n",
       "Jack                          Jack\n",
       "Lady Chiltern              Erlynne\n",
       "Lady Windermere    Lady Windermere\n",
       "Lord Windermere    Lady Windermere\n",
       "Mabel                     Cheveley\n",
       "Mrs Artbuthnot      Mrs Artbuthnot\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_2_deltas = get_deltas(wilde_characters, wilde_zscores_test_2, wilde_zscores_2)\n",
    "predictions_wilde_2 = wilde_2_deltas.idxmin()\n",
    "predictions_wilde_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_part_3_corpus = whole_corpus_generator(wilde_part_3)\n",
    "wilde_part_3_corpus_freq = list(nltk.FreqDist(wilde_part_3_corpus).most_common(50))\n",
    "wilde_part_3_features = features_generator(wilde_part_3_corpus_freq, wilde_part_3)\n",
    "df_wilde_3 = pd.DataFrame.from_dict(wilde_part_3_features, orient = 'index')\n",
    "wilde_zscores_3 = zscores(df_wilde_3)\n",
    "wilde_zscores_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test z - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilde_test_3 = dict_word_tokenizer(wilde_test_3)\n",
    "wilde_test_3_features = features_generator(wilde_part_3_corpus_freq, wilde_test_3)\n",
    "df_wilde_test_3 = pd.DataFrame.from_dict(wilde_test_3_features, orient = 'index')\n",
    "wilde_zscores_test_3 = zscores(df_wilde_test_3)\n",
    "wilde_zscores_test_3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algernon                      Jack\n",
       "Allonby                     Cecily\n",
       "Berwick                 Hunstanton\n",
       "Bracknell                Bracknell\n",
       "Caversham                   Gerald\n",
       "Cecily                   Gwendolen\n",
       "Cheveley                  Cheveley\n",
       "Chiltern                  Chiltern\n",
       "Darlington         Lady Windermere\n",
       "Erlynne            Lady Windermere\n",
       "Gerald                      Gerald\n",
       "Goring                    Cheveley\n",
       "Gwendolen                   Cecily\n",
       "Hester                    Cheveley\n",
       "Hunstanton              Hunstanton\n",
       "Illingorth              Illingorth\n",
       "Jack                          Jack\n",
       "Lady Chiltern        Lady Chiltern\n",
       "Lady Windermere    Lady Windermere\n",
       "Lord Windermere    Lady Windermere\n",
       "Mabel                       Goring\n",
       "Mrs Artbuthnot      Mrs Artbuthnot\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilde_3_deltas = get_deltas(wilde_characters, wilde_zscores_test_3, wilde_zscores_3)\n",
    "predictions_wilde_3 = wilde_3_deltas.idxmin()\n",
    "predictions_wilde_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
